<!DOCTYPE html>
<html><head>
	<meta name="generator" content="Hugo 0.82.1" />
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="A personal blog of z217">
  <meta name="Author" content="z217">
  <meta name="keywords" content="hugo blog">
  <link rel="icon" type="image/x-icon" href=https://z217blog.cn/favicon.ico>
  <link rel="stylesheet" href=https://z217blog.cn/css/syntax.css>
  <link rel="stylesheet" href=https://z217blog.cn/css/style.css>
  <script src="https://kit.fontawesome.com/1b7478c139.js" crossorigin="anonymous"></script>
  
  <title>z217&#39;s blog</title>
</head><script src=https://z217blog.cn/js/jquery-3.4.1.min.js></script>
<script src=https://z217blog.cn/js/navbutton.js></script>

<body><aside id="sidenav">
    <header>
        
        <a href=https://z217blog.cn><img src="https://z217blog.cn/avatar.png" alt="avatar"></a>

        

        <a id="branding" href=https://z217blog.cn>
            
            z217&#39;s blog
            
        </a>
    </header>

    <nav>
        
        
        <a href="/" >
            <i class="fas fa-home fa-ms"></i>
            <span>首页</span>
        </a>
        
        
        <a href="/post/" >
            <i class="fas fa-keyboard fa-ms"></i>
            <span>文章</span>
        </a>
        
        
        <a href="/tags" >
            <i class="fas fa-tags fa-sm"></i>
            <span>标签</span>
        </a>
        
        
        <a href="/about" >
            <i class="fas fa-user fa-ms"></i>
            <span>关于</span>
        </a>
        
        
        <a href="https://github.com/z217"  target="_blank" >
            <i class="fab fa-github fa-ms"></i>
            <span>Github</span>
        </a>
        
        
        <a href="/index.xml" >
            <i class="fas fa-rss fa-sm"></i>
            <span>RSS</span>
        </a>
        
        
        <a href="https://www.cnblogs.com/meidaoli/"  target="_blank" >
            <i class="fas fa-map fa-sm"></i>
            <span>友链</span>
        </a>
        
    </nav>
</aside><main id="main">
        <a href="javascript:void(0)" id="closebtn" onclick="navToggle()"><i class="fas fa-bars fa-lg"></i></a>
        <div class="content">




<div class="section">
    <div class="section-title">recent</div>
    
    
    <div class="list-item">
        <a class="entry-title" href="/post/io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/">I/O多路复用</a>
        
        
        <p>操作系统I/O多路复用介绍</p>
        
        <div class="meta">
            
            <i class="far fa-calendar-alt"></i> 2021 Aug 22 15:30
            
            <br>
            
            <i class="fas fa-tags"></i>
            Tags: OS
            
        </div>
    </div>
    
    <div class="list-item">
        <a class="entry-title" href="/post/%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%8F%E8%AE%AEmesi/">缓存一致性协议MESI</a>
        
        
        <p>缓存一致性协议MESI介绍</p>
        
        <div class="meta">
            
            <i class="far fa-calendar-alt"></i> 2021 Aug 16 11:02
            
            <br>
            
            <i class="fas fa-tags"></i>
            Tags: OS
            
        </div>
    </div>
    
    <div class="list-item">
        <a class="entry-title" href="/post/mysql%E7%AC%94%E8%AE%B0/">MySQL笔记</a>
        
        
        <p>MySQL笔记</p>
        
        <div class="meta">
            
            <i class="far fa-calendar-alt"></i> 2021 Jun 21 20:33
            
            <br>
            
            <i class="fas fa-tags"></i>
            Tags: DBS
            
        </div>
    </div>
    
    <div class="list-item">
        <a class="entry-title" href="/post/csapp%E7%AC%94%E8%AE%B0/">CSAPP笔记</a>
        
        
        <p>CSAPP阅读笔记，一些操作系统中有的就不记了</p>
        
        <div class="meta">
            
            <i class="far fa-calendar-alt"></i> 2021 May 19 15:06
            
            <br>
            
            <i class="fas fa-tags"></i>
            Tags: OS
            
        </div>
    </div>
    
    <div class="list-item">
        <a class="entry-title" href="/post/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/">操作系统笔记</a>
        
        
        <p>操作系统笔记，方便查阅</p>
        
        <div class="meta">
            
            <i class="far fa-calendar-alt"></i> 2021 May 10 20:54
            
            <br>
            
            <i class="fas fa-tags"></i>
            Tags: OS
            
        </div>
    </div>
    
</div>



<div class="section">
    <div class="section-title">μblog</div>
    <div class="posts">
        
        
        <div class="post">
            
            <center>
                <h1><a href="/post/io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/">I/O多路复用</a></h1>
            </center>
            <div class="post-content">
                <h2 id="1-基本概念">1. 基本概念</h2>
<p>        操作系统<strong>内核</strong> ( $kernel$ ) 是操作系统的核心，独立于普通应用程序，可以访问受保护的内存空间，也有权访问所有底层硬件设备。为了保证用户进程不能直接操作内核，操作系统将内存空间划为两部分，内核空间和用户空间。对于<code>linux</code>系统，如果是 $32$ 位系统，虚拟内存中最高的 $1G$ 字节 ( $0xC0000000 \sim 0xFFFFFFFF$ ) 为内核空间；如果是 $64$ 位系统，指针的前 $16$ 位保留，从而只有 $48$ 位寻址空间，于是最高的 $128T$ 字节 ( $0x0000000000000000 \sim 0x00007FFFFFFFF000$ ) 作为系统空间，中间部分 ( $0x00007FFFFFFFFFFF \sim 0xFFFF800000000000$ ) 作为保留，其余部分为用户空间。<br>
        正在执行的进程由于某些期待的事件未发生，如资源请求失败或者等待某些操作完成等，会自动执行阻塞原语，使自己由运行态变为阻塞态。进程的阻塞是一种主动行为，只有处于运行态的进程才可以触发，并且阻塞后不占用<code>CPU</code>资源。<br>
        文件描述符 ( $fd$ ) 是一个指向文件引用的概念，在形式上是一个非负整数，实际上是一个索引值，指向内核打开文件表中的对应记录。打开文件表中记录了文件的属性，包括磁盘位置、访问权限、文件位置指针以及打开计数。<br>
        缓存<code>I/O</code>又称为标准<code>I/O</code>，大多数文件系统的默认<code>I/O</code>操作都是缓存<code>I/O</code>。在<code>Linux</code>中，操作系统会将<code>I/O</code>数据缓存在文件系统的 $Page\ \ Cache$ 中，即数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。<br>
        在<code>BIO</code>模式下，当线程接收一个请求后，在等待<code>I/O</code>的时间内，调用会被阻塞，无法接受其他请求。在多线程环境下，如果想要接受大量请求，就需要创建大量线程，占用大量系统空间，并且线程切换会带来很大的开销。$10000$ 个线程真正发生读写的实际的线程数不会超过 $20\%$ 。<br>
        在<code>NIO</code>模式下，当线程接收一个请求后，会加入 $fd_-set$ 集合，每次轮询集合接收数据，如果没有数据会返回错误。每次都要轮询所有集合，包括未发生实际读写的 $fd$ ，会浪费<code>CPU</code>资源。<br>
        在<code>I/O</code>多路复用模式下，服务端通过 $select$ / $poll$ / $epoll$ 等系统调用获取 $fd$ 列表，遍历有事件的 $fd$ 进行数据接收，可以支持更多并发连接请求。</p>
<ul>
<li><code>I/O</code>多路复用是一种同步<code>I/O</code>模型，多路指网络连接，复用指一个线程，即一个线程可以监视多个文件句柄；</li>
<li>一旦某个文件句柄就绪，就可以通知应用程序进行相应的读写操作；</li>
<li>没有文件句柄就会阻塞线程。</li>
</ul>
<h2 id="2-select">2. <code>select</code></h2>
<p>        $select$ 是仅仅知道了有<code>I/O</code>事件发生，但是无法确定是哪几个流 ( 一个或多个，甚至全部 )，只能无差别的轮询所有流，直到找出所有能读出或写入数据的流，具有 $O(n)$ 的无差别轮询复杂度。</p>
<ol>
<li>使用 $copy_-from_-user$ 从用户空间拷贝 $fd_-set$ 到内核空间；</li>
<li>注册回调函数 $\_\_pollwait$ ，负责将当前进程挂载到设备的等待队列中，在设备收到一条消息或者完成磁盘写入后，会唤醒等待队列上等待的进程；</li>
<li>遍历所有 $fd$ ，调用其对应的 $poll$ 方法，$poll$ 方法的核心就是 $\_\_pollwait$ ，返回一个描述读写操作是否完成的 $mask$ ，根据这个 $mask$ 给 $fd\_set$ 赋值；</li>
<li>如果遍历完所有的 $fd$ 还没有返回一个可读写的 $mask$ ，调用 $schedule_-timeout$ 使调用 $select$ 的进程睡眠；</li>
<li>设备驱动发现自身资源可读写后，唤醒等待队列上的进程。如果超过了 $schedule_-timeout$ 设定的时间，调用 $select$ 的进程会被重新唤醒，重新开始遍历；</li>
<li>把 $fd_-set$ 从内核空间拷贝回用户空间。</li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-c" data-lang="c"><span class="c1">// fd_set为数组，通过FD_SETSIZE定义
</span><span class="c1">// readfds、writefds和exceptfds分别对应读、写和异常条件fd
</span><span class="c1">// timeout为超时时间，select会一直阻塞到有事件到达或者等待时间超过timeout
</span><span class="c1"></span><span class="kt">int</span> <span class="nf">select</span><span class="p">(</span><span class="kt">int</span> <span class="n">nfds</span><span class="p">,</span> <span class="n">fd_set</span> <span class="o">*</span><span class="n">readfds</span><span class="p">,</span> <span class="n">fd_set</span> <span class="o">*</span><span class="n">writefds</span><span class="p">,</span> <span class="n">fd_set</span> <span class="o">*</span><span class="n">exceptfds</span><span class="p">,</span> <span class="k">struct</span> <span class="n">timeval</span> <span class="o">*</span><span class="n">timeout</span><span class="p">);</span>
</code></pre></div><p>        $select$ 本质上是通过设置或者检查存放 $fd$ 标志位的数据结构来进行下一步处理，缺点是：</p>
<ul>
<li>单个进程打开的 $fd$ 是有上限的，通过 $FD_-SETSIZE$ 设置，默认为 $1024$ ；</li>
<li>每次调用 $select$ 都需要把 $fd$ 集合从用户空间拷贝到内核空间；</li>
<li>采用轮询方式进行线性扫描，效率较低。</li>
</ul>
<h2 id="4-poll">4. <code>poll</code></h2>
<p>        $poll$ 本质和 $select$ 一样，也是将 $fd$ 拷贝到内核空间并轮询设备状态，但是没有最大连接数的限制。与 $select$ 的不同之处在于：</p>
<ul>
<li>$select$ 会修改 $fd$ ，$poll$ 不会；</li>
<li>$select$ 的 $fds$ 使用标志位，有数量限制；$poll$ 没有数量限制；</li>
<li>$select$ 会检测每个<code>bit</code>位，无论有没有 $fd$ ；$poll$ 检测数组，效率更高；</li>
<li>$poll$ 提供了更多的事件类型，对 $fd$ 的重复利用比 $select$ 高；</li>
<li>如果一个线程对某个 $fd$ 调用了 $select$ 或者 $poll$ ，另一个线程关闭了该 $fd$ ，会导致结果不确定。</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-c" data-lang="c"><span class="k">struct</span> <span class="n">pollfd</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">fd</span><span class="p">;</span>

    <span class="c1">// 期待事件
</span><span class="c1"></span>    <span class="kt">short</span> <span class="n">events</span><span class="p">;</span>

    <span class="c1">// 监听到的事件
</span><span class="c1"></span>    <span class="kt">short</span> <span class="n">revents</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="n">poll</span><span class="p">(</span><span class="k">struct</span> <span class="n">pollfd</span> <span class="o">*</span><span class="n">fds</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">nfds</span><span class="p">,</span> <span class="kt">int</span> <span class="n">timeout</span><span class="p">);</span>
</code></pre></div><p>        缺点是：</p>
<ul>
<li>每次调用都需要把 $fd$ 集合从用户空间拷贝到内核空间；</li>
<li>采用轮询方式进行线性扫描，效率较低。</li>
</ul>
<h2 id="5-epoll">5. <code>epoll</code></h2>
<p>        $epoll$ 可以理解为 $event\ \ poll$ ，不同于忙轮询和无差别轮询，每个流发生了怎样的<code>I/O</code>事件都会通知 $epoll$ ，也就是说 $epoll$ 是事件驱动的，从而将复杂度降低到了 $O(1)$ 。<br>
        当进程调用 $epoll_-create$ 时，<code>Linux</code>内核会创建 $eventpoll$ 结构体，如下：</p>
<div class="highlight"><pre class="chroma"><code class="language-c" data-lang="c"><span class="cp">#include</span> <span class="cpf">&lt;sys/epoll.h&gt;</span><span class="cp">
</span><span class="cp"></span>
<span class="c1">// 每个epoll对象都有一个独立的eventpoll结构体
</span><span class="c1"></span><span class="k">struct</span> <span class="n">eventpoll</span> <span class="p">{</span>
    <span class="c1">// 红黑树根节点，存储所有事件
</span><span class="c1"></span>    <span class="k">struct</span> <span class="n">rb_root</span> <span class="n">rbr</span><span class="p">;</span>

    <span class="c1">// 双链表存储发生事件
</span><span class="c1"></span>    <span class="k">struct</span> <span class="n">list_head</span> <span class="n">rdlist</span><span class="p">;</span>
<span class="p">}</span>

<span class="c1">// 创建epoll对象
</span><span class="c1"></span><span class="kt">int</span> <span class="n">epoll_create</span><span class="p">(</span><span class="kt">int</span> <span class="n">size</span><span class="p">);</span>

<span class="c1">// 添加/删除事件
</span><span class="c1"></span><span class="kt">int</span> <span class="nf">epoll_ctl</span><span class="p">(</span><span class="kt">int</span> <span class="n">epfd</span><span class="p">,</span> <span class="kt">int</span> <span class="n">op</span><span class="p">,</span> <span class="kt">int</span> <span class="n">fd</span><span class="p">,</span> <span class="k">struct</span> <span class="n">epoll_event</span> <span class="o">*</span><span class="n">event</span><span class="p">);</span>

<span class="c1">// 检查事件集合，没有可读流则阻塞进程
</span><span class="c1"></span><span class="kt">int</span> <span class="nf">epoll_wait</span><span class="p">(</span><span class="kt">int</span> <span class="n">epfd</span><span class="p">,</span> <span class="k">struct</span> <span class="n">epoll_event</span> <span class="o">*</span><span class="n">events</span><span class="p">,</span> <span class="kt">int</span> <span class="n">maxevents</span><span class="p">,</span> <span class="kt">int</span> <span class="n">timeout</span><span class="p">);</span>

<span class="c1">// 事件结构
</span><span class="c1"></span><span class="k">struct</span> <span class="n">epitem</span> <span class="p">{</span>
    <span class="c1">// 红黑树节点
</span><span class="c1"></span>    <span class="k">struct</span> <span class="n">rb_node</span> <span class="n">rbn</span><span class="p">;</span>

    <span class="c1">// 双向链表节点
</span><span class="c1"></span>    <span class="k">struct</span> <span class="n">list_head</span> <span class="n">rdllink</span><span class="p">;</span>

    <span class="c1">// 事件句柄
</span><span class="c1"></span>    <span class="k">struct</span> <span class="n">epoll_filefd</span> <span class="n">ffd</span><span class="p">;</span>

    <span class="c1">// 所属eventpoll对象
</span><span class="c1"></span>    <span class="k">struct</span> <span class="n">eventpoll</span> <span class="o">*</span><span class="n">ep</span><span class="p">;</span>

    <span class="c1">// 期待发生的事件类型
</span><span class="c1"></span>    <span class="k">struct</span> <span class="n">epoll_event</span> <span class="n">event</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div><p>        通过 $epoll_-ctl$ 向 $eventpoll$ 对象中添加的事件都会存储在红黑树中，红黑树的高效性保证了重复事件可以被快速识别出来。所有添加到了 $epoll$ 的事件都会与设备 ( 网卡 ) 驱动程序建立回调关系，当相应事件发生时就会回调 $ep_-poll_-callback$ ，将发生的事件添加到双链表中。$epoll_-wait$ 检查是否有事件发生，即链表是否存在节点，如果存在，则复制回用户空间，并返回事件数量。<br>
        $epoll$ 的优点有：</p>
<ul>
<li>不限制并发连接上限 ( $1G$ 内存上能监听 $10$ 万个端口 )；</li>
<li>非轮询，效率高；</li>
<li>利用 $mmap(\ )$ 的将内核空间的一段区域映射到用户空间，不需要拷贝。</li>
</ul>
<p>        $epoll$ 有 $EPOLLLT$ 和 $EPOLLET$ 两种触发模式，$LT$ ( $level-triggered$ ) 是默认模式，$ET$ ( $edge-triggered$ ) 是高速模式。</p>
<ul>
<li>$LT$ ：只要 $fd$ 还有数据可读，每次 $epoll_wait$ 都会返回该事件，即每次触发；</li>
<li>$ET$ ：每个 $fd$ 只会返回一次事件，直到下次有数据流入，即数据到来触发。</li>
</ul>
<h2 id="6-应用场景">6. 应用场景</h2>
<h3 id="61-对比">6.1 对比</h3>
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">$select$</th>
<th style="text-align:center">$poll$</th>
<th style="text-align:center">$epoll$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">方式</td>
<td style="text-align:center">轮询</td>
<td style="text-align:center">轮询</td>
<td style="text-align:center">回调</td>
</tr>
<tr>
<td style="text-align:center">数据结构</td>
<td style="text-align:center">$bitmap$</td>
<td style="text-align:center">数组</td>
<td style="text-align:center">红黑树</td>
</tr>
<tr>
<td style="text-align:center">最大连接数</td>
<td style="text-align:center">$1024$ ( $x86$ )/ $2048$ ( $x64$ )</td>
<td style="text-align:center">无上限</td>
<td style="text-align:center">无上限</td>
</tr>
<tr>
<td style="text-align:center">拷贝</td>
<td style="text-align:center">每次调用都需要进行拷贝</td>
<td style="text-align:center">每次调用都需要进行拷贝</td>
<td style="text-align:center">内核空间和用户空间共享一块内存</td>
</tr>
<tr>
<td style="text-align:center">工作模式</td>
<td style="text-align:center">$LT$</td>
<td style="text-align:center">$LT$</td>
<td style="text-align:center">$LT$ / $ET$</td>
</tr>
<tr>
<td style="text-align:center">复杂度</td>
<td style="text-align:center">$O(n)$</td>
<td style="text-align:center">$O(n)$</td>
<td style="text-align:center">$O(1)$</td>
</tr>
</tbody>
</table>
<ul>
<li>$select$ 应用场景
<ul>
<li>$timeout$ 参数精度为微妙，$poll$ 和 $epoll$ 为毫秒，更适用于对实时性要求高的场景；</li>
<li>几乎所有主流平台都支持 $select$ ，移植性更好；</li>
</ul>
</li>
<li>$poll$ 应用场景
<ul>
<li>没有 $fd$ 数量限制，如果没有实时性要求，应该使用 $poll$ ；</li>
</ul>
</li>
<li>$epoll$ 应用场景
<ul>
<li>只能运行在<code>Linux</code>上，如果存在大量 $fd$ ，并且都是长连接，应该使用 $epoll$ ；</li>
<li>如果需要同时监控的 $fd$ 小于 $1000$ 个，就没必要使用 $epoll$ ，连接数量较少的场景无法体现 $epoll$ 的优势；</li>
<li>如果连接数量很多，但都是短连接，也没必要使用 $epoll$ ，因为 $epoll$ 的所有 $fd$ 都存储在内核空间，频繁调用 $epoll_-ctl(\ )$ 改变状态会导致过多的系统调用，降低效率；</li>
<li>$epoll$ 的 $fd$ 存储在内核空间，不利于调试。</li>
</ul>
</li>
</ul>
<h3 id="62-nginx">6.2 <code>Nginx</code></h3>
<p>        <code>Nginx</code>支持多种并发模型，具体实现根据系统平台而有所不同，在支持多种并发模型的平台上会自动选择最高效的模型，也可以通过 $use$ 指令在配置文件中显示指定。</p>
<h3 id="63-redis">6.3 <code>Redis</code></h3>
<p>        <code>Redis</code>采用<code>I/O</code>多路复用保证在多连接时候的吞吐量，主要是基于 $epoll$ 实现的，也提供了 $select$ 和 $kqueue$ 实现，默认采用 $epoll$ 。</p>

            </div>
            <div class="meta post-footer"> <span>2021 Aug 22 15:30</span> <a href="/post/io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/"><i
                        class="fas fa-link"></i> link</a></div>
        </div>
        
        <div class="post">
            
            <center>
                <h1><a href="/post/%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%8F%E8%AE%AEmesi/">缓存一致性协议MESI</a></h1>
            </center>
            <div class="post-content">
                <p>        <strong>高速缓冲存储器一致性</strong> ( $Cache\ \ coherence$ )，也称缓存一致性，是指在采用层次结构存储系统的计算机系统中，保证告诉缓冲存储器中数据与主存储器中数据相同的机制。在有多个<code>CPU</code>的多处理机系统中特别容易出现高速缓存中数据不一致的问题。<br>
        在<code>CPU</code>缓存设计中，<code>L1</code>高速缓存包含指令缓存和数据缓存，位于<code>CPU</code>芯片上，访问速度几乎和寄存器一样快。<code>L2</code>高速缓存在<code>L1</code>和主存之间，连接到存储器总线或者高速缓存总线上。有些高性能系统还会在存储器总线上设置<code>L3</code>高速缓存。<code>L1</code>和<code>L2</code>是每个<code>CPU</code>内核间独立的，<code>L3</code>是所有<code>CPU</code>内核间共享的。<br>
        对于单核<code>CPU</code>来说，数据更新时缓存更新只用考虑自己的就行了，主要有两种处理方法。<strong>写回法</strong> ( $write\ \ back$ )，是当处理器执行写操作时，信息只写入<code>cache</code>，当<code>cache</code>中的数据被替换出去时写回主存。为了减少内存写操作，<code>cache</code>中通常还会设置一个脏位 ( $dirty\ \ bit$ )，标识该块在被载入后是否发生了更新。<strong>直写法</strong> ( $write\ \ through$ ) 是当处理器执行写操作时，既向<code>cache</code>中写入也向主存中写入。直写法会造成大量写内存操作，需要设置一个缓冲来减少硬件冲突，称为写缓冲器 ( $write\ \ buffer$ )，通常不超过 $4$ 个缓存块的大小，也适用于写回法。<br>
        相比于单核<code>CPU</code>，多核<code>CPU</code>除了要保证<code>L1</code>和<code>L2</code>最新外还要考虑到其他核中<code>L1</code>和<code>L2</code>的实时性和有效性。<code>MESI</code>协议是一个基于失效的缓存一致性协议，是支持写回缓存的最常用协议。该协议对总线上的操作进行监听，即核 $A$ 可以窥探到核 $B$ 对过期值的读操作，并更新主存中的过期值。<code>MESI</code>把<code>cache</code>中的数据分为几个状态：</p>
<table>
<thead>
<tr>
<th style="text-align:center">状态</th>
<th style="text-align:center">描述</th>
<th style="text-align:center">监听</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$Invalid$</td>
<td style="text-align:center">该<code>cache</code>字段失效</td>
<td style="text-align:center">无</td>
</tr>
<tr>
<td style="text-align:center">$Shared$</td>
<td style="text-align:center">字段数据一致并且多核<code>cache</code>共享该字段</td>
<td style="text-align:center">监听其他缓存使该字段无效或者变为 $Exclusive$ 的请求，监听到对应事件后会将该字段设为 $Invalid$</td>
</tr>
<tr>
<td style="text-align:center">$Exclusive$</td>
<td style="text-align:center">字段数据一致并且只在当前核<code>cache</code>中独有</td>
<td style="text-align:center">监听其他缓存读主存中该字段的操作，监听到对应事件后将该字段变为 $Shared$</td>
</tr>
<tr>
<td style="text-align:center">$Modified$</td>
<td style="text-align:center">该字段有效但是与主存不一致，只存在于当前核<code>cache</code>中</td>
<td style="text-align:center">监听所有试图读该字段对应主存字段的操作，该操作会被延迟到当前缓存字段写回主存并将状态设为 $Shared$ 之后执行</td>
</tr>
</tbody>
</table>
<p><img src="/image/2021-08-16-01.png" alt="状态机"></p>
<table>
<thead>
<tr>
<th style="text-align:center">事件</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$Local\ \ Read$</td>
<td style="text-align:center">读取本地<code>cache</code>字段</td>
</tr>
<tr>
<td style="text-align:center">$Local\ \ Write$</td>
<td style="text-align:center">写入本地<code>cache</code>字段</td>
</tr>
<tr>
<td style="text-align:center">$Remote\ \ Read$</td>
<td style="text-align:center">其他<code>cache</code>读取字段</td>
</tr>
<tr>
<td style="text-align:center">$Remote\ \ Write$</td>
<td style="text-align:center">其他<code>cache</code>写入字段</td>
</tr>
</tbody>
</table>
<p>        对于 $Modified$ 和 $Exclusive$
状态，数据是精确的，而 $Shared$ 状态可能是非一致的。如果一个处于 $Shared$ 的缓存字段作废了，另一个缓存实际上可能已经独享了该缓存字段，但是该缓存不会转为 $Exclusive$
，因为其他缓存并不会广播他们作废该缓存字段的通知。如果一个<code>CPU</code>想修改一个处于 $Shared$ 状态的缓存字段，总线事务需要将所有该缓存字段的副本变为 $Invalid$ 状态，而修改 $Exclusive$ 状态的缓存字段不需要总线事务。<br>
        缓存的一致性消息传递是需要时间的，这就使其切换时产生延迟。当一个缓存被切换状态时其他缓存收到消息完成各自的切换并且发出回应消息这么长一段时间中<code>CPU</code>都会等待所有缓存响应完成。为了避免这种<code>CPU</code>运算能力的浪费，$Store\ \ Buffer$ 被引入。处理器会将想要写入主存的值写到 $Store\ \ Buffer$ 中再去处理其他事情。为了避免在 $Store\ \ Buffer$ 未保存完时其他核已经完成读取，需要引入内存屏障。写屏障保证处理器在更新数据前必须将所有 $Store\ \ Buffer$ 中的指令执行完毕，读屏障保证处理器在读之前将所有需要设置为 $Invalid$ 的字段设置完毕。</p>

            </div>
            <div class="meta post-footer"> <span>2021 Aug 16 11:02</span> <a href="/post/%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%8F%E8%AE%AEmesi/"><i
                        class="fas fa-link"></i> link</a></div>
        </div>
        
        <div class="post">
            
            <center>
                <h1><a href="/post/mysql%E7%AC%94%E8%AE%B0/">MySQL笔记</a></h1>
            </center>
            <div class="post-content">
                <h2 id="1-架构">1. 架构</h2>
<p>        大体来说，<code>MySQL</code>可以分为<code>Server</code>层和存储引擎层两部分。<code>Server</code>层包括连接器、查询缓存、分析器、优化器、执行器等，以及所有的内置函数，所有跨存储引擎功能都在这一层实现。而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持<code>InnoDB</code>、<code>MyISAM</code>、<code>Memory</code>等多个引擎。不同的存储引擎共用一个<code>Server</code>层，也就是从连接器到执行器的部分。</p>
<ul>
<li>连接器：连接器负责跟客户端建立连接、获取权限、维持和管理连接。数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接。建立连接的过程通常比较复杂，所以应尽量使用长连接。但是全部使用长连接后，有时候<code>MySQL</code>内存占用会很高，因为<code>MySQL</code>在执行过程中临时使用的内存是在连接对象里的，只有在断开连接时才释放。</li>
<li>查询缓存：<code>MySQL</code>会在执行语句之前先在查询缓存中查询。但是查询缓存的失效很频繁，只要有一个表更新，表上所有缓存都会失效。对于更新压力大的数据库来讲，命中率会很低。<code>MySQL</code>在 $8.0$ 版本移除了查询缓存功能。</li>
<li>分析器：分析器会对语句做语法分析，判断语句是否存在错误，同时理解语句要执行的操作。</li>
<li>优化器：优化器是在表中存在多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联时，决定表的连接顺序。</li>
<li>执行器：在开始执行之前，会检查是否对表具有查询权限。如果有权限，就打开表执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。</li>
</ul>
<p>        一个<code>InnoDB</code>表包含两个部分，即表结构定义和数据。表结构定义的占用空间很小，在<code>MySQL 8.0</code>版本以前，表结构是存在以 $.frm$ 为后缀的文件里，而<code>MySQL 8.0</code>版本已经允许把表结构定义放在系统数据表中了。表数据既可放在共享表空间里，也可以是单独的文件，从<code>MySQL 5.6.6</code>开始，默认是存储在一个以 $.ibd$ 为后缀的文件中的。对于放在共享表空间中的表，即使通过 $DROP$ 命令删除后，空间也不会回收。在删除的过程中，<code>InnoDB</code>会查找聚簇索引，将对应的记录标记为删除，而不是真正删除，目的是为以后插入新数据时的复用。记录的复用与数据页的复用不同，记录的复用只允许对应范围的新记录复用，而如果删除整个数据页后，数据页的复用可以允许复用到任何位置。如果相邻的两个数据页的利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另一个数据页就被标记为可复用。<br>
        重建表即将原来表的记录读取出来，一行一行地插入到新表中。原来的表在删除和插入时会产生很多空洞，数据利用率不高，而重建表就可以解决这个问题。<code>MySQL 5.6</code>引入了 $Online\ \ DDL$ ，会先建立一个临时文件，保存原来表中的聚簇索引。在建立临时文件的过程中，在之后对原表的操作会被记录到日志文件中，并在临时文件建立完成后重新应用到临时文件中，从而允许重建表过程中的读写。<br>
        在不同的引擎中，$COUNT(*)$ 有不同的实现方式，<code>MyISAM</code>把表的行数存在了磁盘上，可以直接返回；<code>InnoDB</code>会把数据一行一行地读出来然后计数。由于<code>MVCC</code>的存在，在某个时间段表有多少行是不确定的，因此<code>InnoDB</code>并不能简单地将行数存起来。<code>MySQL</code>对此的优化策略是，如果表存在多个索引，那么会选择较小的一颗索引树进行扫描。<br>
        <code>MySQL</code>会给每个线程分配一块内存用于排序，称为 $sort_-buffer$。在 $sort_-buffer$ 里面的字段，会每次从数据库中取出数据并存到里面。当取出所有数据后再进行快速排序，如果内存空间不足，会使用外部排序。如果单行长度超过排序的最大长度，那么会将要排序的字段与<code>ID</code>关联，在排序完成后再通过<code>ID</code>回查。如果现有索引覆盖了需要排序的字段，那么会直接使用索引。对于使用聚集函数的排序，<code>MySQL</code>可能会使用临时表。临时表默认是在内存中的，如果超过了内存临时表的大小，就会转成磁盘临时表。<br>
        内存表指的是使用<code>Memory</code>引擎的表，这种表的数据都保存在内存里，系统重启的时候会被清空，但是表结构还在。临时表可以使用各种引擎类型，如果是使用<code>InnoDB</code>或者<code>MyISAM</code>引擎的临时表，写数据的时候是写到磁盘上的。一个临时表只能被创建它的 $session$ 访问，可以与普通表同名。</p>
<h2 id="2-日志">2. 日志</h2>
<p>        更新语句的执行过程其实与查询语句一样，但是会涉及日志模块。<br>
        <code>redo log</code>记录将要修改的记录，使用了<code>WAL</code> ( $Write-Ahead\ \ Logging$ ) 技术，即先写日志，再写磁盘。当有一条记录需要更新时，<code>InnoDB</code>会先把记录写到<code>redo log</code>中，并更新内存，之后在适当的时候，将这个操作记录更新到磁盘中，往往是在磁盘比较空闲的时候。<br>
        <code>InnoDB</code>的<code>redo log</code>是固定大小的，写到末尾时就循环回到开头重新写。$write\ \ pos$ 是当前记录的位置，随着数据写入后移。$check\ \ point$ 是当前要擦除的位置，在擦除之前要把记录更新到数据文件。$write\ \ pos$ 和 $check\ \ point$ 之间的部分可以记录新的操作。如果之间没有空白部分，需要等待执行记录。<br>
        <code>InnoDB</code>通过<code>redo log</code>，可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，称为 $crash-safe$ 。<br>
        <code>binlog</code>与<code>redo log</code>的区别有：</p>
<ol>
<li><code>redo log</code>是<code>InnoDB</code>特有的，<code>binlog</code>是<code>MySQL</code>的<code>Server</code>层实现的；</li>
<li><code>redo log</code>是物理日志，记录对某个数据页的修改；<code>binlog</code>是逻辑日志，记录语句的原始逻辑；</li>
<li><code>redo log</code>是循环写入的，<code>binlog</code>是可以追加写入的，即当文件达到一定空间后切换到下一个文件。</li>
</ol>
<p>        每当引擎将新数据更新到内存中时，就会把更新操作记录到<code>redo log</code>中，此时<code>redo log</code>处于 $prepare$ 状态。当执行器执行完成后，会生成操作的<code>binlog</code>。当事务提交之后，引擎会把刚写入的<code>redo log</code>改成 $commit$ 状态，完成更新。<br>
        写<code>redo log</code>的时候，可以通过 $innodb_-flush_-log_-at_-trx_-commit$ 参数设置：</p>
<ul>
<li>该值为 $0$ 时，事务提交时只是把<code>redo log</code>留在 $redo\ \ log\ \ buffer$ 中；</li>
<li>该值为 $1$ 时，每次事务提交都会把数据同步到磁盘上；</li>
<li>该值为 $2$ 时，在事务提交时只做写到 $page\ \ cache$ 。</li>
</ul>
<p>        <code>InnoDB</code>后台有一个线程，每隔 $1$ 秒，就会把 $redo\ \ log\ \ buffer$ 中的日志调用 $write$ 写到 $page\ \ cache$ 中，然后调用 $fsync$ 持久化到磁盘。事务执行中间过程的<code>redo log</code>也是直接写在 $redo\ \ log\ \ buffer$ 中的，也就是说，一个没有提交的事务也是可能已经持久化到磁盘的。<br>
        <code>binlog</code>会记录所有的逻辑操作，如果要恢复到以前的某个状态，可以通过取出<code>binlog</code>并重放操作。<code>binlog</code>的写入逻辑是先写到 $binlog\ \ cache$ ，在事务提交的时候清空 $binlog\ \ cache$ 并写到<code>binlog</code>文件中。事务的<code>binlog</code>不能拆开，要保证一次性写入。每个线程都有自己的 $binlog\ \  cache$ ，但是共用同一份<code>binlog</code>。通过参数 $sync_-binlog$ 控制写磁盘方式：</p>
<ul>
<li>该值为 $0$ 时，每次提交都会写到 $page\ \ cache$ ，不会写到磁盘；</li>
<li>该值为 $1$ 时，每次提交都会写到磁盘；</li>
<li>该值为 $N$ 时，每次提交都会写到 $page\ \ cache$ ，累计 $N$ 次后写到磁盘。</li>
</ul>
<p>        <code>redo log</code>和<code>binlog</code>是两个独立的逻辑，如果不使用两阶段提交，要么就是写完<code>redo log</code>再写<code>binlog</code>，或者反过来，但这会带来问题：</p>
<ul>
<li>先写<code>redo log</code>再写<code>binlog</code>。假设在<code>redo log</code>写完，<code>binlog</code>还没有写完时出现异常重启，那么<code>binlog</code>中会缺少对应数据，从而在之后备份恢复时缺少数据；</li>
<li>先写<code>binlog</code>再写<code>redo log</code>。如果在<code>binlog</code>写完后出现异常，那么由于<code>redo log</code>没写，事务无效，从而在之后备份恢复时多出新事务。</li>
</ul>
<p>        <code>binlog</code>存在三种格式：$statement$ 、$row$ 和 $mixed$ 。$statement$ 格式会记录操作的语句，$row$ 格式会记录操作的行，$mixed$ 格式则由<code>MySQL</code>自己判断是使用 $statement$ 还是 $row$ 。<br>
        在更新方面，<code>MySQL</code>引入 $change\ \ buffer$ 的概念。当需要更新一个数据页时，如果数据页在内存中就会直接更新，如果不在内存中，在不影响一致性的前提下，<code>InnoDB</code>会将更新操作缓存在 $change\ \ buffer$ 中，在下次查询访问改数据页时进行更新。$change\ \ buffer$ 是可持久化的数据，既在内存中有拷贝，也会被写到磁盘上。将 $change\ \ buffer$ 中的操作应用到原数据页的操作称为 $merge$ ，除了访问数据页外，系统也会有后台线程定期进行 $merge$ ，在数据库正常关闭的过程中，也会执行 $merge$ 。<br>
        $change\ \ buffer$ 和<code>redo log</code>的关系在于，$change\ \ buffer$ 中所做的更改会被写入到<code>redo log</code>当中，也就是<code>redo log</code>的记录先于 $change\ \ buffer$ 写入。<code>redo log</code>的目的是减少随机写磁盘的<code>I/O</code>消耗，即转换成顺序写；$change\ \ buffer$ 的目的是节省随机读磁盘的<code>I/O</code>消耗，如果数据在内存中，那么被更改后的数据可以直接从内存中获得。<br>
        当内存数据页与磁盘数据页内容不一致时，内存页就被称为脏页。在内存页被写入磁盘后，数据就一致了，这时内存页就是干净页。在<code>MySQL</code>查询的过程中，有时候会抖动一下，就是在刷脏页 ( $flush$ ) 的过程。引发 $flush$ 的情况有：<code>redo log</code>写满、系统内存不足需要淘汰脏页、系统空闲自动更新、<code>MySQL</code>正常关闭。一般情况下，$flush$ 都是由于系统内存不足导致的。<code>InnoDB</code>使用缓冲池 ( $buffer\ \ pool$ ) 管理内存，使用策略是尽量使用内存，因此对于一个长时间执行的数据库来说，未被使用的页面很少。当要读入的数据页不在内存时，就必须到缓冲池中申请数据页，即淘汰页面。<code>InnoDB</code>会控制一个脏页比例，以避免一次要淘汰过多的脏页。在默认情况下，如果<code>MySQL</code>在刷一个脏页的时候发现其相邻的下一个页面也是脏页，那么就会顺带刷掉，这种连坐机制可以很好的利用顺序<code>I/O</code>，减少随机<code>I/O</code> ( 在<code>MySQL 8.0</code>中默认不开启 ) 。<br>
        <code>InnoDB</code>的内存管理使用的是<code>LRU</code>算法，用链表实现。因为数据库经常会有全表读或者大范围扫描的需求，如果直接采用<code>LRU</code>，当我们对一些使用不太频繁的大表进行全表扫描，一段时间之后，$buffer\ \ pool$ 的命中率会明显下降。实际上，<code>InnoDB</code>对<code>LRU</code>算法做了改进，按照 $5:3$ 的比例把整个<code>LRU</code>链表分成了 $young$ 区域和 $old$ 区域，即靠近链表头部的 $\large\frac{5}{8}$ 是 $young$ 区域，靠近链表尾部的 $\large\frac{3}{8}$ 是 $old$ 区域。每次访问一个不存在于当前链表的数据页，依然淘汰链表尾部的数据页，新插入的数据页会放在 $old$ 区域的头部，并且在 $1$ 秒内对这个数据页的访问不会移动该数据页 ( 可以通过 $innodb_-old_-blocks_-time$ 控制 )。如果超过了 $1$ 秒，就会把它移到整个链表的头部。</p>
<h2 id="3-事务">3. 事务</h2>
<p>        当数据库上有多个事务同时执行的时候，就可能出现脏读 ( $dirty\ \ read$ )、不可重复读 ( $non-repeatable\ \ read$ )、幻读 ( $phantom\ \ read$ ) 的问题。</p>
<ul>
<li>未提交读。一个事务所做的变更在未提交时就能被其他事务看到。</li>
<li>提交读。一个事务所做的变更在提交后才能被其他事务看到。</li>
<li>可重复读。一个事务执行过程中看到的数据总是与事务启动时看到的数据一致。</li>
<li>串行化。对读写进行加锁，当出现读写冲突时，后一个事务必须等待前一个事务执行完成。</li>
</ul>
<p>        在实现上，数据库会创建一个视图，访问的时候以视图的逻辑结果为准。在可重复读的隔离级别下，这个视图在事务启动时创建，并且在整个事务的过程中一直使用。在提交读的隔离级别下，视图会在每个<code>SQL</code>语句开始执行时创建。<br>
        在<code>MySQL</code>中，每条记录在更新时都会记录一条回滚操作，即<code>undo log</code>，记录上的最新值通过回滚操作都可以得到前一个状态的值。在回滚段中的日志分为 $insert\ \ undo\ \ log$ 和 $update\ \ undo\ \ log$ ，前者是 $INSERT$ 时产生的，在事务提交后就可以丢弃；后者是 $DELETE$ 和 $UPDATE$ 时产生的，不仅在事务回滚时需要，一致性读也需要，只有当数据库所使用的视图中不存在比回滚日志更早的读视图时才会被删除，因此长事务的存在会导致日志长时间存在，占用大量存储空间。<br>
        <code>InnoDB</code>里面每个事务都有一个唯一的事务<code>ID</code> ( $trasaction\ \ id$ )，在事务开始时向<code>InnoDB</code>事务系统申请，按照申请顺序严格递增。每行数据都会对应一个事务版本，每次事务更新数据时都会把事务<code>ID</code>赋给这个数据作为版本，记为 $row\ \ trx_-id$ 。同时，旧的数据版本会被保留。在<code>undo log</code>中记录的每条数据都会有一个指向上一个版本数据的指针，每当需要获取之前某个版本的数据时，就会通过最新版本进行访问。<br>
        <code>InnoDB</code>存储引擎在数据库每行数据的后面添加了三个字段：</p>
<ul>
<li>$6$ 字节的事务<code>ID</code> ( $row\ \ trx_-id$ ) ：标识最近一次对本行记录做修改 ( $INSERT$ / $UPDATE$ ) 的事务的标识符，即最后一次修改本行记录的事务<code>ID</code>；</li>
<li>$7$ 字节的回滚指针字段：写入<code>undo log</code>中的记录指针；</li>
<li>$6$ 字节的 $row_-id$ 字段：包含一个随着新行插入而单调递增的 $row_-id$ ，如果表中没有指定主键或者唯一索引，<code>InnoDB</code>会使用该行的值作为主键生成聚簇索引。如果指定了主键或者唯一索引，聚簇索引中就不会包含该行数据。</li>
</ul>
<p>        在视图的实现上，<code>InnoDB</code>为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在活跃的所有事务<code>ID</code>。数组里面事务<code>ID</code>的最小值记为低水位，当前系统里面已经创建过的事务<code>ID</code>的最大值加 $1$ 记为高水位。这个视图数组和高水位，就组成了当前事务的一致性视图 ( $read-view$ )。对于当前事务的启动瞬间来说，一个数据版本 $row\ \ trx_-id$ ，有以下几种可能：</p>
<ul>
<li>如果小于低水位，代表这个版本是已提交事务或者是当前事务自己生成的，是可见的；</li>
<li>如果大于高水位，表示这个版本是由将来启动的事务生成的，是不可见的；</li>
<li>如果介于低水位和高水位之间，存在两种情况：
<ul>
<li>如果 $row\ \ trx_-id$ 在数组中，表示这个版本是由未提交的事务生成的，不可见；</li>
<li>如果 $row\ \ trx_-id$ 不在数组中，表示这个版本是由已提交的事务生成的，可见。</li>
</ul>
</li>
</ul>
<p>        此外，对于更新语句会有特殊情况。更新数据都是先读后写的，读只能读到当前值，称为当前读 ( $current\ \ read$ )。在更新的过程中会对要更新的数据进行加锁，因此如果存在多个事务对同一个数据进行更新，那么需要先获取锁。而如果对 $select$ 语句进行加锁的话，也是当前读。<br>
        幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的，因此幻读在提交读下才会出现。为了解决幻读问题，<code>InnoDB</code>引入了间隙锁 ( $Gap\ \ Lock$ )。间隙锁和行锁合称 $next-key\ \ lock$，每个 $next-key\ \ lock$ 是前开后闭区间。对同个区间的多个间隙锁不会冲突，这会导致一个区间可能会被多个<code>session</code>加锁，从而造成死锁。</p>
<h2 id="4-索引">4. 索引</h2>
<p>        三种常见的索引：哈希表、有序数组和搜索树。<br>
        哈希表是一种以键值对方式存储数据的结构，只适用于等值查询，当出现哈希碰撞时采用拉链法解决。有序数组采用递增顺序存储索引数据，但是只适用于静态存储引擎，因为在数组中插入和删除数据的代价很大。<br>
        <code>InnoDB</code>采用<code>B+</code>树作为索引。在<code>InnoDB</code>中，表都是根据主键顺序以索引的形式存放的，这种存储方式称为索引组织表。主键索引的叶子节点存储整行数据，也被称为聚簇索引 ( $clustered\ \ index$ )。非主键索引的叶子结点存储主键值，也被称为二级索引 ( $secondary\ \ index$ )。也就是说，基于非主键索引的查询需要多扫描一次索引树。<br>
        为了维护索引的有序性，在插入和删除的时候索引可能需要分裂或者合并。对于自增主键，由于可以保证上一条数据的主键值小于下一条数据，因此不会挪动其他记录。而有业务逻辑的字段做主键，往往不容易保证有序插入，成本相对较高。<br>
        最左前缀原则可以用于在索引中定位记录。但是对于不满足最左前缀原则的条件，<code>MySQL 5.6</code>引入了索引下推优化 ( $index\ \ condition\ \ pushdown$ )，可以在索引遍历的过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。<br>
        唯一索引保证了每条数据在表中只会出现一次，主键默认是唯一的。与普通索引相比，唯一索引在查询方面的性能相差几乎没有，因为<code>InnoDB</code>以页为单位读取数据，而大部分情况下普通索引相比于唯一索引仅仅多做了一次查询而已。对于唯一索引来说，所有的更新操作都要先判断是否违反唯一性约束，如果数据页不在内存中，会要求将数据页读入内存，而这时无法使用 $change\ \ buffer$ ；相比之下，普通索引可以用到 $change\ \ buffer$ 。如果要更新的页面存在于内存中，那么唯一索引和普通索引的更新时间几乎没有区别；但是如果不在内存中，唯一索引会要求将数据页读入内存中，这时唯一索引比起普通索引来讲性能就会差很多。<br>
        <code>MySQL</code>在执行语句之前无法精确的知道满足这个条件的记录有多少条，只能根据统计信息来估算记录数，这个统计信息就是区分度。一个索引上不同的值越多，这个索引的区分度就越好。一个索引上不同值的个数称为基数 ( $cardinality$ )。<code>MySQL</code>通过采样统计获取索引的基数，默认选择 $N$ 个数据页，统计页面上不同值得到平均值，然后乘以这个索引的页面值，从而得到基数。当变更的数据行数超过 $1/M$ 的时候，就会自动触发一次索引统计。对于持久化的索引统计，$N$ 默认是 $20$ ，$M$ 是 $10$ ；对于非持久化的统计，$N$ 默认是 $8$ ，$M$ 是 $16$ 。由于 $N$ 比较小，因此很容易不准确。由于不确定性的存在，所以<code>MySQL</code>优化器有时候会选择更差的索引进行搜索。<br>
        对于字符串数据，可以使用前缀索引减少查询次数，但是会损失一些区分度，而且无法使用覆盖索引。对于一些长字符串，前缀索引的效率较差，可以考虑使用倒序索引，或者建立一个哈希字段，再对哈希字段进行索引。</p>
<h2 id="5-锁">5. 锁</h2>
<p>        根据加锁范围，<code>MySQL</code>的锁大致可以分为全局锁、表级锁和行锁。<br>
        全局锁就是对整个数据库进行加锁，在加锁后整个数据库就处于只读状态。全局锁的典型使用场景是做全库逻辑备份，也就是把整库每个表都 $select$ 出来存成文本。对于支持可重复读的引擎，通过事务可以完成备份。而对于不支持可重复读的引擎比如<code>MyISAM</code>，就需要通过全局锁来进行备份。全局锁会在客户端断开时自动释放。<br>
        <code>MySQL</code>里面表级锁有两种：一种是表锁，一种是元数据锁 ( $meta\ \ data\ \ lock$, $MDL$ )。与全局锁一样，表锁会在客户端连接断开时自动释放。对于不支持更细粒度的引擎，表锁是最常用的处理并发的方式。而对于<code>InnoDB</code>这种支持行锁的引擎，则一般不实用。与表锁相比，<code>MDL</code>不需要显式使用，在访问一个表的时候会被自动加上，用于保证读写的正确性。当要对一个表做增删改查操作时，会加<code>MDL</code>读锁；当要对一个表做结构变更操作时，会加<code>MDL</code>写锁。读锁和写锁、写锁和写锁之间是互斥的，因此不能同时对一个表进行结构变更。<br>
        在<code>InnoDB</code>事务中，行锁是在需要的时候才加上，在事务结束的时候释放。如果事务需要多个锁，要把最可能造成锁冲突、最可能影响并发度的锁放在后面。出现死锁的时候，<code>InnoDB</code>提供了两种策略，第一种是等待超时，默认超时时间是 $50s$ ，第二种是进行死锁检测。每一个新来的进入阻塞状态的线程在发现行上有锁后都要进行死锁检测，如果不会产生死锁才会执行。</p>
<h2 id="6-分布式">6. 分布式</h2>
<h3 id="61-cap理论">6.1 <code>CAP</code>理论</h3>
<p>        <code>CAP</code>理论是指在分布式系统中，$C$ ( $Consistency$ )、$A$ ( $Availability$ )、$P$ ( $Partition\ \ Tolerance$ ) 这三个特征不能同时满足。在分布式系统中，现在的网络基础设施无法做到始终保持稳定，网络分区难以避免，牺牲 $P$ 相当于放弃使用分布式系统，因此在分布式系统中不能牺牲 $P$ 。对于涉及钱的交易，数据的一致性非常重要，因此保 $CP$ 弃 $A$ 是最佳选择。对于其他场景，大多数情况下的做法是选择 $AP$ 牺牲 $C$ ，因为很多情况下不需要太强的一致性，只要满足最终一致性即可。</p>
<h3 id="62-分布式数据存储">6.2 分布式数据存储</h3>
<p>        哈希是一种非常常用的数据分布式方法，其核心思想是确定一个哈希函数，通过计算得到对应的存储节点。哈希算法的一个优点是，只要哈希函数设置得当，可以很好地保证数据均匀性，缺点是稳定性较差。如果需要新增节点，那么原有节点中的数据就需要重新计算，即大规模数据迁移，降低稳定性。所以，哈希适用于同类型节点且节点数量比较固定的场景。<br>
        一致性哈希是指将存储节点和数据都映射到一个首尾相连的哈希环上，数据先通过哈希函数计算其在哈希环中的位置，存储节点可以根据<code>IP</code>地址再进行哈希，然后数据通过顺时针方向寻找的方式，来确定自己所属的存储节点。一致性哈希是对哈希的改进，在数据存储时采用哈希方式确定存储位置的基础上，又增加了一层哈希，也就是在数据存储前，对存储节点预先进行了哈希。这种改进可以很好地解决哈希方法存在的稳定性问题，当节点加入或退出时，仅影响该节点在哈希环上顺时针相邻的后继节点。比如前一个节点发生故障需要移除时，需要把该节点数据移到后一个节点，避免了大规模数据迁移。所以，一致性哈希方法比较适合同类型节点、节点规模会发生变化的场景。<br>
        带有限负载的一致性哈希方法的核心原理是给每个存储节点设置了一个存储上限值来控制存储节点添加或移除造成的数据不均匀。当数据按照一致性哈希算法找到相应的存储节点时，要先判断该存储节点是否达到了存储上限，如果达到上限，则继续寻找存储节点。<br>
        其实，哈希、一致性哈希、带有限负载的一致性哈希，都没有考虑节点异构性的问题。如果存储节点的性能好坏不一，数据分布方案还按照这些方法的话，还是没做到数据的均匀分布。带虚拟节点的一致性哈希方法，核心思想是根据每个节点的性能，为每个节点划分不同数量的虚拟节点，并将这些虚拟节点映射到哈希环中，然后再按照一致性哈希算法进行数据映射。带虚拟节点的一致性哈希方法比较适合异构节点，节点规模会发生变化的场景。</p>
<h3 id="63-分布式数据复制">6.3 分布式数据复制</h3>
<p>        从库与主库之间维持一个长连接，主库内部有一个线程，专门用于服务从库的长连接。完整的同步过程为：</p>
<ol>
<li>在从库上通过 $change\ \ master$ 命令，设置主库的<code>IP</code>、端口、用户名、密码以及<code>binlog</code>的起始位置 ( 文件名和偏移量 )；</li>
<li>在从库上执行 $start\ \ slave$ 命令，从库会启动一个 $io_-thread$ 和多个 $sql_-thread$ ，前者负责与主库建立连接；</li>
<li>主库校验完用户名和密码后，根据位置读取<code>binlog</code>并发送给从库；</li>
<li>从库将<code>binlog</code>写到<code>relay log</code>中；</li>
<li>$sql_-thread$ 读取<code>relay log</code>，解析命令并执行。</li>
</ol>
<p>        对于分布式存储系统中的数据复制技术来讲，也需要在一致性和可用性之间作出一些权衡。<br>
        同步复制技术是指，当用户请求更新数据时，主数据库必须要同步到备数据库之后才可以给用户返回，即如果主数据库没有同步到备数据库，用户的更新操作会一直阻塞。这种方式保证了 $CP$ ，牺牲了 $A$ 。由于性能不佳，影响用户体验，同步复制技术经常用于分布式数据库主备场景或对数据一致性有严格要求的场景，比如金融、交易之类的场景。<br>
        异步复制技术是指当用户请求更新数据时，主数据库处理完请求后可以直接给用户响应，而不必等待备数据库完成同步，即备数据库会异步进行数据的同步，用户的更新操作不会因为备数据库未完成数据同步而导致阻塞。显然，这种方式保证了<code>AP</code> ，牺牲了 $C$ 。异步复制技术大多应用在对用户请求响应时延要求很高的场景。<br>
        同步复制技术会满足数据的强一致性，但会牺牲可用性；异步复制技术会满足高可用，但会在一定程度上牺牲数据的一致性。半同步复制技术则介于两者之间。半同步复制技术是，用户发出写请求后，主数据库会执行写操作，并给备数据库发送同步请求，但主数据库不需要等待所有备数据库回复数据同步成功便可以响应用户，也就是说主数据库可以等待一部分备数据库同步完成后响应用户写操作执行成功。半同步复制技术通常有两种方式：</p>
<ol>
<li>当主数据库收到多个备数据库中的某一个回复数据同步成功后，便可以给用户响应写操作完成；</li>
<li>另一种是，主数据库等待超过一半节点 ( 包括主数据库
) 回复数据更新后，再给用户响应写操作成功。</li>
</ol>
<p>        <code>MySQL</code>集群在一主多备的场景下，也支持半同步复制模式，一般采用的是第一种半同步复制模式。普通的半同步是在主库事务提交后再等待从库同步，而增强型半同步会在主库事务提交前等待从库同步，避免了主从数据不一致的问题。</p>

            </div>
            <div class="meta post-footer"> <span>2021 Jun 21 20:33</span> <a href="/post/mysql%E7%AC%94%E8%AE%B0/"><i
                        class="fas fa-link"></i> link</a></div>
        </div>
        
        <div class="post">
            
            <center>
                <h1><a href="/post/csapp%E7%AC%94%E8%AE%B0/">CSAPP笔记</a></h1>
            </center>
            <div class="post-content">
                <h2 id="1-计算机系统漫游">1. 计算机系统漫游</h2>
<div class="highlight"><pre class="chroma"><code class="language-c" data-lang="c"><span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
</span><span class="cp"></span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">&#34;hello, world</span><span class="se">\n</span><span class="s">&#34;</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div><p>        $hello$ 程序生命周期的一开始是一个高级<code>C</code>程序，因为处于这种形式时，它是能够被人读懂的。为了运行 $hello.c$ ，每条<code>C</code>语句都必须被其他程序转化为一系列的低级机器语言指令。然后这些指令按照一种称为<strong>可执行目标程序</strong> ( $executable\ \ object\ \ program$ ) 的格式打包，并以二进制磁盘文件的形式存放起来。在<code>Unix</code>系统上，从源文件到目标文件的转化是由<strong>编译器驱动程序</strong> ( $compiler\ \ driver$ ) 完成的，这个过程可以分成四个阶段，执行这四个阶段的程序一起构成了编译系统：</p>
<ul>
<li>预处理阶段。预处理器 ( $cpp$ ) 根据以字符 $\#$ 开头的命令 ( $directives$ )，修改原始的<code>C</code>程序。修改完成后得到另一个<code>C</code>程序，通常是以 $.i$ 作为文件扩展名；</li>
<li>编译阶段：编译器 ( $ccl$ ) 将文本文件 $hello.i$ 翻译成文本文件 $hello.s$ ，它包含一个汇编语言程序；</li>
<li>汇编阶段：汇编器 ( $as$ ) 将 $hello.s$ 翻译成机器语言指令，并把这些指令打包成一种叫做<strong>可重定位</strong> ( $relocatable$ ) 目标程序的格式，将结果保存在目标文件 $hello.o$ 中；</li>
<li>链接阶段：$hello.c$ 调用了<code>C</code>库函数 $printf$ ，后者存在于名为 $printf.o$ 的单独的预编译目标文件中。链接器 ( $ld$ ) 负责处理目标文件的并入，处理完成后得到可执行文件。可执行文件加载到存储器后，由系统负责执行。</li>
</ul>
<p><img src="/image/2021-05-19-01.png" alt="一个典型系统的硬件组成"></p>
<ul>
<li><strong>总线</strong>：总线是贯穿整个系统的电子管道，携带信息字节并负责在各个部件间传递。通常被设计成传送定长的字节块，也就是<strong>字</strong> ( $word$ )；</li>
<li><code>I/O</code><strong>设备</strong>：系统与外界的联系通道。每个<code>I/O</code>设备都是通过一个控制器或适配器与<code>I/O</code>总线连接。控制器是<code>I/O</code>设备本身中或是系统的主板上的芯片组，而适配器是一块插在主板槽上的卡；</li>
<li><strong>主存</strong>：临时存储设备，在处理器执行程序时，用于存放程序和程序处理的数据。物理上来说，主存是一组<code>DRAM</code>芯片组成的，逻辑上来说，主存是由一个线性字节数组组成的；</li>
<li><strong>处理器</strong> ( <code>CPU</code> )：解释 ( 或执行 ) 存储在主存中指令的引擎，核心是<strong>程序计数器</strong> ( $PC$ )。寄存器文件 ( $register\ \ file$ ) 是一个小存储设备，由一些字长大小的寄存器组成。算术逻辑单元 ( $ALU$ ) 计算新数据和地址值。</li>
</ul>
<p>        一个典型的寄存器文件只存储几百字节的信息，主存可存放几百万字节。然而，处理器从寄存器文件中读取数据比从主存中读取要快几乎 $100$ 倍。针对这种处理器与主存之间的差异，系统设计者采用了更小更快的存储设备，称为<strong>高速缓存存储器</strong> ( $cache\ \ memories$ )。位于处理器芯片上的<code>L1</code>高速缓存的容量可以达到数万字节，访问速度几乎和访问寄存器文件一样快。容量为数十万到数百万字节的<code>L2</code>高速缓存是通过一条特殊的总线连接到处理器的，访问<code>L2</code>的时间开销要比访问<code>L1</code>的开销大 $5$ 倍。</p>
<h2 id="2-信息表示和处理">2. 信息表示和处理</h2>
<p>        大多数计算机采用 $8$ 位的块，或叫做<strong>字节</strong> ( $byte$ ) 作为最小的可寻址的存储器单位。机器级程序将存储器视为一个非常大的字节数组，称为<strong>虚拟存储器</strong> ( $virtual\ \ memory$ )。编译器和运行时系统的一个任务就是将存储器空间划分为可管理的单元，用来存放不同的<strong>程序对象</strong> ( $program\ \ object$ )，也就是程序数据、指令和控制信息。<br>
        每台计算机都有一个<strong>字长</strong> ( $word\ \ size$ )，指明整数和指针数据的标称大小 ( $normal\ \ size$ )。字长决定的最重要的系统参数就是虚拟地址空间的最大大小。<br>
        <strong>无符号</strong> ( $unsigned$ ) 编码是基于传统的二进制表示法的，<strong>二进制补码</strong> ( $tow&rsquo;s-complement$ ) 编码是表示有符号整数的最常见的方式，<strong>浮点数</strong> ( $floating-point$ ) 编码是表示实数的科学记数法的以二为基数的版本。将一个无符号数转换为一个更大的数据类型，只需要在开头添加 $0$ 即可，称为零扩展 ( $zero\ \ extension$ )。将一个二进制补码数字转换为一个更大的数据类型，规则是执行一个符号扩展 ( $sign\ \ extension$ )，在开头添加最高有效位的值。</p>
<h2 id="3-程序的机器级表示">3. 程序的机器级表示</h2>
<p>        与<code>C</code>代码相比，汇编代码可以看到一些被屏蔽的处理器状态，包括：</p>
<ul>
<li>程序计数器 ( $\%eip$ )</li>
<li>整数寄存器文件，包含 $8$ 个被命名的位置，分别存储 $32$ 位的值；</li>
<li>条件码寄存器保存着最近执行的算术指令的状态信息，用来实现控制流中的条件变化；</li>
<li>浮点寄存器文件包含 $8$ 个位置，用来存放浮点数据。</li>
</ul>
<p>        程序存储器 ( $program\ \ memory$ ) 包含程序的目标代码，操作系统需要的一些信息，用来管理过程调用和返回的运行时栈，以及用户分配的存储器块。程序存储器采用虚拟地址寻址。<br>
        一个<code>IA32</code>中央处理单元 ( $CPU$ ) 包含一组八个存储 $32$ 位值的寄存器，这些寄存器用来存储整数数据和指针。在平面寻址中，对特殊寄存器的需求已经大为降低了，在大多数情况中，前六个寄存器都可以看成通用寄存器，对它们的使用没有限制。<br>
        大多数指令有一个或多个操作数 ( $operand$ )，指示出执行一个操作中要引用的源数据值，以及放置结果的目的的位置。源数据值可以以常数形式给出，或是从寄存器或存储器中读出，结果可以存放在寄存器或存储器中。因此，各种操作数的可能性被分为三种类型。第一种是立即数 ( $immediate$ )，也就是常数值。第二种类型是寄存器 ( $register$ )，它表示某个寄存器的内容。第三种是存储器引用，根据计算出来的地址访问某个存储器位置。<br>
        除了整数寄存器，<code>CPU</code>还包含一组单个位的条件码 ( $condition\ \ code$ ) 寄存器，它们描述了最近的算术或逻辑操作的属性。最有用的条件码是：</p>
<ul>
<li>CF：进位标志；</li>
<li>ZF：零标志；</li>
<li>SF：符号标志；</li>
<li>OF：溢出标志。</li>
</ul>
<p>        一个过程调用包括将数据 ( 以过程参数和返回值的形式 ) 和控制从代码的一部分传递到另一部分。另外，它还必须在进入时为过程的局部变量分配空间，并在退出时释放这些空间。<code>IA32</code>程序用程序栈来支持过程调用，为单个过程分配的那部分栈称为栈帧 ( $stack\ \ frame$ )。假设过程 $P$ 调用过程 $Q$ ，$Q$ 的参数放在 $P$ 的栈帧中，$P$ 的返回地址被压入栈中，形成 $P$ 的栈帧的末尾。过程 $Q$ 也会用栈来保存其他不能存放在寄存器中的局部变量。<br>
        程序寄存器组是唯一一个被所有过程共享的资源。虽然在给定时刻只能有一个过程是活动的，但我们必须保证当调用者调用被调用者时，被调用者不会覆盖某个调用者稍后会使用的寄存器的值。为此，<code>IA32</code>采用了一组统一的寄存器使用惯例，所有的过程都必须遵守，包括程序库中的过程。<br>
        <code>C</code>的 $struct$ 声明创建一个数据类型，将可能不同类型的对象聚合到一个对象中。结构的各个组成部分是用名字来引用的，实现类似于数组的实现。编译器保存关于每个结构类型的信息，指示每个域 ( $field$ ) 的字节偏移。<br>
        许多计算机系统对基本数据类型的可允许地址做出了一些限制，要求某种类型的对象的地址必须是某个值的倍数。这种对齐限制简化了处理器和存储器系统之间接口的硬件设计。例如，假设一个处理器总是从存储器中取 $8$ 个字节出来，则地址必须为 $8$ 的倍数。如果可以保证所有的 $double$ 都将它们的地址对齐成 $8$ 的倍数，那么就可以用一个存储器操作来读或者写值了。<br>
        <code>C</code>对于数组引用不进行任何边界检查，而且局部变量和状态信息都存放在栈中。一个对越界的数组元素的写操作破坏了存储在栈中的状态信息，当程序使用这个被破坏的状态，试图重新加载寄存器或执行 $ret$ 指令时，就会出现很严重的错误。一种特别常见的状态破坏称为缓冲区溢出 ( $buffer\ \ overflow$ )。例如，在栈中分配某个字节数组来保存一个字符串，但是字符串的长度超出了为数组分配的空间时，就会发生缓冲区溢出。<br>
        浮点单元包括 $8$ 个浮点寄存器，但是和普通寄存器不一样，这些寄存器是被当成一个浅栈 ( $shallow\ \ stack$ ) 来对待的。当压入栈中的值超过 $8$ 个时，栈底的那些值就会消失。对于返回值为 $float$ 或 $double$ 类型的函数，结果是以扩展精度格式在浮点寄存器栈顶部返回的。</p>
<h2 id="4-处理器体系结构">4. 处理器体系结构</h2>
<p>        处理器必须执行一系列的指令，每条指令执行某个简单操作，被编码为由一个或多个字节序列组成的二进制格式。一个处理器支持的指令和指令的字节级编码称为它的<code>ISA</code> ( $instruction-set\ \ architecture$，指令集体系结构 )。<code>ISA</code>在编译器编写者和处理器设计人员之间提供了一个概念抽象层，编译器编写者只需要知道允许哪些指令，以及它们是如何编码的；而处理器设计者必须建造出执行这些指令的处理器。<br>
        在硬件设计中，电子电路被用来计算位的函数 ( $functions\ \ on\ \ bits$ )，以及在各种存储器元素中存储位。大多数现代电路技术都是用信号线上的高电压或低电压来表示不同的位值。通常的技术中，逻辑 $1$ 是用 $1.0$ 伏特左右的高电压表示的，而逻辑 $0$ 是用 $0.0$ 伏特左右的低电压表示的。要实现一个数字系统需要三个主要的组成部分：计算位的函数的组合逻辑、存储位的存储器元素，以及控制存储器元素更新的时钟信号。<br>
        通常，处理一条指令包括很多操作。我们将它们组织成某个特殊的阶段序列，使得即使指令的动作差异很大，但所有的指令都遵循统一的序列。处理指令的阶段有：</p>
<ul>
<li>取指 ( $fetch$ )：取指阶段从存储器读入指令，地址为程序计数器的值。从指令中抽取出指令指示符字节的两个四位部分，称为 $icode$ ( 指令代码 ) 和 $ifun$ ( 指令功能 )；</li>
<li>解码 ( $decode$ )：解码阶段从寄存器文件读入最多两个操作数；</li>
<li>执行 ( $execute$ )：执行阶段，<code>ALU</code>要么执行指令指明的操作，计算存储器引用的有效地址，要么增加或减少栈指针；</li>
<li>访存 ( $memory$ )：访存阶段可以将数据写入存储器，或者从存储器读出数据；</li>
<li>写回 ( $write\ \ back$ )：写回阶段最多可以写两个结果到寄存器文件；</li>
<li>更新<code>PC</code> ( $PC\ \ update$ )：将<code>PC</code>设置成下一条指令的地址。</li>
</ul>
<p>        处理器无限循环执行这些阶段，只有在遇到 $halt$ 或一些错误情况时，才会停下来，包括非法存储器地址和非法指令。<br>
        六个阶段按序执行，产生的处理器设计称为 $SEQ$ 。重新排列六个阶段，使得更新<code>PC</code>阶段在一个周期开始时执行，而不是结束时才执行，这样产生的处理器设计称为 $SEQ+$ 。$SEQ+$ 对控制逻辑的唯一修改就是重新定义了<code>PC</code>的计算，使它使用以前的状态值。<br>
        在流水线化的系统中，待执行的任务被划分成了若干个独立的阶段。流水线化的一个重要特性就是增加了系统的吞吐量 ( $throughput$ )，不过它也会轻微地增加执行时间 ( $latency$ )。对硬件设计者来说，将系统计算设计划分成一组具有相同延迟的阶段是一个主要的挑战。现代处理器为了提高时钟频率，采用了很深的 ( $15$ 或更多的阶段 ) 流水线。处理器设计师将指令的执行划分成很多非常简单的步骤，这样一来每个阶段的延迟就很小。电路设计者小心地设计流水线寄存器，使其延迟尽可能的小。芯片设计者也必须小心地设计时钟传播网络，以保证时钟在整个芯片上同时改变。<br>
        对于程序来说，相邻指令之间很可能是相关的，相关包括数据相关 ( $data\ \ dependency$ )、顺序相关 ( $sequential\ \ dependency$ ) 和控制相关 ( $control\ \ dependency$ )。为了处理相关指令，流水线需要调整指令的执行顺序，保证在执行一条指令时，其前一个相关指令执行完毕。<br>
        流水线化的设计的目的就是每个时钟周期都发射 ( $issue$ ) 一条新指令，也就是说每个时钟周期都有一条新指令进入执行阶段并最终完成。为了达到这个目的，我们必须在取出当前指令后，马上确定下一条指令的位置。不幸的是，如果取出的指令是条件分支指令，要到几个周期后，也就是指令通过执行阶段后，才能知道是否要选择分支。类似地，如果取出的指令是 $ret$ ，要到指令通过访存阶段，才能确定返回地址。猜测分支方向并根据猜测开始取指的技术称为分支预测。<br>
        相关的存在可能会导致流水线产生计算错误，称为冒险。同相关一样，冒险也可以分为数据冒险 ( $data\ \ hazard$ ) 和控制冒险 ( $control\ \ hazard$ )。暂停 ( $stalling$ ) 是一种常用的用来避免冒险的技术。暂停时，处理器会停止流水线中一条或多条指令，直到冒险条件不再满足。只要一条指令的源操作数会被流水线后面某个阶段中的指令产生，处理器就会通过将指令阻塞在解码阶段来避免数据冒险。暂停技术就是让一组指令阻塞在它们的阶段，而允许其他指令继续通过流水线。将结果值直接从一个流水线阶段传到较早阶段的技术称为数据转发 ( $data\ \ forwarding$ )，通过使用转发可以在一定程度上避免暂停。有一类数据冒险不能单纯使用转发解决，因为存储器读是在流水线较后面发生的，称为加载/使用冒险 ( $load/use\ \ hazard$ )，可以通过结合暂停和转发来解决，称为加载互锁 ( $load\ \ interlock$ )。<br>
        对于一些简单的操作，比如数字加法，可以在执行阶段一个周期内处理完。但是对于一些更加复杂操作指令，例如过整数乘法和除法，以及浮点运算，执行时间会需要几个或者几十个周期。为了实现这些指令，我们既需要额外的硬件来执行这些计算，还需要一种机制来协调这些指令的处理与流水线其他部分之间的关系。可以通过采用独立于主流水线的特殊硬件功能单元来处理较为复杂的操作。</p>
<h2 id="5-优化程序性能">5. 优化程序性能</h2>
<p>        对许多程序都很有用的度量标准是每元素的周期数 ( $cycles\ \ per\ \ element$, $CPE$ )。这种度量标准帮助我们在更详细的级别上理解迭代程序的循环性能。<br>
        <code>P6</code>微体系结构是自 $20$ 世纪 $90$ 年代后期以来许多厂商生产的高端处理器的典型。在工业界称为超标量 ( $superscalar$ )，意思是它可以在每个时钟周期执行多个操作，而且是乱序的。整个设计有两个主要部分：<code>ICU</code> ( $Instruction\ \ Control\ \ Unit$ ) 和<code>EU</code> ( $Execution\ \ Unit$ )，前者负责从存储器中读出指令序列，并根据这些指令序列生成一组针对程序数据的基本操作，而后者执行这些操作。<br>
        <code>ICU</code>从指令高速缓存 ( $instruction\  \ cache$ ) 中读取指令，指令高速缓存是一个特殊的高速缓存存储器，它包含最近访问的指令。通常，<code>ICU</code>会在当前正在执行的指令很早之前取指，所以它有足够的时间对指令解码，并把操作发送到<code>EU</code>。不过，有一个问题，那就是当程序遇到分支时，程序有两个可能的前进方向。一种可能会选择分支，控制被传递到分支目标；另一种可能是不选择分支，控制被传递到指令序列的下一条指令。现代处理器采用了一种称为分支预测 ( $branch\ \ prediction$ ) 的技术，在这种技术中处理器会预测是否选择分支，同时还预测分支的目标地址。使用一种称为投机执行 ( $speculative\ \ execution$ ) 的技术，处理器会开始取出它预测的分支处的指令并对指令解码，甚至于在它确定分支预测是否正确之前就开始执行这些操作。如果过后它确定分支预测错误，它会将状态重新设置到分支点的状态。<br>
        <code>EU</code>接收来自指令读取单元的操作。通常，它会每个时钟周期接收若干个操作。这些操作会被分派到一组功能单元中，它们会执行实际的操作。这些功能单元是专门用来处理特定类型的操作。<br>
        在<code>ICU</code>中，退役单元 ( $Retirement\ \ Unit$ ) 记录正在进行的处理，并确保它遵守机器级程序的顺序语义。指令解码时，关于指令的信息被放置在一个先进先出的队列中。这个信息会一直保持在队列中，直到两个结果中的一个发生。首先，一旦指令的操作完成了，而所有导致这条指令的分支点也都被确认为预测正确，那么这条指令就可以退役了，所有对程序寄存器的更新都可以被实际执行了。另一方面，如果导致该指令的某个分支点预测错误，这条指令会被清空，丢弃所有计算出来的值。通过这种方法，错误的预测就不会改变程序状态了。<br>
        循环并行性的好处是受描述计算的汇编代码的能力限制的。特别地，<code>IA32</code>指令集只有很少量的寄存器来存放累积的值。如果我们有并行度 $p$ 超过了可用的寄存器数量，编译器会诉诸于溢出 ( $spilling$ )，将某些临时值存放到栈中。一旦出现这种情况，性能会急剧下降。</p>
<h2 id="6-存储器层次结构">6. 存储器层次结构</h2>
<p>        存储器系统 ( $memory\ \ system$ ) 是一个具有不同容量、成本和访问时间的存储 ( $storage$ ) 设备的层次结构。</p>
<h3 id="61-主存">6.1 主存</h3>
<p>        随机访问存储器 ( $random-access\ \ memory$, $RAM$ ) 分为两类——静态的和动态的。静态<code>RAM</code> ( <code>SRAM</code> ) 比动态<code>RAM</code> ( <code>DRAM</code> ) 更快，但也贵得多。<code>SRAM</code>用来作为高速缓存存储器，既可以在<code>CPU</code>芯片上，也可以不在<code>CPU</code>芯片上。<code>DRAM</code>用来作为主存以及图形系统的帧缓冲区。典型地，一个桌面系统的<code>SRAM</code>不会超过几兆字节，但是<code>DRAM</code>却有几百或几千兆字节。<br>
        <code>DRAM</code>芯片中的单元 ( 位 ) 被分成 $d$ 个超单元 ( $supercell$ )，每个超单元都是由 $w$ 个<code>DRAM</code>单元组成的。一个 $d \times w$ 的<code>DRAM</code>总共存储了 $dw$ 位信息。超单元被组织成一个 $r$ 行 $c$ 列的长方形阵列，这里 $rc = d$ 。每个超单元有形如 $(i, j)$ 的地址，这里 $i$ 表示行，而 $j$ 表示列。<br>
        每个<code>DRAM</code>芯片被连接到某个称为存储控制器的电路，这个电路可以一次传送 $w$ 位到每个<code>DRAM</code>芯片或一次从每个<code>DRAM</code>芯片传出 $w$ 位。为了读出超单元 $(i, j)$ 的内容，存储控制器将行地址 $i$ 发送到<code>DRAM</code>，然后是列地址 $j$ 。行地址 $i$ 被称为<code>RAS</code> ( $Row\ \ Access\ \ Strobe$ ，行访问选通脉冲 ) 请求。列地址 $j$ 被称为<code>CAS</code> ( $Column\ \ Access\ \ Strobe$ ，列访问选通脉冲 ) 请求。<code>RAS</code>和<code>CAS</code>请求共享同样的<code>DRAM</code>地址管脚 ( $pin$ )，信息通过管脚的外部连接器流入和流出芯片，每个管脚携带一个一位的信号。为了读出某一单元数据，存储控制器首先发送行地址，<code>DRAM</code>会将对应行的所有内容都拷贝到行缓冲区。接下来，存储控制器再发送列地址，<code>DRAM</code>从行缓冲区中拷贝出对应列的超单元数据并发送到存储控制器。电路设计者将<code>DRAM</code>组织成二维阵列而不是线性数组的一个原因是降低芯片上地址管脚的数量，缺点是必须分两步发送地址，增加了访问时间。<br>
        如果断电，<code>DRAM</code>和<code>SRAM</code>会丢失它们的信息，从这个意义上说，它们是易失的 ( $volatile$ )。另一方面，非易失性存储器 ( $nonvolatile\ \ memory$ ) 即使是在关电后，仍然保存着它们的信息。出于历史原因，虽然<code>ROM</code>中有的类型既可以读也可以写，但是它们整体上都被称为<code>ROM</code> ( $read-only\ \ memory$ )。<code>ROM</code>是以它们能够被重编程 ( 写 ) 的次数和对它们进行重编程所用的机制来区分的。存储在<code>ROM</code>设备中的程序通常被称为固件 ( $firmware$ )。当一个计算机系统通电以后，它会运行存储在<code>ROM</code>中的固件。</p>
<h3 id="62-总线">6.2 总线</h3>
<p>        数据流通过称为总线 ( $bus$ ) 的共享电路在处理器和<code>DRAM</code>主存之间来来回回。每次<code>CPU</code>和主存之间的数据传送都是通过一系列步骤来完成的，这些步骤称为总线事务 ( $bus\ \ transaction$ )。读事务 ( $read\ \ transaction$ ) 从主存传送数据到<code>CPU</code>，写事务 ( $write\ \ transaction$ ) 从<code>CPU</code>传送数据到主存。总线是一组并行的导线，能携带地址、数据和控制信号。取决于总线设计，数据和地址信号可以共享同一组导线，也可以使用不同的。同时，两个以上的设备也能共享同一个总线。</p>
<p><img src="/image/2021-05-19-02.png" alt="典型的连接CPU和主存的总线结构"></p>
<p>        典型的桌面系统的结构，主要部件是<code>CPU</code>芯片、<code>I/O</code>桥接器 ( $I/O\ \ bridge$，包括存储控制器 ) 以及组成主存的<code>DRAM</code>存储器模块。这些部件由一对总线连接起来，其中一条总线是系统总线 ( $system\ \ bus$ )，它将<code>CPU</code>连接到<code>I/O</code>桥接器，另一条总线是存储器总线 ( $memory\ \ bus$ )，它将<code>I/O</code>桥接器连接到主存。<code>I/O</code>桥接器将系统总线的电信号翻译成存储器总线的电信号。</p>
<pre><code class="language-x86asm" data-lang="x86asm">movl A, %eax
</code></pre><p>当<code>CPU</code>执行上述加载操作时，地址 $A$ 的内容会被加载到寄存器 $\%eax$ 中。<code>CPU</code>芯片上称为总线接口 ( $bus\ \ interface$ ) 的电路发起总线上的读事务。读事务由三步骤组成。首先，<code>CPU</code>将地址 $A$ 放到系统总线上。<code>I/O</code>桥接器将信号传递到存储器总线，接下来，主存感受到存储器总线上的地址信号，从存储器总线读地址，从<code>DRAM</code>取出数据字，并将数据写到存储器总线。<code>I/O</code>桥接器将存储器总线信号翻译成系统总线信号，然后传递到系统总线。最后，<code>CPU</code>感受到系统总线上的数据，从总线上读数据，并将数据拷贝到寄存器 $\%eax$ 。</p>
<h3 id="63-磁盘">6.3 磁盘</h3>
<p>        磁盘是由盘片 ( $platter$ ) 构成的，每个盘片有两面，表面 ( $surface$ ) 覆盖着磁性记录材料。盘片中间有一个可以旋转的主轴 ( $spindle$ )，它使得盘片以固定的旋转速率 ( $rotational\ \ rate$ ) 旋转。每个表面由一组称为磁道 ( $track$ ) 的同心圆组成的，且每个磁道被划分为一组扇区 ( $sector$ )。每个扇区包含相等数量的数据位 ( 通常是 $512$ 字节 )，这些数据编码在扇区上的磁性材料中。扇区之间由一些间隙 ( $gap$ ) 分隔开，这些间隙中不存储数据位。间隙存储用来标识扇区的格式化位。磁盘是由一个或多个叠放在一起的盘片组成的，它们放在一个密封的包装里，整个装置通常被称为磁盘驱动器 ( $disk\ \ drive$ )。磁盘制造商通常用柱面 ( $cylinder$ ) 来描述多个盘片驱动器的构造，这里，柱面是所有盘片表面上到中心主轴的距离相等的磁道的集合。<br>
        磁盘用连接到一个传动臂 ( $actuator\ \ arm$ ) 的读/写头 ( $read/write\ \ head$ ) 来读写存储在磁性表面的位。通过沿着半径轴移动传动臂，驱动器可以将读/写头定位在盘面上的任何磁道上，这样的机械运动称为寻道 ( $seek$ )。<br>
        像图形卡、监视器、鼠标、键盘和磁盘这样的设备都是通过诸如<code>Intel</code>的<code>PCI</code> ( $Peripheral\ \ Component\ \ Interconnect$，外围设备互连 ) 总线这样的<code>I/O</code>总线连接到<code>CPU</code>和主存的。同系统总线和存储器总线不同，诸如<code>PCI</code>这样的<code>I/O</code>总线设计成与底层<code>CPU</code>无关。<br>
        虽然<code>I/O</code>总线比系统总线和存储器总线慢，但是它可以容纳种类繁多的第三方设备，例如<code>USB</code>、图形卡等。其他的设备，例如网络适配器，可以通过将适配器插入到主板上空的扩展槽中，从而连接到<code>I/O</code>总线，这些插槽提供了到总线的直接电路连接。<br>
        <code>CPU</code>使用一种称为存储器映射<code>I/O</code> ( $memory-mapped\ \ I/O$ ) 的技术来向<code>I/O</code>设备发射命令。在使用存储器映射<code>I/O</code>的系统中，地址空间中有一块地址是为与<code>I/O</code>设备通信保留的。每个这样的地址称为一个<code>I/O</code>端口 ( $I/O\ \ port$ )。当一个设备连接到总线时，它与一个或多个端口相关联 ( 或它被映射到一个或多个端口 )。<br>
        在磁盘控制器收到来自<code>CPU</code>的读命令之后，它将逻辑块号翻译成一个扇区地址，读该扇区的内容，然后将这些内容直接传送到主存，不需要<code>CPU</code>的干涉，这个设备称为<code>DMA</code> ( $direct\ \ memory\ \ access$ )，这种数据传送称为<code>DMA</code>传送 ( $DMA\ \ transfer$ )。在<code>DMA</code>传送完成，磁盘扇区的内容被安全地存储在主存中以后，磁盘控制器通过给<code>CPU</code>发送一个中断信号来通知<code>CPU</code>。基本思想是中断会发信号到<code>CPU</code>芯片的一个外部管脚上，这会导致<code>CPU</code>暂停它当前正在做的工作，跳转到一个操作系统函数，这个函数会记录下<code>I/O</code>已经完成，然后将控制返回到<code>CPU</code>被中断的地方。</p>
<h3 id="64-局部性">6.4 局部性</h3>
<p>        一个编写良好的计算机程序倾向于展示出良好的局部性 ( $locality$ )。也就是，它们倾向于引用的数据项邻近于其他最近引用过的数据项，或者邻近于最近自我引用过的数据项。局部性通常有两种形式：时间局部性 ( $temporal\ \ locality$ ) 和空间局部性 ( $spatial\ \ locality$ )。在一个具有良好时间局部性的程序中，被引用过一次的存储器位置很可能在不远的将来再被多次引用。在一个具有良好空间局部性的程序中，如果一个存储器位置被引用了一次，那么程序很可能在不远的将来引用附近的一个存储器位置。<br>
        一般而言，高速缓存 ( $cache$ ) 是一个小而快速的存储设备，它作为存储在更大也更慢的设备中的数据对象的缓冲区域，使用高速缓存的过程被称为缓存 ( $caching$ )。存储器层次结构的中心思想是，对于每个 $k$ ，位于 $k$ 层的更快更小的存储设备作为位于 $k + 1$ 层的更大更慢的存储设备的缓存。换句话说，层次结构中的每一层都缓存来自较低一层的数据对象。<br>
        当发生缓存不命中时，第 $k$ 层的缓存就必须执行某个替换策略，确定把它从第 $k + 1$ 层中取出的块放在哪里。硬件缓存通常使用的是更严格的放置策略，这个策略将第 $k + 1$ 层的某个块限制放置在第 $k$ 层块的一个小的子集中 ( 有时只是一个块 )。这种限制性的放置策略会引起冲突不命中 ( $conflict\ \ miss$ )。当工作集的大小超过缓存的大小时，缓存会经历容量不命中 ( $capacity\ \ miss$ )。</p>
<h3 id="65-高速缓存">6.5 高速缓存</h3>
<p>        早期计算机系统的存储器层次结构只有三层：<code>CPU</code>寄存器、主<code>DRAM</code>存储器和磁盘存储设备。不过由于<code>CPU</code>和主存之间逐渐增大的差距，系统设计者被迫在<code>CPU</code>寄存器文件和主存之间插入了一个小的<code>SRAM</code>存储器，称为<code>L1</code>高速缓存。在现代系统中，<code>L1</code>高速缓存位于<code>CPU</code>芯片上，访问速度几乎和寄存器一样快。随着<code>CPU</code>和主存之间的性能差距不断增大，系统设计者在<code>L1</code>高速缓存和主存之间又插入了一个高速缓存，称为<code>L2</code>高速缓存，可以将<code>L2</code>高速缓存连接到存储器总线，或者连接到它自己的高速缓存总线 ( $cache\ \ bus$ )。有些高性能系统，甚至于在存储器总线上还有一个层高速缓存，称为<code>L3</code>高速缓存。<br>
        考虑一个计算机系统，其中每个存储器地址有 $m$ 位，形成 $M = 2^m$ 个不同的地址。这样一个机器的高速缓存被组织成一个 $S = 2^s$ 个高速缓存组 ( $cache\ \ set$ ) 的数组。每个组包含 $E$ 个高速缓存行 ( $cache\ \ line$ )。每个行是由一个 $B = 2^b$ 字节的数据块 ( $block$ ) 组成的，一个有效位 ( $valid\ \ bit$ ) 指明这个行包含的数据是否有意义，还有 $t = m - (b + s)$ 个标记位 ( $tag\ \ bit$ )，唯一标识存储在这个高速缓存行中的块。<br>
        当一条加载指令指示<code>CPU</code>从主存地址 $A$ 中读一个字时，它将地址 $A$ 发送到高速缓存。如果高速缓存正保存着地址 $A$ 处那个字的拷贝，它就立即将那个字发回给<code>CPU</code>。<br>
        假设<code>CPU</code>写一个已经缓存了的字 $w$ ，在高速缓存更新了它的 $w$ 的拷贝之后，要更新在存储器中对应的拷贝。最简单的方法称为直写 ( $well-through$ )，就是立即将 $w$ 的高速缓存块写回到存储器中。虽然简单，但是直写的缺点是每条存储指令都会引起总线上的一个写事务。另一种方法，称为写回 ( $write-back$ )，尽可能地推迟存储器更新，只有当替换算法要驱逐已更新的块时，才把它写到存储器。虽然减少了总线事务的数量，但是增加了复杂性，高速缓存必须为每个高速缓存行维护一个额外的修改位 ( $dirty\ \ bit$ )，表明这个高速缓存块是否被修改过。另一个问题是如何处理写不命中。一种方法，称为写分配 ( $write-allocate$ )，加载相应的存储器块到高速缓存中，然后更新这个高速缓存块。写分配利用了写的空间局部性，但是缺点是每次不命中都会导致一个块从存储器传送到高速缓存。另一种方法称为非写分配 ( $non-write-allocate$ )，避开高速缓存，直接把这个字写到存储器中。直写高速缓存通常是非写分配的，写回高速缓存通常是写分配的。<br>
        只保存指令的高速缓存称为 $i-cache$ ，只保存数据的高速缓存称为 $d-cache$ ，两者都保存的称为统一的高速缓存 ( $unified\ \ cache$ )。一个典型的桌面系统<code>CPU</code>芯片本身就包括一个<code>L1</code> $i-cache$ 和一个<code>L1</code> $d-cache$ 。</p>
<h2 id="7-链接">7. 链接</h2>
<p>        <strong>链接</strong> ( $linking$ ) 就是将不同部分的代码和数据收集和组合成一个单一文件的过程，这个文件可被加载 ( 或被拷贝 ) 到存储器并执行。链接可以执行于编译时 ( $compile\ \ time$ )，也就是在源代码被翻译成机器代码时；也可以执行于加载时 ( $load\ \ time$ )，也就是在程序被加载器 ( $loader$ ) 加载到存储器并执行时；甚至于运行时 ( $run\ \ time$ ) 由应用程序来执行。在早期的计算机系统中，链接是手动执行的。在现代系统中，链接是由叫做链接器 ( $linker$ ) 的程序自动执行的。<br>
        像<code>Unix ld</code>程序这样的静态链接器 ( $static\ \ linker$ ) 以一组可重定位目标文件和命令行参数作为输入，生成一个完全链接的可以加载和运行的可执行目标文件作为输出。输入的可重定位目标文件由各种不同的代码和数据节 ( $section$ ) 组成。指令在一个节中，初始化的全局变量在另一个节中，而未初始化的变量又在另外一个节中。<br>
        为了创建可执行文件，链接器必须完成两个主要任务：</p>
<ul>
<li>符号解析 ( $symbol\ \ resolution$ )。目标文件定义和引用符号。符号解析的目的是将每个符号引用和一个符号定义联系起来。</li>
<li>重定位 ( $relocation$ )。编译器和汇编器生成从地址零开始的代码和数据节。链接器通过把每个符号定义与一个存储器位置联系起来，然后修改所有对这些符号的引用，使得它们指向这个存储器位置，从而重定位这些节。</li>
</ul>
<p>        目标文件有三种形式：</p>
<ul>
<li>可重定位目标文件。包含二进制代码和数据，其形式可以在编译时与其他可重定位目标文件合并起来，创建一个可执行目标文件。</li>
<li>可执行目标文件。包含二进制代码和数据，其形式可以被直接拷贝到存储器并执行。</li>
<li>共享目标文件。一种特殊类型的可重定位目标文件，可以在加载或者运行时，被动态地加载到存储器并链接。</li>
</ul>
<p>        编译器和汇编器生成可重定位目标文件 ( 包括共享目标文件 )。链接器生成可执行目标文件。从技术上来说，一个目标模块 ( $object\ \ module$ ) 就是一个字节序列，而一个目标文件 ( $object\ \ file$ ) 就是一个存放在磁盘文件中的目标模块。<br>
        每个可重定位目标模块 $m$ 都有一个符号表，包含 $m$ 所定义和引用的符号的信息。在链接器的上下文中，有三种不同的符号：</p>
<ul>
<li>由 $m$ 定义并能被其他模块引用的全局符号。</li>
<li>由其他模块定义并被模块 $m$ 引用的全局符号。</li>
<li>只被模块 $m$ 定义和引用的本地符号。</li>
</ul>
<p>        链接器解析符号引用的方法是将每个引用与它输入的可重定位目标文件的符号表中的一个确定的符号定义联系起来。当编译器遇到一个不是在当前模块中定义的符号时，它会假设该符号是在其他某个模块中定义的，生成一个链接器符号表表目，并把它交给链接器处理。如果链接器在它的任何输入模块中都找不到这个被引用的符号，它就输出一条错误信息并终止。<br>
        所有的编译系统都提供一种机制，将所有相关的目标模块打包为一个单独的文件，称为静态库 ( $static\ \ library$ )，它也可以用做链接器的输入。当链接器构造一个输出的可执行文件时，它只拷贝静态库里被应用程序引用的目标模块。在<code>Unix</code>系统中，静态库以一种称为存档 ( $archive$ ) 的特殊文件格式存放在磁盘中。存档文件是一组连接起来的可重定位目标文件的集合，有一个头部描述每个成员目标文件的大小和位置。<br>
        一旦链接器完成了符号解析，它就把代码中的每个符号引用和确定的一个符号定义联系起来。在此时，链接器就知道它的输入目标模块中代码节和数据节的确切大小。接下来就可以开始重定位了：</p>
<ul>
<li>重定位节和符号定义。链接器将所有相同类型的节合并为同一类型的新的聚合节。</li>
<li>重定位节中的符号引用。链接器修改代码节和数据节中对每个符号的引用，使得它们指向正确的运行时地址。为了执行这一步，链接器依赖于称为重定位表目 ( $relocation\ \ entry$ ) 的可重定位目标模块中的数据结构，记录需要修改的引用。</li>
</ul>
<p>        静态库同所有的软件一样，需要定期维护和更新。如果应用程序员想要使用一个库的最新版本，他们必须以某种方式了解到该库的更新情况，然后显式地将他们的程序与新的库重新链接。另一个问题是<code>C</code>程序使用的标准库函数，在运行时会被复制到每个运行进程的文本段中，从而造成存储器系统资源的极大浪费。<br>
        共享库 ( $shared\ \ library$ ) 是一个目标模块，在运行时，可以加载到任意的存储器地址，并在存储器中和一个程序链接起来。这个过程称为动态链接 ( $dynamic\ \ linking$ )，是由一个叫做动态链接器 ( $dynamic\ \ linker$ ) 的程序来执行的。在任何给定的文件系统中，对于一个库只有一个共享库文件，所有引用该库的可执行目标文件共享这个库中的代码和数据。使用共享库后，链接过程中不会将库中代码和数据节拷贝到可执行文件中，而是拷贝一些重定位和符号表信息，它们使得运行时可以解析库中代码和数据的引用。</p>
<h2 id="8-异常控制流">8. 异常控制流</h2>
<h3 id="81-异常">8.1 异常</h3>
<p>        从给处理器加电开始，直到断电为止，程序计数器假设一个序列的值</p>
<p>$$
a_0, a_1, \cdots, a_{n-1}
$$</p>
<p>        其中，每个 $a_k$ 是某个相应的指令 $I_k$ 的地址，每次从 $a_k$ 到 $a_{k+1}$ 的过渡称为控制转移 ( $control\ \ transfer$ )。这样的控制转移序列叫做处理器的控制流 ( $control\ \ flow$ )。现代系统通过使控制流发生突变来应对系统状态的变化，一般而言，我们把这些突变称为<code>ECF</code> ( $exceptional\ \ control\ \ flow$ )。<br>
        <b>异常</b> ( $exception$ ) 是一种形式的异常控制流，它一部分是由硬件实现的，一部分是由操作系统实现的。因为它们有一部分是由硬件实现的，所以具体细节将随系统的不同而有所不同。然而，对于每个系统而言，基本的思想都是相同的。在处理器中，状态被编码为不同的位和信号。状态变化被称为事件 ( $event$ )，事件可能和当前指令的执行直接相关，也可能没有关系。在任何情况中，当处理器检测到有事件发生时，它就会通过一张叫做异常表 ( $exception\ \ table$ ) 的跳转表，进行一个间接过程调用，到一个专门设计用来处理这类事件的操作系统子程序——异常处理程序 ( $exception\ \ handler$ )。当异常处理程序完成处理后，根据引起异常的事件的类型，会发生以下三种情况中的一种：</p>
<ol>
<li>处理程序将控制返回给当前指令 $Icurr$ 。</li>
<li>处理程序将控制返回给 $Inext$ 。</li>
<li>处理程序终止被中断的程序。</li>
</ol>
<p>        系统中可能的每种类型的异常都分配了一个唯一的非负整数的异常号 ( $exception\ \ number$ )。这些号码中的某一些是由处理器的设计者分配的，其他号码是由操作系统内核的设计者分配的。在系统启动时，操作系统分配和初始化一张称为异常表的跳转表，表目 $k$ 包含异常 $k$ 的处理程序的地址。在运行时，处理器检测到发生了一个事件，并且确定了相应的异常号 $k$ 。随后，处理器触发异常，方法是间接过程调用，通过异常表的表目 $k$ ，转到相应的处理程序。异常号是异常表的索引，异常表的起始地址放在一个叫做异常表基寄存器 ( $exception\ \ table\ \ base\ \ register$ ) 的特殊<code>CPU</code>寄存器里。<br>
        异常可以分为四类：</p>
<table>
<thead>
<tr>
<th style="text-align:center">类别</th>
<th style="text-align:center">原因</th>
<th style="text-align:center">异步/同步</th>
<th style="text-align:center">返回行为</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">中断</td>
<td style="text-align:center">来自<code>I/O</code>设备的信号</td>
<td style="text-align:center">异步</td>
<td style="text-align:center">总是返回到下一条指令</td>
</tr>
<tr>
<td style="text-align:center">陷阱</td>
<td style="text-align:center">有意的异常</td>
<td style="text-align:center">同步</td>
<td style="text-align:center">总是返回到下一条指令</td>
</tr>
<tr>
<td style="text-align:center">故障</td>
<td style="text-align:center">潜在可恢复的错误</td>
<td style="text-align:center">同步</td>
<td style="text-align:center">可能返回到当前指令</td>
</tr>
<tr>
<td style="text-align:center">终止</td>
<td style="text-align:center">不可恢复的错误</td>
<td style="text-align:center">同步</td>
<td style="text-align:center">不会返回</td>
</tr>
</tbody>
</table>
<p>        <strong>中断</strong>是异步发生的，是来自处理器外部的<code>I/O</code>设备的信号的结果。硬件中断不是任何一条专门的指令造成的，从这个意义上来说它是异步的。硬件终端的异常处理程序常常被称为中断处理程序 ( $interrupt\ \ handler$ )。<code>I/O</code>设备，例如网络适配器、磁盘控制器和定时器芯片，通过向处理器芯片上的一个管脚发信号，并将异常号放到系统总线上，来触发中断，这个异常号标识了引起中断的设备。在当前指令完成之前，处理器注意到中断管脚的电压变高了，就从系统总线读取异常号，然后调用适当的中断处理器程序。当处理程序返回时，它就将控制返回给下一条指令。结果是程序继续执行，就好像没有发生中断一样。<br>
        陷阱是有意的异常，是执行一条指令的结果。就像中断处理程序一样，陷阱处理程序将返回到下一条指令。陷阱最重要的用途是在用户程序和内核之间提供一个像过程一样的接口，叫做系统调用。用户程序经常需要向内核请求服务，比如读一个文件 ( $read$ )、创建一个新的进程 ( $fork$ )、加载一个新的程序 ( $execve$ )，或者终止当前进程 ( $exit$ )。为了允许对这些内核服务的受控的访问，处理器提供了一条特殊的 $syscall\ \ n$ 指令，当用户程序想要请求服务 $n$ 时，可以执行这条指令，产生一个到异常处理程序的陷阱。<br>
        故障由错误情况引起，它可能被故障处理程序修正。当一个故障发生时，处理器将控制转移给故障处理程序。如果处理程序能够修正这个错误情况，它就将控制返回到故障指令，从而重新执行它。否则，处理程序返回到内核中的 $abort$ 例程，终止引起故障的应用程序。故障的一个经典示例是缺页异常。<br>
        终止是不可恢复的致命错误造成的结果——典型的是一些硬件错误，比如<code>DRAM</code>或者<code>SRAM</code>位被损坏时发生的奇偶错误。终止处理程序从不将控制返回给应用程序，而是传递给一个内核 $abort$ 例程。</p>
<h3 id="82-进程">8.2 进程</h3>
<p>        异常提供基本的构造块，它允许操作系统提供<strong>进程</strong> ( $process$ ) 的概念。进程的经典定义就是一个执行中程序的实例。系统中的每个程序都是运行在某个进程的上下文 ( $context$ ) 中的。上下文是由程序正确运行所需的状态组成的，这个状态包括存放在存储器中的程序的代码和数据、它的栈、它的通用目的寄存器的内容、它的程序计数器、环境变量以及打开文件描述符的集合。<br>
        典型的，即使在系统中有许多其他程序在运行，进程也可以向每个程序提供一种假象，好像它在独占地使用处理器。如果我们想用调试器单步执行我们的程序，我们会看到一系列的<code>PC</code>的值，这些值唯一地对应于包含在我们程序的可执行目标文件中的指令或是包含在运行时动态链接到我们程序的共享对象中的指令。这个<code>PC</code>值的序列叫做逻辑控制流。任何逻辑流在时间上和另外的逻辑流重叠的进程被称为并发进程 ( $concurrent\ \ process$ )，而这两个进程就被称为并发运行。进程和其他进程轮换运行的概念称为多任务 ( $multitasking$ )。一个进程执行它的控制流的一部分的每一时间段叫做时间片 ( $time\ \ slice$ )。因此，多任务也叫做时间分片 ( $time\ \ slicing$ )。<br>
        进程也为每个程序提供一种假象，就好像它正在独占地使用系统地址空间。一个进程为每个程序提供它自己的私有地址空间。一般而言，和这个空间中某个地址相关联的那个存储器字节是不能被其他进程读或者写的，从这个意义上说，这个地址空间是私有的。<br>
        为了使操作系统内核提供一个无懈可击的进程抽象，处理器必须提供一种机制，限制一个应用可以执行的指令以及它可以访问的地址空间范围。典型地，处理器是用某个控制寄存器中的一个方式位 ( $mode\ \ bit$ ) 来提供这种功能的，当该方式位设置了时，进程就运行在内核模式中。一个运行在内核模式的进程可以执行指令集中的任何指令，并且可以访问系统中任何存储器位置。一个运行应用程序代码的进程初始时是在用户模式中的。进程从用户模式变为内核模式的唯一方法是通过诸如中断、故障或者陷入系统调用 ( $trapping\ \ system\ \ call$ ) 这样的异常。<br>
        操作系统内核利用一种称为上下文切换 ( $context\ \ switch$ ) 的较高级形式的异常控制流来实现多任务。内核为每个进程维持一个上下文，上下文就是内核重新启动一个被抢占进程所需的状态，由一些对象的值组成，包括通用目的寄存器、浮点寄存器、程序计数器、用户栈、状态寄存器、内核栈和各种内核数据结构，比如描绘地址空间的页表、包含有关当前进程信息的进程表，以及包含进程已打开文件的信息的文件表。在进程执行的某些时刻，内核可以决定抢占当前进程，并重新开始一个先前被抢占的进程，这种决定就叫做调度 ( $scheduling$ )，是由内核中称为调度器 ( $scheduler$ ) 的代码处理的。上下文切换可以：</p>
<ol>
<li>保存当前进程的上下文；</li>
<li>恢复某个先前被抢占进程所保存的上下文；</li>
<li>将控制传递给这个新恢复的进程。</li>
</ol>
<p>        当内核代表用户执行系统调用时，可以发生上下文切换。如果系统调用因为等待某个事件发生而阻塞，那么内核可以让当前进程休眠，切换到另一个进程。<br>
        当一个进程由于某种原因终止时，内核并不是立即把它从系统中清除。取而代之的是，进程被保持在一种终止状态中，直到被它的父进程回收 ( $reaped$ )。当父进程回收已终止的子进程时，内核将子进程的退出状态传递给父进程，然后抛弃已终止的进程，从此时开始，该进程就不存在了。一个终止了但还未被回收的进程称为僵死进程 ( $zombie$ )。如果父进程没有回收它的僵死子进程就终止了，那么内核会安排 $init$ 进程来回收它们。$init$ 进程的 $PID$ 为 $1$ ，并且是在系统初始化时由内核创建的。</p>
<h3 id="83-信号">8.3 信号</h3>
<p>        一个信号 ( $signal$ ) 就是一条消息，它通知进程一个某种类型的事件已经在系统中发生了。每种信号类型都对应于某个类型的系统事件。低层的硬件异常是由内核异常处理程序处理的，对用户进程而言通常是不可见的。信号提供了一种机制向用户进程通知这些异常的发生。发送一个信号到目的进程是由两个不同步骤组成的：</p>
<ul>
<li>发送信号。内核通过更新目的进程上下文中的某个状态，发送一个信号给目的进程。发送信号可以有如下两个原因：内核检测到一个系统事件，或者一个进程调用了 $kill$ 函数，显式地要求内核发送一个信号给目的进程。</li>
<li>接收信号。当目的进程被内核强迫以某种方式对信号的发送作出反应时，目的进程就接收了信号。进程可以忽略这个信号，终止，或者通过执行一个称为信号处理程序 ( $signal\ \ handler$ ) 的用户层函数捕获这个信号。</li>
</ul>
<p>        一个只发出而没有被接收的信号叫做待处理信号 ( $pending\ \ signal$ )。在任何时刻，一种类型至多只会有一个待处理信号，接下来发送到这个进程的该类型的信号都会被丢弃。一个进程可以有选择性地阻塞接收某种信号。当一种信号被阻塞时，它仍可以被发送，但是产生的待处理信号不会被接收，直到取消阻塞。</p>
<h2 id="9-测量程序执行时间">9. 测量程序执行时间</h2>
<p>        计算机是在两个完全不同的时间尺度 ( $time\ \ scale$ ) 上工作的。在微观级别，它们以每个时钟周期一条或多条指令的速度执行指令，这里每个时钟周期只需要大约 $1ns$ 。在宏观尺度上，处理器必须响应外部事件，外部事件发生的时间尺度要以 $ms$ 来度量。<br>
        外部事件，例如击键、磁盘操作和网络活动，会产生中断信号，这些中断信号使得操作系统调度程序得以运行，可能还会切换到另一个进程。即使没有这样的事件，我们也希望处理器从一个进程切换到另一个，这样用户看上去就好像处理器在同时执行许多程序一样。出于这个原因，计算机有一个外部计时器，它周期性地向处理器发送中断信号。这些中断信号之间的时间被称为间隔时间 ( $interval\ \ time$ )。当计时器中断发生时，操作系统调度程序可以选择要么继续当前正在执行的进程，要么切换到另一个进程。这个间隔时间必须设置得足够短，以保证处理器在任务间切换得足够频繁。但如果设置得太短，会导致性能很差，因为进程切换需要几千个时钟周期来进行。典型的计时器间隔范围是 $1 \sim 10ms$ 。<br>
        为了给计时测量提供更高的精确度，许多处理器还包含一个运行在时钟周期级的计时器。这个计时器是一个特殊的寄存器，每个时钟周期它都会加 $1$ 。可以用特殊的机器指令来读这个计数器的值。不是所有的处理器都有这样的计数器，而且有这样的计数器的处理器在实现细节上也各不相同。</p>
<h2 id="10-虚拟存储器">10. 虚拟存储器</h2>
<p>        计算机系统的主存被组织成一个由 $M$ 个连续的字节大小的单元组成的数组。每字节都有一个唯一的物理地址 ( $physical\ \ address$, $PA$ )。<code>CPU</code>访问存储器的最自然的方式就是使用物理地址。我们把这种方式称为物理寻址 ( $physical\ \ addressing$ )。根据虚拟寻址，<code>CPU</code>通过生成一个虚拟地址 ( $virtual\ \ address$, $VA$ ) 来访问主存，这个虚拟地址在被送到存储器之前先转换成适当的物理地址。将一个虚拟地址转换为物理地址的任务叫做地址翻译 ( $address\ \ translation$ )。就像异常处理一样，地址翻译需要<code>CPU</code>硬件和操作系统之间的紧密合作。<code>CPU</code>芯片上叫做<code>MMU</code> ( $memory\ \ management\ \ unit$ ) 的专用硬件，利用存放在主存中的查询表来动态翻译虚拟地址。<br>
        和存储器层次结构中其他缓存一样，磁盘上的数据被分割成块，这些块作为磁盘和主存之间的传输单元。<code>VM</code>系统通过将虚拟存储器分割为称为虚拟页 ( $virtual\ \ page$, $VP$ ) 的大小固定的块。<br>
        同任何缓存一样，虚拟存储器系统必须有某种方法来判定一个虚拟页是否存放在<code>DRAM</code>中的某个地方。如果是，系统还必须确定这个虚拟页存放在哪个物理页中。如果不命中，还需要进行替换。页表将虚拟页映射到物理页。虚拟地址空间中的每个页在页表中的一个固定偏移量处都有一个<code>PTE</code> ( $page\ \ table\ \ entry$ )。为了我们的目的，我们将假设每个<code>PTE</code>是由一个有效位和一个 $n$ 位地址字段组成的。<br>
        独立地址空间为操作系统提供了一个管理用户进程和操作系统自身之间共享的一致机制。一般而言，每个进程都有自己私有的代码、数据、堆以及栈区域，是不和其他进程共享的。然而，在一些情况中，还是需要进程来共享代码和数据。例如，每个进程必须调用相同的操作系统内核代码。操作系统通过将不同进程中适当的虚拟页面映射到相同的物理页面，从而安排多个进程共享这部分代码的一个拷贝，而不是在每个进程中都包括单独的内核的拷贝。<br>
        地址翻译是一个 $N$ 元素的虚拟地址空间 ( $VAS$ ) 中的元素和一个 $M$ 元素的物理地址空间 ( $PAS$ ) 中元素之间的映射。<code>CPU</code>中的一个控制寄存器，页表基址寄存器 ( $page\ \ table\ \ base\ \ register$, $PTBR$ ) 指向当前页表。$n$ 位的虚拟地址包含两个部分：一个 $p$ 位的<code>VPO</code> ( $virtual\ \ page\ \ offset$ ) 和一个 $(n - p)$ 的<code>VPN</code> ( $virtual\ \ page\ \ number$ )。<code>MMU</code>利用<code>VPN</code>来选择适当的<code>PTE</code>。<br>
        每次<code>CPU</code>产生一个虚拟地址，<code>MMU</code>就必须查阅一个<code>PTE</code>，在最糟糕情况下，这会要求一次对存储器的额外的取数据，代价是几十到几百个周期。许多系统都试图消除这样的开销，它们在<code>MMU</code>中包括了一个关于<code>PTE</code>的小的缓存，称为<code>TLB</code> ( $translation\ \ lookaside\ \ buffer$ )。<code>TLB</code>中每一行都保存着一个由单个<code>PTE</code>组成的块。当<code>TLB</code>不命中时，<code>MMU</code>必须从<code>L1</code>缓存中取出相应的<code>PTE</code>。<br>
        <code>Linux</code>通过将一个虚拟存储器区域与一个磁盘上的对象 ( $object$ ) 关联起来，以初始化这个虚拟存储器区域的内容，这个过程称为存储器映射 ( $memory\ \ mapping$ )。虚拟存储器区域可以映射到两种类型的对象：</p>
<ol>
<li><code>Unix</code>文件系统中的普通文件：一个区域可以映射到一个普通磁盘文件的连续部分。文件被分成页面大小的片，每一片包含一个虚拟页面的初始内容。</li>
<li>匿名文件：一个区域也可以映射到一个匿名文件，匿名文件是由内核创建的，包含的全是二进制零。<code>CPU</code>第一次引用这样一个区域内的虚拟页面时，内核就在物理存储器中找到一个合适的牺牲页面，用二进制零覆盖，并更新页表，在磁盘和存储器之间并没有实际的数据传送。</li>
</ol>
<p>        无论哪一种情况，一旦一个虚拟页面被初始化了，它就在一个由内核维护的专门的交换文件 ( $swap\ \ file$ ) 之间换来换去。交换文件也叫做交换空间 ( $swap\ \ space$ ) 或者交换区域 ( $swap\ \ area$ )。在任何时刻，交换空间都限制着当前运行着的进程能够分配的虚拟页面的总数。<br>
        一个对象可以被映射到虚拟存储器的一个区域，要么作为共享对象，要么作为私有对象。私有对象是使用一种叫做写时拷贝 ( $copy-on-write$ ) 的技术映射到虚拟存储器中的。一个私有对象开始的生命周期的方式基本上与共享对象一样，在物理存储器中只保存有私有对象的一份拷贝。两个进程可以将一个私有对象映射到它们的虚拟存储器的不同区域，但是共享同一份物理拷贝。对于每个映射私有对象的进程，相应私有区域的页表条目都被标记为只读，并且区域结构被标记为私有的写时拷贝。只要没有进程试图写它自己的私有区域，它们就可以继续共享物理存储器中对象的一个单独拷贝。然而，只要有一个进程试图写它自己的私有区域内的某个页面，那么这个写操作就会触发一个保护故障。当故障处理程序注意到保护异常是由于进程试图写私有的写时拷贝区域中的一个页面而引起的，它就会在物理存储器中创建这个页面的一个新拷贝，更新页表条目指向这个新拷贝，然后恢复这个页面的可写权限。<br>
        大多数<code>C</code>程序会在运行时需要额外的虚拟存储器，使用一种动态存储器分配器 ( $dynamic\ \ memory\ \ allocater$ )。一个动态存储器分配器维护着一个进程的虚拟存储器区域，称为堆 ( $heap$ )。在大多数的<code>Unix</code>系统中，堆是一个请求二进制零的区域，对于每个进程，内核维护着一个变量 $brk$ ，指向堆的顶部。<br>
        任何实际的分配器都需要一些数据结构，允许它来区分块边界，并区别已分配块和空闲块，大多数分配器将这些信息嵌在块本身当中。一个块是由一个字的头部、有效载荷以及可能的一些额外的填充组成的。头部编码了这个块的大小，以及这个块是已分配的还是空闲的。我们称这种结构为隐式空闲列表，因为空闲块是通过头部中的大小字段隐含地连接着的。<br>
        对于通用的分配器，隐式空闲列表是不适合的。一种更好的方法是将空闲块组织为某种形式的显式数据结构。例如，堆可以组织成一个双向空闲列表，或者使用<code>FIFO</code>方法维护链表。</p>
<h2 id="11-系统级io">11. 系统级<code>I/O</code></h2>
<p>        输入/输出 ( $I/O$ ) 是在主存和外部设备之间拷贝数据的过程。一个<code>Unix</code>文件就是一个 $m$ 字节的序列，所有的<code>I/O</code>设备，都被模型化为文件，而所有的输入和输出都被当作对相应文件的读和写来执行。内核用三种相关的数据结构来表示打开的文件：</p>
<ul>
<li>描述符表 ( $descriptor\ \ table$ )。每个进程都有它独立的描述符表，它的表项是由进程打开的文件描述符来索引的。每个打开的描述符表项指向文件表中的一个表项。</li>
<li>文件表 ( $file\ \ table$ )。打开文件的集合是由一张文件表来表示的，所有的进程共享这张表。每个文件表的表项组成包括有当前的文件位置、引用计数，以及一个指向 $v-node$ 表中对应表项的指针。</li>
<li>$v-node$ 表 ( $v-node\ \ table$ )。同文件表一样，所有的进程共享这张表。每个表项包含 $stat$ 结构中的大多数信息，包括 $st_-mode$ 和 $st_-size$ 成员。</li>
</ul>
<h2 id="12-网络编程">12. 网络编程</h2>
<p>        每个网络应用都是基于客户端-服务器模型的。根据这个模型，一个应用是由一个服务器进程和一个或者多个客户端进程组成的。客户端和服务器通常运行在不同的主机上，并且通过计算机网络的硬件和软件资源来通信。对于一个主机而言，网络只是一种<code>I/O</code>设备，作为数据源和数据接收方。从网络上接收到的数据从适配器经过<code>I/O</code>和存储器总线拷贝到存储器，典型地是通过<code>DMA</code>传送。<br>
        因特网客户端和服务器通过在连接 ( $connection$ ) 上发送和接收字节流来通信。从连接一对进程的意义上而言，连接是点对点 ( $point-to-point$ ) 的。从数据可以同时双向流动的角度来说，它是全双工 ( $full-duplex$ ) 的。套接字 ( $socket$ ) 是连接的端点 ( $end-point$ )。</p>
<h2 id="13-并发编程">13. 并发编程</h2>
<p>        构造并发程序最简单的方法就是用进程。对于在父、子进程间共享状态信息，进程有一个非常清晰的模型：共享文件表，但是不共享用户地址空间。有独立的进程地址空间，进程不可能不小心覆盖另一个进程的虚拟存储器，但是会使得进程共享状态信息变得更加困难。为了共享信息，它们必须使用显式的<code>IPC</code> ( 进程间通信 ) 机制。<br>
        <code>I/O</code>多路技术可以用作并发事件驱动 ( $event-driven$ ) 程序的基础，在事件驱动中，流是作为某种事件的结果前进的。一般概念是将逻辑流模型化为状态机。不严格地说，一个状态机 ( $state\ \ machine$ ) 就是一组状态 ( $state$ )、输入事件 ( $input\ \ event$ ) 和转移 ( $transition$ )，其中转移就是将状态和输入事件映射到状态。对于每个新客户端 $k$ ，基于<code>I/O</code>多路复用的并发服务器会创建一个新的状态机 $s_k$ ，并将它和已连接描述符 $d_k$ 联系起来。服务器使用<code>I/O</code>多路复用，借助 $select$ 函数，检测输入事件的发生。当每个已连接描述符准备好可读时，服务器就为相应的状态机执行转移。<br>
        <strong>线程</strong> ( $thread$ ) 就是运行在一个进程上下文中的一个逻辑流。线程由内核自动调度。每个线程都有它自己的线程上下文 ( $thread\ \ context$ )，包括一个唯一的整数线程<code>ID</code> ( $Thread\ \ ID$, $TID$ )、栈、栈指针、程序计数器、通用目的寄存器和条件码。所有运行在一个进程里的线程共享该进程的整个虚拟地址空间。在一些重要的方面，线程执行是不同于进程的。因为一个线程的上下文要比一个进程的上下文小得多，线程的上下文切换要比进程的上下文切换快得多。另一个不同就是线程不像进程那样按照严格的父子层次来组织，主线程和其他线程的区别仅在于它总是进程中第一个运行的线程。对等线程池概念的主要影响是，一个线程可以杀死它的任何对等线程，或者等待它的任意对等线程终止。进一步来说，每个对等线程都能读写相同的共享数据。<br>
        在任何一个时间点上，线程是可结合的 ( $joinable$ ) 或者是可分离的 ( $detached$ )。一个可结合的线程能够被其他线程收回资源和杀死。在被其他线程回收之前，它的存储器资源是不释放的。相反，一个分离的线程是不能被其他线程回收或杀死的。它的存储器资源在它终止时由系统自动释放。默认情况下，线程是可结合的。</p>

            </div>
            <div class="meta post-footer"> <span>2021 May 19 15:06</span> <a href="/post/csapp%E7%AC%94%E8%AE%B0/"><i
                        class="fas fa-link"></i> link</a></div>
        </div>
        
    </div>
</div>


        </div><footer>
    <div class="footer-content">
        
        <div class="contact-info">
            
            <div class="footer-github">
                <i class="fab fa-github fa-ms"></i> <a target="_blank" href="https://github.com/z217">github.com/z217</a>
            </div>
            
            
            <div class="footer-mail">
                <i class="far fa-envelope"></i> <a href="mailto:mailto:zihan.zhouchn@outlook.com">mailto:zihan.zhouchn@outlook.com</a> </div>
            
            
        </div>
        
        
        <p class="copyright meta">Copyright © 2020–2020, z217 and the Hugo Authors; all rights reserved. Theme: <a target="_blank"
                href="https://github.com/ahmedsaadxyzz/npq-hugo">npq-hugo</a></p>
        
    </div>
</footer>


<script type="text/javascript" async
    src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [
                ['$', '$'],
                ['\\(', '\\)']
            ],
            displayMath: [
                ['$$', '$$'],
                ['\[\[', '\]\]']
            ],
            processEscapes: true,
            processEnvironments: true,
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            TeX: {
                equationNumbers: {
                    autoNumber: "AMS"
                },
                extensions: ["AMSmath.js", "AMSsymbols.js"]
            }
        }
    });

    MathJax.Hub.Queue(function () {
        
        
        
        var all = MathJax.Hub.getAllJax(),
            i;
        for (i = 0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
        if (tocFlag) tocInit();
    });
</script>

<style>
    code.has-jax {
        font: inherit;
        font-size: 100%;
        background: inherit;
        border: inherit;
        color: #515151;
    }
</style></main>
</body>

</html>