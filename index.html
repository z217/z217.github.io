<!DOCTYPE html>
<html><head>
	<meta name="generator" content="Hugo 0.82.1" />
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="A personal blog of z217">
  <meta name="Author" content="z217">
  <meta name="keywords" content="hugo blog">
  <link rel="icon" type="image/x-icon" href=https://z217blog.cn/favicon.ico>
  <link rel="stylesheet" href=https://z217blog.cn/css/syntax.css>
  <link rel="stylesheet" href=https://z217blog.cn/css/style.css>
  <script src="https://kit.fontawesome.com/1b7478c139.js" crossorigin="anonymous"></script>
  
  <title>z217&#39;s blog</title>
</head><script src=https://z217blog.cn/js/jquery-3.4.1.min.js></script>
<script src=https://z217blog.cn/js/navbutton.js></script>

<body><aside id="sidenav">
    <header>
        
        <a href=https://z217blog.cn><img src="https://z217blog.cn/avatar.png" alt="avatar"></a>

        

        <a id="branding" href=https://z217blog.cn>
            
            z217&#39;s blog
            
        </a>
    </header>

    <nav>
        
        
        <a href="/" >
            <i class="fas fa-home fa-ms"></i>
            <span>首页</span>
        </a>
        
        
        <a href="/post/" >
            <i class="fas fa-keyboard fa-ms"></i>
            <span>文章</span>
        </a>
        
        
        <a href="/tags" >
            <i class="fas fa-tags fa-sm"></i>
            <span>标签</span>
        </a>
        
        
        <a href="/about" >
            <i class="fas fa-user fa-ms"></i>
            <span>关于</span>
        </a>
        
        
        <a href="https://github.com/z217"  target="_blank" >
            <i class="fab fa-github fa-ms"></i>
            <span>Github</span>
        </a>
        
        
        <a href="/index.xml" >
            <i class="fas fa-rss fa-sm"></i>
            <span>RSS</span>
        </a>
        
        
        <a href="https://www.cnblogs.com/meidaoli/"  target="_blank" >
            <i class="fas fa-map fa-sm"></i>
            <span>友链</span>
        </a>
        
    </nav>
</aside><main id="main">
        <a href="javascript:void(0)" id="closebtn" onclick="navToggle()"><i class="fas fa-bars fa-lg"></i></a>
        <div class="content">




<div class="section">
    <div class="section-title">recent</div>
    
    
    <div class="list-item">
        <a class="entry-title" href="/post/%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%8F%E8%AE%AEmesi/">缓存一致性协议MESI</a>
        
        
        <p>缓存一致性协议MESI介绍</p>
        
        <div class="meta">
            
            <i class="far fa-calendar-alt"></i> 2021 Aug 16 11:02
            
            <br>
            
            <i class="fas fa-tags"></i>
            Tags: OS
            
        </div>
    </div>
    
    <div class="list-item">
        <a class="entry-title" href="/post/mysql%E7%AC%94%E8%AE%B0/">MySQL笔记</a>
        
        
        <p>MySQL笔记</p>
        
        <div class="meta">
            
            <i class="far fa-calendar-alt"></i> 2021 Jun 21 20:33
            
            <br>
            
            <i class="fas fa-tags"></i>
            Tags: DBS
            
        </div>
    </div>
    
    <div class="list-item">
        <a class="entry-title" href="/post/csapp%E7%AC%94%E8%AE%B0/">CSAPP笔记</a>
        
        
        <p>CSAPP阅读笔记，一些操作系统中有的就不记了</p>
        
        <div class="meta">
            
            <i class="far fa-calendar-alt"></i> 2021 May 19 15:06
            
            <br>
            
            <i class="fas fa-tags"></i>
            Tags: OS
            
        </div>
    </div>
    
    <div class="list-item">
        <a class="entry-title" href="/post/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/">操作系统笔记</a>
        
        
        <p>操作系统笔记，方便查阅</p>
        
        <div class="meta">
            
            <i class="far fa-calendar-alt"></i> 2021 May 10 20:54
            
            <br>
            
            <i class="fas fa-tags"></i>
            Tags: OS
            
        </div>
    </div>
    
    <div class="list-item">
        <a class="entry-title" href="/post/leetcode%E9%A2%98%E8%A7%A37%E8%82%A1%E7%A5%A8%E9%97%AE%E9%A2%98/">Leetcode题解（7）：股票问题</a>
        
        
        <p>LeetCode股票问题合集</p>
        
        <div class="meta">
            
            <i class="far fa-calendar-alt"></i> 2021 Apr 24 19:11
            
            <br>
            
            <i class="fas fa-tags"></i>
            Tags: Algorithm
            
        </div>
    </div>
    
</div>



<div class="section">
    <div class="section-title">μblog</div>
    <div class="posts">
        
        
        <div class="post">
            
            <center>
                <h1><a href="/post/%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%8F%E8%AE%AEmesi/">缓存一致性协议MESI</a></h1>
            </center>
            <div class="post-content">
                <p>        <strong>高速缓冲存储器一致性</strong> ( $Cache\ \ coherence$ )，也称缓存一致性，是指在采用层次结构存储系统的计算机系统中，保证告诉缓冲存储器中数据与主存储器中数据相同的机制。在有多个<code>CPU</code>的多处理机系统中特别容易出现高速缓存中数据不一致的问题。<br>
        在<code>CPU</code>缓存设计中，<code>L1</code>高速缓存包含指令缓存和数据缓存，位于<code>CPU</code>芯片上，访问速度几乎和寄存器一样快。<code>L2</code>高速缓存在<code>L1</code>和主存之间，连接到存储器总线或者高速缓存总线上。有些高性能系统还会在存储器总线上设置<code>L3</code>高速缓存。<code>L1</code>和<code>L2</code>是每个<code>CPU</code>内核间独立的，<code>L3</code>是所有<code>CPU</code>内核间共享的。<br>
        对于单核<code>CPU</code>来说，数据更新时缓存更新只用考虑自己的就行了，主要有两种处理方法。<strong>写回法</strong> ( $write\ \ back$ )，是当处理器执行写操作时，信息只写入<code>cache</code>，当<code>cache</code>中的数据被替换出去时写回主存。为了减少内存写操作，<code>cache</code>中通常还会设置一个脏位 ( $dirty\ \ bit$ )，标识该块在被载入后是否发生了更新。<strong>直写法</strong> ( $write\ \ through$ ) 是当处理器执行写操作时，既向<code>cache</code>中写入也向主存中写入。直写法会造成大量写内存操作，需要设置一个缓冲来减少硬件冲突，称为写缓冲器 ( $write\ \ buffer$ )，通常不超过 $4$ 个缓存块的大小，也适用于写回法。<br>
        相比于单核<code>CPU</code>，多核<code>CPU</code>除了要保证<code>L1</code>和<code>L2</code>最新外还要考虑到其他核中<code>L1</code>和<code>L2</code>的实时性和有效性。<code>MESI</code>协议是一个基于失效的缓存一致性协议，是支持写回缓存的最常用协议。该协议对总线上的操作进行监听，即核 $A$ 可以窥探到核 $B$ 对过期值的读操作，并更新主存中的过期值。<code>MESI</code>把<code>cache</code>中的数据分为几个状态：</p>
<table>
<thead>
<tr>
<th style="text-align:center">状态</th>
<th style="text-align:center">描述</th>
<th style="text-align:center">监听</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$Invalid$</td>
<td style="text-align:center">该<code>cache</code>字段失效</td>
<td style="text-align:center">无</td>
</tr>
<tr>
<td style="text-align:center">$Shared$</td>
<td style="text-align:center">字段数据一致并且多核<code>cache</code>共享该字段</td>
<td style="text-align:center">监听其他缓存使该字段无效或者变为 $Exclusive$ 的请求，监听到对应事件后会将该字段设为 $Invalid$</td>
</tr>
<tr>
<td style="text-align:center">$Exclusive$</td>
<td style="text-align:center">字段数据一致并且只在当前核<code>cache</code>中独有</td>
<td style="text-align:center">监听其他缓存读主存中该字段的操作，监听到对应事件后将该字段变为 $Shared$</td>
</tr>
<tr>
<td style="text-align:center">$Modified$</td>
<td style="text-align:center">该字段有效但是与主存不一致，只存在于当前核<code>cache</code>中</td>
<td style="text-align:center">监听所有试图读该字段对应主存字段的操作，该操作会被延迟到当前缓存字段写回主存并将状态设为 $Shared$ 之后执行</td>
</tr>
</tbody>
</table>
<p><img src="/image/2021-08-16-01.png" alt="状态机"></p>
<table>
<thead>
<tr>
<th style="text-align:center">事件</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$Local\ \ Read$</td>
<td style="text-align:center">读取本地<code>cache</code>字段</td>
</tr>
<tr>
<td style="text-align:center">$Local\ \ Write$</td>
<td style="text-align:center">写入本地<code>cache</code>字段</td>
</tr>
<tr>
<td style="text-align:center">$Remote\ \ Read$</td>
<td style="text-align:center">其他<code>cache</code>读取字段</td>
</tr>
<tr>
<td style="text-align:center">$Remote\ \ Write$</td>
<td style="text-align:center">其他<code>cache</code>写入字段</td>
</tr>
</tbody>
</table>
<p>        对于 $Modified$ 和 $Exclusive$
状态，数据是精确的，而 $Shared$ 状态可能是非一致的。如果一个处于 $Shared$ 的缓存字段作废了，另一个缓存实际上可能已经独享了该缓存字段，但是该缓存不会转为 $Exclusive$
，因为其他缓存并不会广播他们作废该缓存字段的通知。如果一个<code>CPU</code>想修改一个处于 $Shared$ 状态的缓存字段，总线事务需要将所有该缓存字段的副本变为 $Invalid$ 状态，而修改 $Exclusive$ 状态的缓存字段不需要总线事务。<br>
        缓存的一致性消息传递是需要时间的，这就使其切换时产生延迟。当一个缓存被切换状态时其他缓存收到消息完成各自的切换并且发出回应消息这么长一段时间中<code>CPU</code>都会等待所有缓存响应完成。为了避免这种<code>CPU</code>运算能力的浪费，$Store\ \ Buffer$ 被引入。处理器会将想要写入主存的值写到 $Store\ \ Buffer$ 中再去处理其他事情。为了避免在 $Store\ \ Buffer$ 未保存完时其他核已经完成读取，需要引入内存屏障。写屏障保证处理器在更新数据前必须将所有 $Store\ \ Buffer$ 中的指令执行完毕，读屏障保证处理器在读之前将所有需要设置为 $Invalid$ 的字段设置完毕。</p>

            </div>
            <div class="meta post-footer"> <span>2021 Aug 16 11:02</span> <a href="/post/%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%8F%E8%AE%AEmesi/"><i
                        class="fas fa-link"></i> link</a></div>
        </div>
        
        <div class="post">
            
            <center>
                <h1><a href="/post/mysql%E7%AC%94%E8%AE%B0/">MySQL笔记</a></h1>
            </center>
            <div class="post-content">
                <h2 id="1-架构">1. 架构</h2>
<p>        大体来说，<code>MySQL</code>可以分为<code>Server</code>层和存储引擎层两部分。<code>Server</code>层包括连接器、查询缓存、分析器、优化器、执行器等，以及所有的内置函数，所有跨存储引擎功能都在这一层实现。而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持<code>InnoDB</code>、<code>MyISAM</code>、<code>Memory</code>等多个引擎。不同的存储引擎共用一个<code>Server</code>层，也就是从连接器到执行器的部分。</p>
<ul>
<li>连接器：连接器负责跟客户端建立连接、获取权限、维持和管理连接。数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接。建立连接的过程通常比较复杂，所以应尽量使用长连接。但是全部使用长连接后，有时候<code>MySQL</code>内存占用会很高，因为<code>MySQL</code>在执行过程中临时使用的内存是在连接对象里的，只有在断开连接时才释放。</li>
<li>查询缓存：<code>MySQL</code>会在执行语句之前先在查询缓存中查询。但是查询缓存的失效很频繁，只要有一个表更新，表上所有缓存都会失效。对于更新压力大的数据库来讲，命中率会很低。<code>MySQL</code>在 $8.0$ 版本移除了查询缓存功能。</li>
<li>分析器：分析器会对语句做语法分析，判断语句是否存在错误，同时理解语句要执行的操作。</li>
<li>优化器：优化器是在表中存在多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联时，决定表的连接顺序。</li>
<li>执行器：在开始执行之前，会检查是否对表具有查询权限。如果有权限，就打开表执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。</li>
</ul>
<p>        一个<code>InnoDB</code>表包含两个部分，即表结构定义和数据。表结构定义的占用空间很小，在<code>MySQL 8.0</code>版本以前，表结构是存在以 $.frm$ 为后缀的文件里，而<code>MySQL 8.0</code>版本已经允许把表结构定义放在系统数据表中了。表数据既可放在共享表空间里，也可以是单独的文件，从<code>MySQL 5.6.6</code>开始，默认是存储在一个以 $.ibd$ 为后缀的文件中的。对于放在共享表空间中的表，即使通过 $DROP$ 命令删除后，空间也不会回收。在删除的过程中，<code>InnoDB</code>会查找聚簇索引，将对应的记录标记为删除，而不是真正删除，目的是为以后插入新数据时的复用。记录的复用与数据页的复用不同，记录的复用只允许对应范围的新记录复用，而如果删除整个数据页后，数据页的复用可以允许复用到任何位置。如果相邻的两个数据页的利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另一个数据页就被标记为可复用。<br>
        重建表即将原来表的记录读取出来，一行一行地插入到新表中。原来的表在删除和插入时会产生很多空洞，数据利用率不高，而重建表就可以解决这个问题。<code>MySQL 5.6</code>引入了 $Online\ \ DDL$ ，会先建立一个临时文件，保存原来表中的聚簇索引。在建立临时文件的过程中，在之后对原表的操作会被记录到日志文件中，并在临时文件建立完成后重新应用到临时文件中，从而允许重建表过程中的读写。<br>
        在不同的引擎中，$COUNT(*)$ 有不同的实现方式，<code>MyISAM</code>把表的行数存在了磁盘上，可以直接返回；<code>InnoDB</code>会把数据一行一行地读出来然后计数。由于<code>MVCC</code>的存在，在某个时间段表有多少行是不确定的，因此<code>InnoDB</code>并不能简单地将行数存起来。<code>MySQL</code>对此的优化策略是，如果表存在多个索引，那么会选择较小的一颗索引树进行扫描。<br>
        <code>MySQL</code>会给每个线程分配一块内存用于排序，称为 $sort_-buffer$。在 $sort_-buffer$ 里面的字段，会每次从数据库中取出数据并存到里面。当取出所有数据后再进行快速排序，如果内存空间不足，会使用外部排序。如果单行长度超过排序的最大长度，那么会将要排序的字段与<code>ID</code>关联，在排序完成后再通过<code>ID</code>回查。如果现有索引覆盖了需要排序的字段，那么会直接使用索引。对于使用聚集函数的排序，<code>MySQL</code>可能会使用临时表。临时表默认是在内存中的，如果超过了内存临时表的大小，就会转成磁盘临时表。<br>
        内存表指的是使用<code>Memory</code>引擎的表，这种表的数据都保存在内存里，系统重启的时候会被清空，但是表结构还在。临时表可以使用各种引擎类型，如果是使用<code>InnoDB</code>或者<code>MyISAM</code>引擎的临时表，写数据的时候是写到磁盘上的。一个临时表只能被创建它的 $session$ 访问，可以与普通表同名。</p>
<h2 id="2-日志">2. 日志</h2>
<p>        更新语句的执行过程其实与查询语句一样，但是会涉及日志模块。<br>
        <code>redo log</code>记录将要修改的记录，使用了<code>WAL</code> ( $Write-Ahead\ \ Logging$ ) 技术，即先写日志，再写磁盘。当有一条记录需要更新时，<code>InnoDB</code>会先把记录写到<code>redo log</code>中，并更新内存，之后在适当的时候，将这个操作记录更新到磁盘中，往往是在磁盘比较空闲的时候。<br>
        <code>InnoDB</code>的<code>redo log</code>是固定大小的，写到末尾时就循环回到开头重新写。$write\ \ pos$ 是当前记录的位置，随着数据写入后移。$check\ \ point$ 是当前要擦除的位置，在擦除之前要把记录更新到数据文件。$write\ \ pos$ 和 $check\ \ point$ 之间的部分可以记录新的操作。如果之间没有空白部分，需要等待执行记录。<br>
        <code>InnoDB</code>通过<code>redo log</code>，可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，称为 $crash-safe$ 。<br>
        <code>binlog</code>与<code>redo log</code>的区别有：</p>
<ol>
<li><code>redo log</code>是<code>InnoDB</code>特有的，<code>binlog</code>是<code>MySQL</code>的<code>Server</code>层实现的；</li>
<li><code>redo log</code>是物理日志，记录对某个数据页的修改；<code>binlog</code>是逻辑日志，记录语句的原始逻辑；</li>
<li><code>redo log</code>是循环写入的，<code>binlog</code>是可以追加写入的，即当文件达到一定空间后切换到下一个文件。</li>
</ol>
<p>        每当引擎将新数据更新到内存中时，就会把更新操作记录到<code>redo log</code>中，此时<code>redo log</code>处于 $prepare$ 状态。当执行器执行完成后，会生成操作的<code>binlog</code>。当事务提交之后，引擎会把刚写入的<code>redo log</code>改成 $commit$ 状态，完成更新。<br>
        写<code>redo log</code>的时候，可以通过 $innodb_-flush_-log_-at_-trx_-commit$ 参数设置：</p>
<ul>
<li>该值为 $0$ 时，事务提交时只是把<code>redo log</code>留在 $redo\ \ log\ \ buffer$ 中；</li>
<li>该值为 $1$ 时，每次事务提交都会把数据同步到磁盘上；</li>
<li>该值为 $2$ 时，在事务提交时只做写到 $page\ \ cache$ 。</li>
</ul>
<p>        <code>InnoDB</code>后台有一个线程，每隔 $1$ 秒，就会把 $redo\ \ log\ \ buffer$ 中的日志调用 $write$ 写到 $page\ \ cache$ 中，然后调用 $fsync$ 持久化到磁盘。事务执行中间过程的<code>redo log</code>也是直接写在 $redo\ \ log\ \ buffer$ 中的，也就是说，一个没有提交的事务也是可能已经持久化到磁盘的。<br>
        <code>binlog</code>会记录所有的逻辑操作，如果要恢复到以前的某个状态，可以通过取出<code>binlog</code>并重放操作。<code>binlog</code>的写入逻辑是先写到 $binlog\ \ cache$ ，在事务提交的时候清空 $binlog\ \ cache$ 并写到<code>binlog</code>文件中。事务的<code>binlog</code>不能拆开，要保证一次性写入。每个线程都有自己的 $binlog\ \  cache$ ，但是共用同一份<code>binlog</code>。通过参数 $sync_-binlog$ 控制写磁盘方式：</p>
<ul>
<li>该值为 $0$ 时，每次提交都会写到 $page\ \ cache$ ，不会写到磁盘；</li>
<li>该值为 $1$ 时，每次提交都会写到磁盘；</li>
<li>该值为 $N$ 时，每次提交都会写到 $page\ \ cache$ ，累计 $N$ 次后写到磁盘。</li>
</ul>
<p>        <code>redo log</code>和<code>binlog</code>是两个独立的逻辑，如果不使用两阶段提交，要么就是写完<code>redo log</code>再写<code>binlog</code>，或者反过来，但这会带来问题：</p>
<ul>
<li>先写<code>redo log</code>再写<code>binlog</code>。假设在<code>redo log</code>写完，<code>binlog</code>还没有写完时出现异常重启，那么<code>binlog</code>中会缺少对应数据，从而在之后备份恢复时缺少数据；</li>
<li>先写<code>binlog</code>再写<code>redo log</code>。如果在<code>binlog</code>写完后出现异常，那么由于<code>redo log</code>没写，事务无效，从而在之后备份恢复时多出新事务。</li>
</ul>
<p>        <code>binlog</code>存在三种格式：$statement$ 、$row$ 和 $mixed$ 。$statement$ 格式会记录操作的语句，$row$ 格式会记录操作的行，$mixed$ 格式则由<code>MySQL</code>自己判断是使用 $statement$ 还是 $row$ 。<br>
        在更新方面，<code>MySQL</code>引入 $change\ \ buffer$ 的概念。当需要更新一个数据页时，如果数据页在内存中就会直接更新，如果不在内存中，在不影响一致性的前提下，<code>InnoDB</code>会将更新操作缓存在 $change\ \ buffer$ 中，在下次查询访问改数据页时进行更新。$change\ \ buffer$ 是可持久化的数据，既在内存中有拷贝，也会被写到磁盘上。将 $change\ \ buffer$ 中的操作应用到原数据页的操作称为 $merge$ ，除了访问数据页外，系统也会有后台线程定期进行 $merge$ ，在数据库正常关闭的过程中，也会执行 $merge$ 。<br>
        $change\ \ buffer$ 和<code>redo log</code>的关系在于，$change\ \ buffer$ 中所做的更改会被写入到<code>redo log</code>当中，也就是<code>redo log</code>的记录先于 $change\ \ buffer$ 写入。<code>redo log</code>的目的是减少随机写磁盘的<code>I/O</code>消耗，即转换成顺序写；$change\ \ buffer$ 的目的是节省随机读磁盘的<code>I/O</code>消耗，如果数据在内存中，那么被更改后的数据可以直接从内存中获得。<br>
        当内存数据页与磁盘数据页内容不一致时，内存页就被称为脏页。在内存页被写入磁盘后，数据就一致了，这时内存页就是干净页。在<code>MySQL</code>查询的过程中，有时候会抖动一下，就是在刷脏页 ( $flush$ ) 的过程。引发 $flush$ 的情况有：<code>redo log</code>写满、系统内存不足需要淘汰脏页、系统空闲自动更新、<code>MySQL</code>正常关闭。一般情况下，$flush$ 都是由于系统内存不足导致的。<code>InnoDB</code>使用缓冲池 ( $buffer\ \ pool$ ) 管理内存，使用策略是尽量使用内存，因此对于一个长时间执行的数据库来说，未被使用的页面很少。当要读入的数据页不在内存时，就必须到缓冲池中申请数据页，即淘汰页面。<code>InnoDB</code>会控制一个脏页比例，以避免一次要淘汰过多的脏页。在默认情况下，如果<code>MySQL</code>在刷一个脏页的时候发现其相邻的下一个页面也是脏页，那么就会顺带刷掉，这种连坐机制可以很好的利用顺序<code>I/O</code>，减少随机<code>I/O</code> ( 在<code>MySQL 8.0</code>中默认不开启 ) 。<br>
        <code>InnoDB</code>的内存管理使用的是<code>LRU</code>算法，用链表实现。因为数据库经常会有全表读或者大范围扫描的需求，如果直接采用<code>LRU</code>，当我们对一些使用不太频繁的大表进行全表扫描，一段时间之后，$buffer\ \ pool$ 的命中率会明显下降。实际上，<code>InnoDB</code>对<code>LRU</code>算法做了改进，按照 $5:3$ 的比例把整个<code>LRU</code>链表分成了 $young$ 区域和 $old$ 区域，即靠近链表头部的 $\large\frac{5}{8}$ 是 $young$ 区域，靠近链表尾部的 $\large\frac{3}{8}$ 是 $old$ 区域。每次访问一个不存在于当前链表的数据页，依然淘汰链表尾部的数据页，新插入的数据页会放在 $old$ 区域的头部，并且在 $1$ 秒内对这个数据页的访问不会移动该数据页 ( 可以通过 $innodb_-old_-blocks_-time$ 控制 )。如果超过了 $1$ 秒，就会把它移到整个链表的头部。</p>
<h2 id="3-事务">3. 事务</h2>
<p>        当数据库上有多个事务同时执行的时候，就可能出现脏读 ( $dirty\ \ read$ )、不可重复读 ( $non-repeatable\ \ read$ )、幻读 ( $phantom\ \ read$ ) 的问题。</p>
<ul>
<li>未提交读。一个事务所做的变更在未提交时就能被其他事务看到。</li>
<li>提交读。一个事务所做的变更在提交后才能被其他事务看到。</li>
<li>可重复读。一个事务执行过程中看到的数据总是与事务启动时看到的数据一致。</li>
<li>串行化。对读写进行加锁，当出现读写冲突时，后一个事务必须等待前一个事务执行完成。</li>
</ul>
<p>        在实现上，数据库会创建一个视图，访问的时候以视图的逻辑结果为准。在可重复读的隔离级别下，这个视图在事务启动时创建，并且在整个事务的过程中一直使用。在提交读的隔离级别下，视图会在每个<code>SQL</code>语句开始执行时创建。<br>
        在<code>MySQL</code>中，每条记录在更新时都会记录一条回滚操作，即<code>undo log</code>，记录上的最新值通过回滚操作都可以得到前一个状态的值。在回滚段中的日志分为 $insert\ \ undo\ \ log$ 和 $update\ \ undo\ \ log$ ，前者是 $INSERT$ 时产生的，在事务提交后就可以丢弃；后者是 $DELETE$ 和 $UPDATE$ 时产生的，不仅在事务回滚时需要，一致性读也需要，只有当数据库所使用的视图中不存在比回滚日志更早的读视图时才会被删除，因此长事务的存在会导致日志长时间存在，占用大量存储空间。<br>
        <code>InnoDB</code>里面每个事务都有一个唯一的事务<code>ID</code> ( $trasaction\ \ id$ )，在事务开始时向<code>InnoDB</code>事务系统申请，按照申请顺序严格递增。每行数据都会对应一个事务版本，每次事务更新数据时都会把事务<code>ID</code>赋给这个数据作为版本，记为 $row\ \ trx_-id$ 。同时，旧的数据版本会被保留。在<code>undo log</code>中记录的每条数据都会有一个指向上一个版本数据的指针，每当需要获取之前某个版本的数据时，就会通过最新版本进行访问。<br>
        <code>InnoDB</code>存储引擎在数据库每行数据的后面添加了三个字段：</p>
<ul>
<li>$6$ 字节的事务<code>ID</code> ( $row\ \ trx_-id$ ) ：标识最近一次对本行记录做修改 ( $INSERT$ / $UPDATE$ ) 的事务的标识符，即最后一次修改本行记录的事务<code>ID</code>；</li>
<li>$7$ 字节的回滚指针字段：写入<code>undo log</code>中的记录指针；</li>
<li>$6$ 字节的 $row_-id$ 字段：包含一个随着新行插入而单调递增的 $row_-id$ ，如果表中没有指定主键或者唯一索引，<code>InnoDB</code>会使用该行的值作为主键生成聚簇索引。如果指定了主键或者唯一索引，聚簇索引中就不会包含该行数据。</li>
</ul>
<p>        在视图的实现上，<code>InnoDB</code>为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在活跃的所有事务<code>ID</code>。数组里面事务<code>ID</code>的最小值记为低水位，当前系统里面已经创建过的事务<code>ID</code>的最大值加 $1$ 记为高水位。这个视图数组和高水位，就组成了当前事务的一致性视图 ( $read-view$ )。对于当前事务的启动瞬间来说，一个数据版本 $row\ \ trx_-id$ ，有以下几种可能：</p>
<ul>
<li>如果小于低水位，代表这个版本是已提交事务或者是当前事务自己生成的，是可见的；</li>
<li>如果大于高水位，表示这个版本是由将来启动的事务生成的，是不可见的；</li>
<li>如果介于低水位和高水位之间，存在两种情况：
<ul>
<li>如果 $row\ \ trx_-id$ 在数组中，表示这个版本是由未提交的事务生成的，不可见；</li>
<li>如果 $row\ \ trx_-id$ 不在数组中，表示这个版本是由已提交的事务生成的，可见。</li>
</ul>
</li>
</ul>
<p>        此外，对于更新语句会有特殊情况。更新数据都是先读后写的，读只能读到当前值，称为当前读 ( $current\ \ read$ )。在更新的过程中会对要更新的数据进行加锁，因此如果存在多个事务对同一个数据进行更新，那么需要先获取锁。而如果对 $select$ 语句进行加锁的话，也是当前读。<br>
        幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的，因此幻读在提交读下才会出现。为了解决幻读问题，<code>InnoDB</code>引入了间隙锁 ( $Gap\ \ Lock$ )。间隙锁和行锁合称 $next-key\ \ lock$，每个 $next-key\ \ lock$ 是前开后闭区间。对同个区间的多个间隙锁不会冲突，这会导致一个区间可能会被多个<code>session</code>加锁，从而造成死锁。</p>
<h2 id="4-索引">4. 索引</h2>
<p>        三种常见的索引：哈希表、有序数组和搜索树。<br>
        哈希表是一种以键值对方式存储数据的结构，只适用于等值查询，当出现哈希碰撞时采用拉链法解决。有序数组采用递增顺序存储索引数据，但是只适用于静态存储引擎，因为在数组中插入和删除数据的代价很大。<br>
        <code>InnoDB</code>采用<code>B+</code>树作为索引。在<code>InnoDB</code>中，表都是根据主键顺序以索引的形式存放的，这种存储方式称为索引组织表。主键索引的叶子节点存储整行数据，也被称为聚簇索引 ( $clustered\ \ index$ )。非主键索引的叶子结点存储主键值，也被称为二级索引 ( $secondary\ \ index$ )。也就是说，基于非主键索引的查询需要多扫描一次索引树。<br>
        为了维护索引的有序性，在插入和删除的时候索引可能需要分裂或者合并。对于自增主键，由于可以保证上一条数据的主键值小于下一条数据，因此不会挪动其他记录。而有业务逻辑的字段做主键，往往不容易保证有序插入，成本相对较高。<br>
        最左前缀原则可以用于在索引中定位记录。但是对于不满足最左前缀原则的条件，<code>MySQL 5.6</code>引入了索引下推优化 ( $index\ \ condition\ \ pushdown$ )，可以在索引遍历的过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。<br>
        唯一索引保证了每条数据在表中只会出现一次，主键默认是唯一的。与普通索引相比，唯一索引在查询方面的性能相差几乎没有，因为<code>InnoDB</code>以页为单位读取数据，而大部分情况下普通索引相比于唯一索引仅仅多做了一次查询而已。对于唯一索引来说，所有的更新操作都要先判断是否违反唯一性约束，如果数据页不在内存中，会要求将数据页读入内存，而这时无法使用 $change\ \ buffer$ ；相比之下，普通索引可以用到 $change\ \ buffer$ 。如果要更新的页面存在于内存中，那么唯一索引和普通索引的更新时间几乎没有区别；但是如果不在内存中，唯一索引会要求将数据页读入内存中，这时唯一索引比起普通索引来讲性能就会差很多。<br>
        <code>MySQL</code>在执行语句之前无法精确的知道满足这个条件的记录有多少条，只能根据统计信息来估算记录数，这个统计信息就是区分度。一个索引上不同的值越多，这个索引的区分度就越好。一个索引上不同值的个数称为基数 ( $cardinality$ )。<code>MySQL</code>通过采样统计获取索引的基数，默认选择 $N$ 个数据页，统计页面上不同值得到平均值，然后乘以这个索引的页面值，从而得到基数。当变更的数据行数超过 $1/M$ 的时候，就会自动触发一次索引统计。对于持久化的索引统计，$N$ 默认是 $20$ ，$M$ 是 $10$ ；对于非持久化的统计，$N$ 默认是 $8$ ，$M$ 是 $16$ 。由于 $N$ 比较小，因此很容易不准确。由于不确定性的存在，所以<code>MySQL</code>优化器有时候会选择更差的索引进行搜索。<br>
        对于字符串数据，可以使用前缀索引减少查询次数，但是会损失一些区分度，而且无法使用覆盖索引。对于一些长字符串，前缀索引的效率较差，可以考虑使用倒序索引，或者建立一个哈希字段，再对哈希字段进行索引。</p>
<h2 id="5-锁">5. 锁</h2>
<p>        根据加锁范围，<code>MySQL</code>的锁大致可以分为全局锁、表级锁和行锁。<br>
        全局锁就是对整个数据库进行加锁，在加锁后整个数据库就处于只读状态。全局锁的典型使用场景是做全库逻辑备份，也就是把整库每个表都 $select$ 出来存成文本。对于支持可重复读的引擎，通过事务可以完成备份。而对于不支持可重复读的引擎比如<code>MyISAM</code>，就需要通过全局锁来进行备份。全局锁会在客户端断开时自动释放。<br>
        <code>MySQL</code>里面表级锁有两种：一种是表锁，一种是元数据锁 ( $meta\ \ data\ \ lock$, $MDL$ )。与全局锁一样，表锁会在客户端连接断开时自动释放。对于不支持更细粒度的引擎，表锁是最常用的处理并发的方式。而对于<code>InnoDB</code>这种支持行锁的引擎，则一般不实用。与表锁相比，<code>MDL</code>不需要显式使用，在访问一个表的时候会被自动加上，用于保证读写的正确性。当要对一个表做增删改查操作时，会加<code>MDL</code>读锁；当要对一个表做结构变更操作时，会加<code>MDL</code>写锁。读锁和写锁、写锁和写锁之间是互斥的，因此不能同时对一个表进行结构变更。<br>
        在<code>InnoDB</code>事务中，行锁是在需要的时候才加上，在事务结束的时候释放。如果事务需要多个锁，要把最可能造成锁冲突、最可能影响并发度的锁放在后面。出现死锁的时候，<code>InnoDB</code>提供了两种策略，第一种是等待超时，默认超时时间是 $50s$ ，第二种是进行死锁检测。每一个新来的进入阻塞状态的线程在发现行上有锁后都要进行死锁检测，如果不会产生死锁才会执行。</p>
<h2 id="6-分布式">6. 分布式</h2>
<h3 id="61-cap理论">6.1 <code>CAP</code>理论</h3>
<p>        <code>CAP</code>理论是指在分布式系统中，$C$ ( $Consistency$ )、$A$ ( $Availability$ )、$P$ ( $Partition\ \ Tolerance$ ) 这三个特征不能同时满足。在分布式系统中，现在的网络基础设施无法做到始终保持稳定，网络分区难以避免，牺牲 $P$ 相当于放弃使用分布式系统，因此在分布式系统中不能牺牲 $P$ 。对于涉及钱的交易，数据的一致性非常重要，因此保 $CP$ 弃 $A$ 是最佳选择。对于其他场景，大多数情况下的做法是选择 $AP$ 牺牲 $C$ ，因为很多情况下不需要太强的一致性，只要满足最终一致性即可。</p>
<h3 id="62-分布式数据存储">6.2 分布式数据存储</h3>
<p>        哈希是一种非常常用的数据分布式方法，其核心思想是确定一个哈希函数，通过计算得到对应的存储节点。哈希算法的一个优点是，只要哈希函数设置得当，可以很好地保证数据均匀性，缺点是稳定性较差。如果需要新增节点，那么原有节点中的数据就需要重新计算，即大规模数据迁移，降低稳定性。所以，哈希适用于同类型节点且节点数量比较固定的场景。<br>
        一致性哈希是指将存储节点和数据都映射到一个首尾相连的哈希环上，数据先通过哈希函数计算其在哈希环中的位置，存储节点可以根据<code>IP</code>地址再进行哈希，然后数据通过顺时针方向寻找的方式，来确定自己所属的存储节点。一致性哈希是对哈希的改进，在数据存储时采用哈希方式确定存储位置的基础上，又增加了一层哈希，也就是在数据存储前，对存储节点预先进行了哈希。这种改进可以很好地解决哈希方法存在的稳定性问题，当节点加入或退出时，仅影响该节点在哈希环上顺时针相邻的后继节点。比如前一个节点发生故障需要移除时，需要把该节点数据移到后一个节点，避免了大规模数据迁移。所以，一致性哈希方法比较适合同类型节点、节点规模会发生变化的场景。<br>
        带有限负载的一致性哈希方法的核心原理是给每个存储节点设置了一个存储上限值来控制存储节点添加或移除造成的数据不均匀。当数据按照一致性哈希算法找到相应的存储节点时，要先判断该存储节点是否达到了存储上限，如果达到上限，则继续寻找存储节点。<br>
        其实，哈希、一致性哈希、带有限负载的一致性哈希，都没有考虑节点异构性的问题。如果存储节点的性能好坏不一，数据分布方案还按照这些方法的话，还是没做到数据的均匀分布。带虚拟节点的一致性哈希方法，核心思想是根据每个节点的性能，为每个节点划分不同数量的虚拟节点，并将这些虚拟节点映射到哈希环中，然后再按照一致性哈希算法进行数据映射。带虚拟节点的一致性哈希方法比较适合异构节点，节点规模会发生变化的场景。</p>
<h3 id="63-分布式数据复制">6.3 分布式数据复制</h3>
<p>        从库与主库之间维持一个长连接，主库内部有一个线程，专门用于服务从库的长连接。完整的同步过程为：</p>
<ol>
<li>在从库上通过 $change\ \ master$ 命令，设置主库的<code>IP</code>、端口、用户名、密码以及<code>binlog</code>的起始位置 ( 文件名和偏移量 )；</li>
<li>在从库上执行 $start\ \ slave$ 命令，从库会启动一个 $io_-thread$ 和多个 $sql_-thread$ ，前者负责与主库建立连接；</li>
<li>主库校验完用户名和密码后，根据位置读取<code>binlog</code>并发送给从库；</li>
<li>从库将<code>binlog</code>写到<code>relay log</code>中；</li>
<li>$sql_-thread$ 读取<code>relay log</code>，解析命令并执行。</li>
</ol>
<p>        对于分布式存储系统中的数据复制技术来讲，也需要在一致性和可用性之间作出一些权衡。<br>
        同步复制技术是指，当用户请求更新数据时，主数据库必须要同步到备数据库之后才可以给用户返回，即如果主数据库没有同步到备数据库，用户的更新操作会一直阻塞。这种方式保证了 $CP$ ，牺牲了 $A$ 。由于性能不佳，影响用户体验，同步复制技术经常用于分布式数据库主备场景或对数据一致性有严格要求的场景，比如金融、交易之类的场景。<br>
        异步复制技术是指当用户请求更新数据时，主数据库处理完请求后可以直接给用户响应，而不必等待备数据库完成同步，即备数据库会异步进行数据的同步，用户的更新操作不会因为备数据库未完成数据同步而导致阻塞。显然，这种方式保证了<code>AP</code> ，牺牲了 $C$ 。异步复制技术大多应用在对用户请求响应时延要求很高的场景。<br>
        同步复制技术会满足数据的强一致性，但会牺牲可用性；异步复制技术会满足高可用，但会在一定程度上牺牲数据的一致性。半同步复制技术则介于两者之间。半同步复制技术是，用户发出写请求后，主数据库会执行写操作，并给备数据库发送同步请求，但主数据库不需要等待所有备数据库回复数据同步成功便可以响应用户，也就是说主数据库可以等待一部分备数据库同步完成后响应用户写操作执行成功。半同步复制技术通常有两种方式：</p>
<ol>
<li>当主数据库收到多个备数据库中的某一个回复数据同步成功后，便可以给用户响应写操作完成；</li>
<li>另一种是，主数据库等待超过一半节点 ( 包括主数据库
) 回复数据更新后，再给用户响应写操作成功。</li>
</ol>
<p>        <code>MySQL</code>集群在一主多备的场景下，也支持半同步复制模式，一般采用的是第一种半同步复制模式。普通的半同步是在主库事务提交后再等待从库同步，而增强型半同步会在主库事务提交前等待从库同步，避免了主从数据不一致的问题。</p>

            </div>
            <div class="meta post-footer"> <span>2021 Jun 21 20:33</span> <a href="/post/mysql%E7%AC%94%E8%AE%B0/"><i
                        class="fas fa-link"></i> link</a></div>
        </div>
        
        <div class="post">
            
            <center>
                <h1><a href="/post/csapp%E7%AC%94%E8%AE%B0/">CSAPP笔记</a></h1>
            </center>
            <div class="post-content">
                <h2 id="1-计算机系统漫游">1. 计算机系统漫游</h2>
<div class="highlight"><pre class="chroma"><code class="language-c" data-lang="c"><span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
</span><span class="cp"></span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">&#34;hello, world</span><span class="se">\n</span><span class="s">&#34;</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div><p>        $hello$ 程序生命周期的一开始是一个高级<code>C</code>程序，因为处于这种形式时，它是能够被人读懂的。为了运行 $hello.c$ ，每条<code>C</code>语句都必须被其他程序转化为一系列的低级机器语言指令。然后这些指令按照一种称为<strong>可执行目标程序</strong> ( $executable\ \ object\ \ program$ ) 的格式打包，并以二进制磁盘文件的形式存放起来。在<code>Unix</code>系统上，从源文件到目标文件的转化是由<strong>编译器驱动程序</strong> ( $compiler\ \ driver$ ) 完成的，这个过程可以分成四个阶段，执行这四个阶段的程序一起构成了编译系统：</p>
<ul>
<li>预处理阶段。预处理器 ( $cpp$ ) 根据以字符 $\#$ 开头的命令 ( $directives$ )，修改原始的<code>C</code>程序。修改完成后得到另一个<code>C</code>程序，通常是以 $.i$ 作为文件扩展名；</li>
<li>编译阶段：编译器 ( $ccl$ ) 将文本文件 $hello.i$ 翻译成文本文件 $hello.s$ ，它包含一个汇编语言程序；</li>
<li>汇编阶段：汇编器 ( $as$ ) 将 $hello.s$ 翻译成机器语言指令，并把这些指令打包成一种叫做<strong>可重定位</strong> ( $relocatable$ ) 目标程序的格式，将结果保存在目标文件 $hello.o$ 中；</li>
<li>链接阶段：$hello.c$ 调用了<code>C</code>库函数 $printf$ ，后者存在于名为 $printf.o$ 的单独的预编译目标文件中。链接器 ( $ld$ ) 负责处理目标文件的并入，处理完成后得到可执行文件。可执行文件加载到存储器后，由系统负责执行。</li>
</ul>
<p><img src="/image/2021-05-19-01.png" alt="一个典型系统的硬件组成"></p>
<ul>
<li><strong>总线</strong>：总线是贯穿整个系统的电子管道，携带信息字节并负责在各个部件间传递。通常被设计成传送定长的字节块，也就是<strong>字</strong> ( $word$ )；</li>
<li><code>I/O</code><strong>设备</strong>：系统与外界的联系通道。每个<code>I/O</code>设备都是通过一个控制器或适配器与<code>I/O</code>总线连接。控制器是<code>I/O</code>设备本身中或是系统的主板上的芯片组，而适配器是一块插在主板槽上的卡；</li>
<li><strong>主存</strong>：临时存储设备，在处理器执行程序时，用于存放程序和程序处理的数据。物理上来说，主存是一组<code>DRAM</code>芯片组成的，逻辑上来说，主存是由一个线性字节数组组成的；</li>
<li><strong>处理器</strong> ( <code>CPU</code> )：解释 ( 或执行 ) 存储在主存中指令的引擎，核心是<strong>程序计数器</strong> ( $PC$ )。寄存器文件 ( $register\ \ file$ ) 是一个小存储设备，由一些字长大小的寄存器组成。算术逻辑单元 ( $ALU$ ) 计算新数据和地址值。</li>
</ul>
<p>        一个典型的寄存器文件只存储几百字节的信息，主存可存放几百万字节。然而，处理器从寄存器文件中读取数据比从主存中读取要快几乎 $100$ 倍。针对这种处理器与主存之间的差异，系统设计者采用了更小更快的存储设备，称为<strong>高速缓存存储器</strong> ( $cache\ \ memories$ )。位于处理器芯片上的<code>L1</code>高速缓存的容量可以达到数万字节，访问速度几乎和访问寄存器文件一样快。容量为数十万到数百万字节的<code>L2</code>高速缓存是通过一条特殊的总线连接到处理器的，访问<code>L2</code>的时间开销要比访问<code>L1</code>的开销大 $5$ 倍。</p>
<h2 id="2-信息表示和处理">2. 信息表示和处理</h2>
<p>        大多数计算机采用 $8$ 位的块，或叫做<strong>字节</strong> ( $byte$ ) 作为最小的可寻址的存储器单位。机器级程序将存储器视为一个非常大的字节数组，称为<strong>虚拟存储器</strong> ( $virtual\ \ memory$ )。编译器和运行时系统的一个任务就是将存储器空间划分为可管理的单元，用来存放不同的<strong>程序对象</strong> ( $program\ \ object$ )，也就是程序数据、指令和控制信息。<br>
        每台计算机都有一个<strong>字长</strong> ( $word\ \ size$ )，指明整数和指针数据的标称大小 ( $normal\ \ size$ )。字长决定的最重要的系统参数就是虚拟地址空间的最大大小。<br>
        <strong>无符号</strong> ( $unsigned$ ) 编码是基于传统的二进制表示法的，<strong>二进制补码</strong> ( $tow&rsquo;s-complement$ ) 编码是表示有符号整数的最常见的方式，<strong>浮点数</strong> ( $floating-point$ ) 编码是表示实数的科学记数法的以二为基数的版本。将一个无符号数转换为一个更大的数据类型，只需要在开头添加 $0$ 即可，称为零扩展 ( $zero\ \ extension$ )。将一个二进制补码数字转换为一个更大的数据类型，规则是执行一个符号扩展 ( $sign\ \ extension$ )，在开头添加最高有效位的值。</p>
<h2 id="3-程序的机器级表示">3. 程序的机器级表示</h2>
<p>        与<code>C</code>代码相比，汇编代码可以看到一些被屏蔽的处理器状态，包括：</p>
<ul>
<li>程序计数器 ( $\%eip$ )</li>
<li>整数寄存器文件，包含 $8$ 个被命名的位置，分别存储 $32$ 位的值；</li>
<li>条件码寄存器保存着最近执行的算术指令的状态信息，用来实现控制流中的条件变化；</li>
<li>浮点寄存器文件包含 $8$ 个位置，用来存放浮点数据。</li>
</ul>
<p>        程序存储器 ( $program\ \ memory$ ) 包含程序的目标代码，操作系统需要的一些信息，用来管理过程调用和返回的运行时栈，以及用户分配的存储器块。程序存储器采用虚拟地址寻址。<br>
        一个<code>IA32</code>中央处理单元 ( $CPU$ ) 包含一组八个存储 $32$ 位值的寄存器，这些寄存器用来存储整数数据和指针。在平面寻址中，对特殊寄存器的需求已经大为降低了，在大多数情况中，前六个寄存器都可以看成通用寄存器，对它们的使用没有限制。<br>
        大多数指令有一个或多个操作数 ( $operand$ )，指示出执行一个操作中要引用的源数据值，以及放置结果的目的的位置。源数据值可以以常数形式给出，或是从寄存器或存储器中读出，结果可以存放在寄存器或存储器中。因此，各种操作数的可能性被分为三种类型。第一种是立即数 ( $immediate$ )，也就是常数值。第二种类型是寄存器 ( $register$ )，它表示某个寄存器的内容。第三种是存储器引用，根据计算出来的地址访问某个存储器位置。<br>
        除了整数寄存器，<code>CPU</code>还包含一组单个位的条件码 ( $condition\ \ code$ ) 寄存器，它们描述了最近的算术或逻辑操作的属性。最有用的条件码是：</p>
<ul>
<li>CF：进位标志；</li>
<li>ZF：零标志；</li>
<li>SF：符号标志；</li>
<li>OF：溢出标志。</li>
</ul>
<p>        一个过程调用包括将数据 ( 以过程参数和返回值的形式 ) 和控制从代码的一部分传递到另一部分。另外，它还必须在进入时为过程的局部变量分配空间，并在退出时释放这些空间。<code>IA32</code>程序用程序栈来支持过程调用，为单个过程分配的那部分栈称为栈帧 ( $stack\ \ frame$ )。假设过程 $P$ 调用过程 $Q$ ，$Q$ 的参数放在 $P$ 的栈帧中，$P$ 的返回地址被压入栈中，形成 $P$ 的栈帧的末尾。过程 $Q$ 也会用栈来保存其他不能存放在寄存器中的局部变量。<br>
        程序寄存器组是唯一一个被所有过程共享的资源。虽然在给定时刻只能有一个过程是活动的，但我们必须保证当调用者调用被调用者时，被调用者不会覆盖某个调用者稍后会使用的寄存器的值。为此，<code>IA32</code>采用了一组统一的寄存器使用惯例，所有的过程都必须遵守，包括程序库中的过程。<br>
        <code>C</code>的 $struct$ 声明创建一个数据类型，将可能不同类型的对象聚合到一个对象中。结构的各个组成部分是用名字来引用的，实现类似于数组的实现。编译器保存关于每个结构类型的信息，指示每个域 ( $field$ ) 的字节偏移。<br>
        许多计算机系统对基本数据类型的可允许地址做出了一些限制，要求某种类型的对象的地址必须是某个值的倍数。这种对齐限制简化了处理器和存储器系统之间接口的硬件设计。例如，假设一个处理器总是从存储器中取 $8$ 个字节出来，则地址必须为 $8$ 的倍数。如果可以保证所有的 $double$ 都将它们的地址对齐成 $8$ 的倍数，那么就可以用一个存储器操作来读或者写值了。<br>
        <code>C</code>对于数组引用不进行任何边界检查，而且局部变量和状态信息都存放在栈中。一个对越界的数组元素的写操作破坏了存储在栈中的状态信息，当程序使用这个被破坏的状态，试图重新加载寄存器或执行 $ret$ 指令时，就会出现很严重的错误。一种特别常见的状态破坏称为缓冲区溢出 ( $buffer\ \ overflow$ )。例如，在栈中分配某个字节数组来保存一个字符串，但是字符串的长度超出了为数组分配的空间时，就会发生缓冲区溢出。<br>
        浮点单元包括 $8$ 个浮点寄存器，但是和普通寄存器不一样，这些寄存器是被当成一个浅栈 ( $shallow\ \ stack$ ) 来对待的。当压入栈中的值超过 $8$ 个时，栈底的那些值就会消失。对于返回值为 $float$ 或 $double$ 类型的函数，结果是以扩展精度格式在浮点寄存器栈顶部返回的。</p>
<h2 id="4-处理器体系结构">4. 处理器体系结构</h2>
<p>        处理器必须执行一系列的指令，每条指令执行某个简单操作，被编码为由一个或多个字节序列组成的二进制格式。一个处理器支持的指令和指令的字节级编码称为它的<code>ISA</code> ( $instruction-set\ \ architecture$，指令集体系结构 )。<code>ISA</code>在编译器编写者和处理器设计人员之间提供了一个概念抽象层，编译器编写者只需要知道允许哪些指令，以及它们是如何编码的；而处理器设计者必须建造出执行这些指令的处理器。<br>
        在硬件设计中，电子电路被用来计算位的函数 ( $functions\ \ on\ \ bits$ )，以及在各种存储器元素中存储位。大多数现代电路技术都是用信号线上的高电压或低电压来表示不同的位值。通常的技术中，逻辑 $1$ 是用 $1.0$ 伏特左右的高电压表示的，而逻辑 $0$ 是用 $0.0$ 伏特左右的低电压表示的。要实现一个数字系统需要三个主要的组成部分：计算位的函数的组合逻辑、存储位的存储器元素，以及控制存储器元素更新的时钟信号。<br>
        通常，处理一条指令包括很多操作。我们将它们组织成某个特殊的阶段序列，使得即使指令的动作差异很大，但所有的指令都遵循统一的序列。处理指令的阶段有：</p>
<ul>
<li>取指 ( $fetch$ )：取指阶段从存储器读入指令，地址为程序计数器的值。从指令中抽取出指令指示符字节的两个四位部分，称为 $icode$ ( 指令代码 ) 和 $ifun$ ( 指令功能 )；</li>
<li>解码 ( $decode$ )：解码阶段从寄存器文件读入最多两个操作数；</li>
<li>执行 ( $execute$ )：执行阶段，<code>ALU</code>要么执行指令指明的操作，计算存储器引用的有效地址，要么增加或减少栈指针；</li>
<li>访存 ( $memory$ )：访存阶段可以将数据写入存储器，或者从存储器读出数据；</li>
<li>写回 ( $write\ \ back$ )：写回阶段最多可以写两个结果到寄存器文件；</li>
<li>更新<code>PC</code> ( $PC\ \ update$ )：将<code>PC</code>设置成下一条指令的地址。</li>
</ul>
<p>        处理器无限循环执行这些阶段，只有在遇到 $halt$ 或一些错误情况时，才会停下来，包括非法存储器地址和非法指令。<br>
        六个阶段按序执行，产生的处理器设计称为 $SEQ$ 。重新排列六个阶段，使得更新<code>PC</code>阶段在一个周期开始时执行，而不是结束时才执行，这样产生的处理器设计称为 $SEQ+$ 。$SEQ+$ 对控制逻辑的唯一修改就是重新定义了<code>PC</code>的计算，使它使用以前的状态值。<br>
        在流水线化的系统中，待执行的任务被划分成了若干个独立的阶段。流水线化的一个重要特性就是增加了系统的吞吐量 ( $throughput$ )，不过它也会轻微地增加执行时间 ( $latency$ )。对硬件设计者来说，将系统计算设计划分成一组具有相同延迟的阶段是一个主要的挑战。现代处理器为了提高时钟频率，采用了很深的 ( $15$ 或更多的阶段 ) 流水线。处理器设计师将指令的执行划分成很多非常简单的步骤，这样一来每个阶段的延迟就很小。电路设计者小心地设计流水线寄存器，使其延迟尽可能的小。芯片设计者也必须小心地设计时钟传播网络，以保证时钟在整个芯片上同时改变。<br>
        对于程序来说，相邻指令之间很可能是相关的，相关包括数据相关 ( $data\ \ dependency$ )、顺序相关 ( $sequential\ \ dependency$ ) 和控制相关 ( $control\ \ dependency$ )。为了处理相关指令，流水线需要调整指令的执行顺序，保证在执行一条指令时，其前一个相关指令执行完毕。<br>
        流水线化的设计的目的就是每个时钟周期都发射 ( $issue$ ) 一条新指令，也就是说每个时钟周期都有一条新指令进入执行阶段并最终完成。为了达到这个目的，我们必须在取出当前指令后，马上确定下一条指令的位置。不幸的是，如果取出的指令是条件分支指令，要到几个周期后，也就是指令通过执行阶段后，才能知道是否要选择分支。类似地，如果取出的指令是 $ret$ ，要到指令通过访存阶段，才能确定返回地址。猜测分支方向并根据猜测开始取指的技术称为分支预测。<br>
        相关的存在可能会导致流水线产生计算错误，称为冒险。同相关一样，冒险也可以分为数据冒险 ( $data\ \ hazard$ ) 和控制冒险 ( $control\ \ hazard$ )。暂停 ( $stalling$ ) 是一种常用的用来避免冒险的技术。暂停时，处理器会停止流水线中一条或多条指令，直到冒险条件不再满足。只要一条指令的源操作数会被流水线后面某个阶段中的指令产生，处理器就会通过将指令阻塞在解码阶段来避免数据冒险。暂停技术就是让一组指令阻塞在它们的阶段，而允许其他指令继续通过流水线。将结果值直接从一个流水线阶段传到较早阶段的技术称为数据转发 ( $data\ \ forwarding$ )，通过使用转发可以在一定程度上避免暂停。有一类数据冒险不能单纯使用转发解决，因为存储器读是在流水线较后面发生的，称为加载/使用冒险 ( $load/use\ \ hazard$ )，可以通过结合暂停和转发来解决，称为加载互锁 ( $load\ \ interlock$ )。<br>
        对于一些简单的操作，比如数字加法，可以在执行阶段一个周期内处理完。但是对于一些更加复杂操作指令，例如过整数乘法和除法，以及浮点运算，执行时间会需要几个或者几十个周期。为了实现这些指令，我们既需要额外的硬件来执行这些计算，还需要一种机制来协调这些指令的处理与流水线其他部分之间的关系。可以通过采用独立于主流水线的特殊硬件功能单元来处理较为复杂的操作。</p>
<h2 id="5-优化程序性能">5. 优化程序性能</h2>
<p>        对许多程序都很有用的度量标准是每元素的周期数 ( $cycles\ \ per\ \ element$, $CPE$ )。这种度量标准帮助我们在更详细的级别上理解迭代程序的循环性能。<br>
        <code>P6</code>微体系结构是自 $20$ 世纪 $90$ 年代后期以来许多厂商生产的高端处理器的典型。在工业界称为超标量 ( $superscalar$ )，意思是它可以在每个时钟周期执行多个操作，而且是乱序的。整个设计有两个主要部分：<code>ICU</code> ( $Instruction\ \ Control\ \ Unit$ ) 和<code>EU</code> ( $Execution\ \ Unit$ )，前者负责从存储器中读出指令序列，并根据这些指令序列生成一组针对程序数据的基本操作，而后者执行这些操作。<br>
        <code>ICU</code>从指令高速缓存 ( $instruction\  \ cache$ ) 中读取指令，指令高速缓存是一个特殊的高速缓存存储器，它包含最近访问的指令。通常，<code>ICU</code>会在当前正在执行的指令很早之前取指，所以它有足够的时间对指令解码，并把操作发送到<code>EU</code>。不过，有一个问题，那就是当程序遇到分支时，程序有两个可能的前进方向。一种可能会选择分支，控制被传递到分支目标；另一种可能是不选择分支，控制被传递到指令序列的下一条指令。现代处理器采用了一种称为分支预测 ( $branch\ \ prediction$ ) 的技术，在这种技术中处理器会预测是否选择分支，同时还预测分支的目标地址。使用一种称为投机执行 ( $speculative\ \ execution$ ) 的技术，处理器会开始取出它预测的分支处的指令并对指令解码，甚至于在它确定分支预测是否正确之前就开始执行这些操作。如果过后它确定分支预测错误，它会将状态重新设置到分支点的状态。<br>
        <code>EU</code>接收来自指令读取单元的操作。通常，它会每个时钟周期接收若干个操作。这些操作会被分派到一组功能单元中，它们会执行实际的操作。这些功能单元是专门用来处理特定类型的操作。<br>
        在<code>ICU</code>中，退役单元 ( $Retirement\ \ Unit$ ) 记录正在进行的处理，并确保它遵守机器级程序的顺序语义。指令解码时，关于指令的信息被放置在一个先进先出的队列中。这个信息会一直保持在队列中，直到两个结果中的一个发生。首先，一旦指令的操作完成了，而所有导致这条指令的分支点也都被确认为预测正确，那么这条指令就可以退役了，所有对程序寄存器的更新都可以被实际执行了。另一方面，如果导致该指令的某个分支点预测错误，这条指令会被清空，丢弃所有计算出来的值。通过这种方法，错误的预测就不会改变程序状态了。<br>
        循环并行性的好处是受描述计算的汇编代码的能力限制的。特别地，<code>IA32</code>指令集只有很少量的寄存器来存放累积的值。如果我们有并行度 $p$ 超过了可用的寄存器数量，编译器会诉诸于溢出 ( $spilling$ )，将某些临时值存放到栈中。一旦出现这种情况，性能会急剧下降。</p>
<h2 id="6-存储器层次结构">6. 存储器层次结构</h2>
<p>        存储器系统 ( $memory\ \ system$ ) 是一个具有不同容量、成本和访问时间的存储 ( $storage$ ) 设备的层次结构。</p>
<h3 id="61-主存">6.1 主存</h3>
<p>        随机访问存储器 ( $random-access\ \ memory$, $RAM$ ) 分为两类——静态的和动态的。静态<code>RAM</code> ( <code>SRAM</code> ) 比动态<code>RAM</code> ( <code>DRAM</code> ) 更快，但也贵得多。<code>SRAM</code>用来作为高速缓存存储器，既可以在<code>CPU</code>芯片上，也可以不在<code>CPU</code>芯片上。<code>DRAM</code>用来作为主存以及图形系统的帧缓冲区。典型地，一个桌面系统的<code>SRAM</code>不会超过几兆字节，但是<code>DRAM</code>却有几百或几千兆字节。<br>
        <code>DRAM</code>芯片中的单元 ( 位 ) 被分成 $d$ 个超单元 ( $supercell$ )，每个超单元都是由 $w$ 个<code>DRAM</code>单元组成的。一个 $d \times w$ 的<code>DRAM</code>总共存储了 $dw$ 位信息。超单元被组织成一个 $r$ 行 $c$ 列的长方形阵列，这里 $rc = d$ 。每个超单元有形如 $(i, j)$ 的地址，这里 $i$ 表示行，而 $j$ 表示列。<br>
        每个<code>DRAM</code>芯片被连接到某个称为存储控制器的电路，这个电路可以一次传送 $w$ 位到每个<code>DRAM</code>芯片或一次从每个<code>DRAM</code>芯片传出 $w$ 位。为了读出超单元 $(i, j)$ 的内容，存储控制器将行地址 $i$ 发送到<code>DRAM</code>，然后是列地址 $j$ 。行地址 $i$ 被称为<code>RAS</code> ( $Row\ \ Access\ \ Strobe$ ，行访问选通脉冲 ) 请求。列地址 $j$ 被称为<code>CAS</code> ( $Column\ \ Access\ \ Strobe$ ，列访问选通脉冲 ) 请求。<code>RAS</code>和<code>CAS</code>请求共享同样的<code>DRAM</code>地址管脚 ( $pin$ )，信息通过管脚的外部连接器流入和流出芯片，每个管脚携带一个一位的信号。为了读出某一单元数据，存储控制器首先发送行地址，<code>DRAM</code>会将对应行的所有内容都拷贝到行缓冲区。接下来，存储控制器再发送列地址，<code>DRAM</code>从行缓冲区中拷贝出对应列的超单元数据并发送到存储控制器。电路设计者将<code>DRAM</code>组织成二维阵列而不是线性数组的一个原因是降低芯片上地址管脚的数量，缺点是必须分两步发送地址，增加了访问时间。<br>
        如果断电，<code>DRAM</code>和<code>SRAM</code>会丢失它们的信息，从这个意义上说，它们是易失的 ( $volatile$ )。另一方面，非易失性存储器 ( $nonvolatile\ \ memory$ ) 即使是在关电后，仍然保存着它们的信息。出于历史原因，虽然<code>ROM</code>中有的类型既可以读也可以写，但是它们整体上都被称为<code>ROM</code> ( $read-only\ \ memory$ )。<code>ROM</code>是以它们能够被重编程 ( 写 ) 的次数和对它们进行重编程所用的机制来区分的。存储在<code>ROM</code>设备中的程序通常被称为固件 ( $firmware$ )。当一个计算机系统通电以后，它会运行存储在<code>ROM</code>中的固件。</p>
<h3 id="62-总线">6.2 总线</h3>
<p>        数据流通过称为总线 ( $bus$ ) 的共享电路在处理器和<code>DRAM</code>主存之间来来回回。每次<code>CPU</code>和主存之间的数据传送都是通过一系列步骤来完成的，这些步骤称为总线事务 ( $bus\ \ transaction$ )。读事务 ( $read\ \ transaction$ ) 从主存传送数据到<code>CPU</code>，写事务 ( $write\ \ transaction$ ) 从<code>CPU</code>传送数据到主存。总线是一组并行的导线，能携带地址、数据和控制信号。取决于总线设计，数据和地址信号可以共享同一组导线，也可以使用不同的。同时，两个以上的设备也能共享同一个总线。</p>
<p><img src="/image/2021-05-19-02.png" alt="典型的连接CPU和主存的总线结构"></p>
<p>        典型的桌面系统的结构，主要部件是<code>CPU</code>芯片、<code>I/O</code>桥接器 ( $I/O\ \ bridge$，包括存储控制器 ) 以及组成主存的<code>DRAM</code>存储器模块。这些部件由一对总线连接起来，其中一条总线是系统总线 ( $system\ \ bus$ )，它将<code>CPU</code>连接到<code>I/O</code>桥接器，另一条总线是存储器总线 ( $memory\ \ bus$ )，它将<code>I/O</code>桥接器连接到主存。<code>I/O</code>桥接器将系统总线的电信号翻译成存储器总线的电信号。</p>
<pre><code class="language-x86asm" data-lang="x86asm">movl A, %eax
</code></pre><p>当<code>CPU</code>执行上述加载操作时，地址 $A$ 的内容会被加载到寄存器 $\%eax$ 中。<code>CPU</code>芯片上称为总线接口 ( $bus\ \ interface$ ) 的电路发起总线上的读事务。读事务由三步骤组成。首先，<code>CPU</code>将地址 $A$ 放到系统总线上。<code>I/O</code>桥接器将信号传递到存储器总线，接下来，主存感受到存储器总线上的地址信号，从存储器总线读地址，从<code>DRAM</code>取出数据字，并将数据写到存储器总线。<code>I/O</code>桥接器将存储器总线信号翻译成系统总线信号，然后传递到系统总线。最后，<code>CPU</code>感受到系统总线上的数据，从总线上读数据，并将数据拷贝到寄存器 $\%eax$ 。</p>
<h3 id="63-磁盘">6.3 磁盘</h3>
<p>        磁盘是由盘片 ( $platter$ ) 构成的，每个盘片有两面，表面 ( $surface$ ) 覆盖着磁性记录材料。盘片中间有一个可以旋转的主轴 ( $spindle$ )，它使得盘片以固定的旋转速率 ( $rotational\ \ rate$ ) 旋转。每个表面由一组称为磁道 ( $track$ ) 的同心圆组成的，且每个磁道被划分为一组扇区 ( $sector$ )。每个扇区包含相等数量的数据位 ( 通常是 $512$ 字节 )，这些数据编码在扇区上的磁性材料中。扇区之间由一些间隙 ( $gap$ ) 分隔开，这些间隙中不存储数据位。间隙存储用来标识扇区的格式化位。磁盘是由一个或多个叠放在一起的盘片组成的，它们放在一个密封的包装里，整个装置通常被称为磁盘驱动器 ( $disk\ \ drive$ )。磁盘制造商通常用柱面 ( $cylinder$ ) 来描述多个盘片驱动器的构造，这里，柱面是所有盘片表面上到中心主轴的距离相等的磁道的集合。<br>
        磁盘用连接到一个传动臂 ( $actuator\ \ arm$ ) 的读/写头 ( $read/write\ \ head$ ) 来读写存储在磁性表面的位。通过沿着半径轴移动传动臂，驱动器可以将读/写头定位在盘面上的任何磁道上，这样的机械运动称为寻道 ( $seek$ )。<br>
        像图形卡、监视器、鼠标、键盘和磁盘这样的设备都是通过诸如<code>Intel</code>的<code>PCI</code> ( $Peripheral\ \ Component\ \ Interconnect$，外围设备互连 ) 总线这样的<code>I/O</code>总线连接到<code>CPU</code>和主存的。同系统总线和存储器总线不同，诸如<code>PCI</code>这样的<code>I/O</code>总线设计成与底层<code>CPU</code>无关。<br>
        虽然<code>I/O</code>总线比系统总线和存储器总线慢，但是它可以容纳种类繁多的第三方设备，例如<code>USB</code>、图形卡等。其他的设备，例如网络适配器，可以通过将适配器插入到主板上空的扩展槽中，从而连接到<code>I/O</code>总线，这些插槽提供了到总线的直接电路连接。<br>
        <code>CPU</code>使用一种称为存储器映射<code>I/O</code> ( $memory-mapped\ \ I/O$ ) 的技术来向<code>I/O</code>设备发射命令。在使用存储器映射<code>I/O</code>的系统中，地址空间中有一块地址是为与<code>I/O</code>设备通信保留的。每个这样的地址称为一个<code>I/O</code>端口 ( $I/O\ \ port$ )。当一个设备连接到总线时，它与一个或多个端口相关联 ( 或它被映射到一个或多个端口 )。<br>
        在磁盘控制器收到来自<code>CPU</code>的读命令之后，它将逻辑块号翻译成一个扇区地址，读该扇区的内容，然后将这些内容直接传送到主存，不需要<code>CPU</code>的干涉，这个设备称为<code>DMA</code> ( $direct\ \ memory\ \ access$ )，这种数据传送称为<code>DMA</code>传送 ( $DMA\ \ transfer$ )。在<code>DMA</code>传送完成，磁盘扇区的内容被安全地存储在主存中以后，磁盘控制器通过给<code>CPU</code>发送一个中断信号来通知<code>CPU</code>。基本思想是中断会发信号到<code>CPU</code>芯片的一个外部管脚上，这会导致<code>CPU</code>暂停它当前正在做的工作，跳转到一个操作系统函数，这个函数会记录下<code>I/O</code>已经完成，然后将控制返回到<code>CPU</code>被中断的地方。</p>
<h3 id="64-局部性">6.4 局部性</h3>
<p>        一个编写良好的计算机程序倾向于展示出良好的局部性 ( $locality$ )。也就是，它们倾向于引用的数据项邻近于其他最近引用过的数据项，或者邻近于最近自我引用过的数据项。局部性通常有两种形式：时间局部性 ( $temporal\ \ locality$ ) 和空间局部性 ( $spatial\ \ locality$ )。在一个具有良好时间局部性的程序中，被引用过一次的存储器位置很可能在不远的将来再被多次引用。在一个具有良好空间局部性的程序中，如果一个存储器位置被引用了一次，那么程序很可能在不远的将来引用附近的一个存储器位置。<br>
        一般而言，高速缓存 ( $cache$ ) 是一个小而快速的存储设备，它作为存储在更大也更慢的设备中的数据对象的缓冲区域，使用高速缓存的过程被称为缓存 ( $caching$ )。存储器层次结构的中心思想是，对于每个 $k$ ，位于 $k$ 层的更快更小的存储设备作为位于 $k + 1$ 层的更大更慢的存储设备的缓存。换句话说，层次结构中的每一层都缓存来自较低一层的数据对象。<br>
        当发生缓存不命中时，第 $k$ 层的缓存就必须执行某个替换策略，确定把它从第 $k + 1$ 层中取出的块放在哪里。硬件缓存通常使用的是更严格的放置策略，这个策略将第 $k + 1$ 层的某个块限制放置在第 $k$ 层块的一个小的子集中 ( 有时只是一个块 )。这种限制性的放置策略会引起冲突不命中 ( $conflict\ \ miss$ )。当工作集的大小超过缓存的大小时，缓存会经历容量不命中 ( $capacity\ \ miss$ )。</p>
<h3 id="65-高速缓存">6.5 高速缓存</h3>
<p>        早期计算机系统的存储器层次结构只有三层：<code>CPU</code>寄存器、主<code>DRAM</code>存储器和磁盘存储设备。不过由于<code>CPU</code>和主存之间逐渐增大的差距，系统设计者被迫在<code>CPU</code>寄存器文件和主存之间插入了一个小的<code>SRAM</code>存储器，称为<code>L1</code>高速缓存。在现代系统中，<code>L1</code>高速缓存位于<code>CPU</code>芯片上，访问速度几乎和寄存器一样快。随着<code>CPU</code>和主存之间的性能差距不断增大，系统设计者在<code>L1</code>高速缓存和主存之间又插入了一个高速缓存，称为<code>L2</code>高速缓存，可以将<code>L2</code>高速缓存连接到存储器总线，或者连接到它自己的高速缓存总线 ( $cache\ \ bus$ )。有些高性能系统，甚至于在存储器总线上还有一个层高速缓存，称为<code>L3</code>高速缓存。<br>
        考虑一个计算机系统，其中每个存储器地址有 $m$ 位，形成 $M = 2^m$ 个不同的地址。这样一个机器的高速缓存被组织成一个 $S = 2^s$ 个高速缓存组 ( $cache\ \ set$ ) 的数组。每个组包含 $E$ 个高速缓存行 ( $cache\ \ line$ )。每个行是由一个 $B = 2^b$ 字节的数据块 ( $block$ ) 组成的，一个有效位 ( $valid\ \ bit$ ) 指明这个行包含的数据是否有意义，还有 $t = m - (b + s)$ 个标记位 ( $tag\ \ bit$ )，唯一标识存储在这个高速缓存行中的块。<br>
        当一条加载指令指示<code>CPU</code>从主存地址 $A$ 中读一个字时，它将地址 $A$ 发送到高速缓存。如果高速缓存正保存着地址 $A$ 处那个字的拷贝，它就立即将那个字发回给<code>CPU</code>。<br>
        假设<code>CPU</code>写一个已经缓存了的字 $w$ ，在高速缓存更新了它的 $w$ 的拷贝之后，要更新在存储器中对应的拷贝。最简单的方法称为直写 ( $well-through$ )，就是立即将 $w$ 的高速缓存块写回到存储器中。虽然简单，但是直写的缺点是每条存储指令都会引起总线上的一个写事务。另一种方法，称为写回 ( $write-back$ )，尽可能地推迟存储器更新，只有当替换算法要驱逐已更新的块时，才把它写到存储器。虽然减少了总线事务的数量，但是增加了复杂性，高速缓存必须为每个高速缓存行维护一个额外的修改位 ( $dirty\ \ bit$ )，表明这个高速缓存块是否被修改过。另一个问题是如何处理写不命中。一种方法，称为写分配 ( $write-allocate$ )，加载相应的存储器块到高速缓存中，然后更新这个高速缓存块。写分配利用了写的空间局部性，但是缺点是每次不命中都会导致一个块从存储器传送到高速缓存。另一种方法称为非写分配 ( $non-write-allocate$ )，避开高速缓存，直接把这个字写到存储器中。直写高速缓存通常是非写分配的，写回高速缓存通常是写分配的。<br>
        只保存指令的高速缓存称为 $i-cache$ ，只保存数据的高速缓存称为 $d-cache$ ，两者都保存的称为统一的高速缓存 ( $unified\ \ cache$ )。一个典型的桌面系统<code>CPU</code>芯片本身就包括一个<code>L1</code> $i-cache$ 和一个<code>L1</code> $d-cache$ 。</p>
<h2 id="7-链接">7. 链接</h2>
<p>        <strong>链接</strong> ( $linking$ ) 就是将不同部分的代码和数据收集和组合成一个单一文件的过程，这个文件可被加载 ( 或被拷贝 ) 到存储器并执行。链接可以执行于编译时 ( $compile\ \ time$ )，也就是在源代码被翻译成机器代码时；也可以执行于加载时 ( $load\ \ time$ )，也就是在程序被加载器 ( $loader$ ) 加载到存储器并执行时；甚至于运行时 ( $run\ \ time$ ) 由应用程序来执行。在早期的计算机系统中，链接是手动执行的。在现代系统中，链接是由叫做链接器 ( $linker$ ) 的程序自动执行的。<br>
        像<code>Unix ld</code>程序这样的静态链接器 ( $static\ \ linker$ ) 以一组可重定位目标文件和命令行参数作为输入，生成一个完全链接的可以加载和运行的可执行目标文件作为输出。输入的可重定位目标文件由各种不同的代码和数据节 ( $section$ ) 组成。指令在一个节中，初始化的全局变量在另一个节中，而未初始化的变量又在另外一个节中。<br>
        为了创建可执行文件，链接器必须完成两个主要任务：</p>
<ul>
<li>符号解析 ( $symbol\ \ resolution$ )。目标文件定义和引用符号。符号解析的目的是将每个符号引用和一个符号定义联系起来。</li>
<li>重定位 ( $relocation$ )。编译器和汇编器生成从地址零开始的代码和数据节。链接器通过把每个符号定义与一个存储器位置联系起来，然后修改所有对这些符号的引用，使得它们指向这个存储器位置，从而重定位这些节。</li>
</ul>
<p>        目标文件有三种形式：</p>
<ul>
<li>可重定位目标文件。包含二进制代码和数据，其形式可以在编译时与其他可重定位目标文件合并起来，创建一个可执行目标文件。</li>
<li>可执行目标文件。包含二进制代码和数据，其形式可以被直接拷贝到存储器并执行。</li>
<li>共享目标文件。一种特殊类型的可重定位目标文件，可以在加载或者运行时，被动态地加载到存储器并链接。</li>
</ul>
<p>        编译器和汇编器生成可重定位目标文件 ( 包括共享目标文件 )。链接器生成可执行目标文件。从技术上来说，一个目标模块 ( $object\ \ module$ ) 就是一个字节序列，而一个目标文件 ( $object\ \ file$ ) 就是一个存放在磁盘文件中的目标模块。<br>
        每个可重定位目标模块 $m$ 都有一个符号表，包含 $m$ 所定义和引用的符号的信息。在链接器的上下文中，有三种不同的符号：</p>
<ul>
<li>由 $m$ 定义并能被其他模块引用的全局符号。</li>
<li>由其他模块定义并被模块 $m$ 引用的全局符号。</li>
<li>只被模块 $m$ 定义和引用的本地符号。</li>
</ul>
<p>        链接器解析符号引用的方法是将每个引用与它输入的可重定位目标文件的符号表中的一个确定的符号定义联系起来。当编译器遇到一个不是在当前模块中定义的符号时，它会假设该符号是在其他某个模块中定义的，生成一个链接器符号表表目，并把它交给链接器处理。如果链接器在它的任何输入模块中都找不到这个被引用的符号，它就输出一条错误信息并终止。<br>
        所有的编译系统都提供一种机制，将所有相关的目标模块打包为一个单独的文件，称为静态库 ( $static\ \ library$ )，它也可以用做链接器的输入。当链接器构造一个输出的可执行文件时，它只拷贝静态库里被应用程序引用的目标模块。在<code>Unix</code>系统中，静态库以一种称为存档 ( $archive$ ) 的特殊文件格式存放在磁盘中。存档文件是一组连接起来的可重定位目标文件的集合，有一个头部描述每个成员目标文件的大小和位置。<br>
        一旦链接器完成了符号解析，它就把代码中的每个符号引用和确定的一个符号定义联系起来。在此时，链接器就知道它的输入目标模块中代码节和数据节的确切大小。接下来就可以开始重定位了：</p>
<ul>
<li>重定位节和符号定义。链接器将所有相同类型的节合并为同一类型的新的聚合节。</li>
<li>重定位节中的符号引用。链接器修改代码节和数据节中对每个符号的引用，使得它们指向正确的运行时地址。为了执行这一步，链接器依赖于称为重定位表目 ( $relocation\ \ entry$ ) 的可重定位目标模块中的数据结构，记录需要修改的引用。</li>
</ul>
<p>        静态库同所有的软件一样，需要定期维护和更新。如果应用程序员想要使用一个库的最新版本，他们必须以某种方式了解到该库的更新情况，然后显式地将他们的程序与新的库重新链接。另一个问题是<code>C</code>程序使用的标准库函数，在运行时会被复制到每个运行进程的文本段中，从而造成存储器系统资源的极大浪费。<br>
        共享库 ( $shared\ \ library$ ) 是一个目标模块，在运行时，可以加载到任意的存储器地址，并在存储器中和一个程序链接起来。这个过程称为动态链接 ( $dynamic\ \ linking$ )，是由一个叫做动态链接器 ( $dynamic\ \ linker$ ) 的程序来执行的。在任何给定的文件系统中，对于一个库只有一个共享库文件，所有引用该库的可执行目标文件共享这个库中的代码和数据。使用共享库后，链接过程中不会将库中代码和数据节拷贝到可执行文件中，而是拷贝一些重定位和符号表信息，它们使得运行时可以解析库中代码和数据的引用。</p>
<h2 id="8-异常控制流">8. 异常控制流</h2>
<h3 id="81-异常">8.1 异常</h3>
<p>        从给处理器加电开始，直到断电为止，程序计数器假设一个序列的值</p>
<p>$$
a_0, a_1, \cdots, a_{n-1}
$$</p>
<p>        其中，每个 $a_k$ 是某个相应的指令 $I_k$ 的地址，每次从 $a_k$ 到 $a_{k+1}$ 的过渡称为控制转移 ( $control\ \ transfer$ )。这样的控制转移序列叫做处理器的控制流 ( $control\ \ flow$ )。现代系统通过使控制流发生突变来应对系统状态的变化，一般而言，我们把这些突变称为<code>ECF</code> ( $exceptional\ \ control\ \ flow$ )。<br>
        <b>异常</b> ( $exception$ ) 是一种形式的异常控制流，它一部分是由硬件实现的，一部分是由操作系统实现的。因为它们有一部分是由硬件实现的，所以具体细节将随系统的不同而有所不同。然而，对于每个系统而言，基本的思想都是相同的。在处理器中，状态被编码为不同的位和信号。状态变化被称为事件 ( $event$ )，事件可能和当前指令的执行直接相关，也可能没有关系。在任何情况中，当处理器检测到有事件发生时，它就会通过一张叫做异常表 ( $exception\ \ table$ ) 的跳转表，进行一个间接过程调用，到一个专门设计用来处理这类事件的操作系统子程序——异常处理程序 ( $exception\ \ handler$ )。当异常处理程序完成处理后，根据引起异常的事件的类型，会发生以下三种情况中的一种：</p>
<ol>
<li>处理程序将控制返回给当前指令 $Icurr$ 。</li>
<li>处理程序将控制返回给 $Inext$ 。</li>
<li>处理程序终止被中断的程序。</li>
</ol>
<p>        系统中可能的每种类型的异常都分配了一个唯一的非负整数的异常号 ( $exception\ \ number$ )。这些号码中的某一些是由处理器的设计者分配的，其他号码是由操作系统内核的设计者分配的。在系统启动时，操作系统分配和初始化一张称为异常表的跳转表，表目 $k$ 包含异常 $k$ 的处理程序的地址。在运行时，处理器检测到发生了一个事件，并且确定了相应的异常号 $k$ 。随后，处理器触发异常，方法是间接过程调用，通过异常表的表目 $k$ ，转到相应的处理程序。异常号是异常表的索引，异常表的起始地址放在一个叫做异常表基寄存器 ( $exception\ \ table\ \ base\ \ register$ ) 的特殊<code>CPU</code>寄存器里。<br>
        异常可以分为四类：</p>
<table>
<thead>
<tr>
<th style="text-align:center">类别</th>
<th style="text-align:center">原因</th>
<th style="text-align:center">异步/同步</th>
<th style="text-align:center">返回行为</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">中断</td>
<td style="text-align:center">来自<code>I/O</code>设备的信号</td>
<td style="text-align:center">异步</td>
<td style="text-align:center">总是返回到下一条指令</td>
</tr>
<tr>
<td style="text-align:center">陷阱</td>
<td style="text-align:center">有意的异常</td>
<td style="text-align:center">同步</td>
<td style="text-align:center">总是返回到下一条指令</td>
</tr>
<tr>
<td style="text-align:center">故障</td>
<td style="text-align:center">潜在可恢复的错误</td>
<td style="text-align:center">同步</td>
<td style="text-align:center">可能返回到当前指令</td>
</tr>
<tr>
<td style="text-align:center">终止</td>
<td style="text-align:center">不可恢复的错误</td>
<td style="text-align:center">同步</td>
<td style="text-align:center">不会返回</td>
</tr>
</tbody>
</table>
<p>        <strong>中断</strong>是异步发生的，是来自处理器外部的<code>I/O</code>设备的信号的结果。硬件中断不是任何一条专门的指令造成的，从这个意义上来说它是异步的。硬件终端的异常处理程序常常被称为中断处理程序 ( $interrupt\ \ handler$ )。<code>I/O</code>设备，例如网络适配器、磁盘控制器和定时器芯片，通过向处理器芯片上的一个管脚发信号，并将异常号放到系统总线上，来触发中断，这个异常号标识了引起中断的设备。在当前指令完成之前，处理器注意到中断管脚的电压变高了，就从系统总线读取异常号，然后调用适当的中断处理器程序。当处理程序返回时，它就将控制返回给下一条指令。结果是程序继续执行，就好像没有发生中断一样。<br>
        陷阱是有意的异常，是执行一条指令的结果。就像中断处理程序一样，陷阱处理程序将返回到下一条指令。陷阱最重要的用途是在用户程序和内核之间提供一个像过程一样的接口，叫做系统调用。用户程序经常需要向内核请求服务，比如读一个文件 ( $read$ )、创建一个新的进程 ( $fork$ )、加载一个新的程序 ( $execve$ )，或者终止当前进程 ( $exit$ )。为了允许对这些内核服务的受控的访问，处理器提供了一条特殊的 $syscall\ \ n$ 指令，当用户程序想要请求服务 $n$ 时，可以执行这条指令，产生一个到异常处理程序的陷阱。<br>
        故障由错误情况引起，它可能被故障处理程序修正。当一个故障发生时，处理器将控制转移给故障处理程序。如果处理程序能够修正这个错误情况，它就将控制返回到故障指令，从而重新执行它。否则，处理程序返回到内核中的 $abort$ 例程，终止引起故障的应用程序。故障的一个经典示例是缺页异常。<br>
        终止是不可恢复的致命错误造成的结果——典型的是一些硬件错误，比如<code>DRAM</code>或者<code>SRAM</code>位被损坏时发生的奇偶错误。终止处理程序从不将控制返回给应用程序，而是传递给一个内核 $abort$ 例程。</p>
<h3 id="82-进程">8.2 进程</h3>
<p>        异常提供基本的构造块，它允许操作系统提供<strong>进程</strong> ( $process$ ) 的概念。进程的经典定义就是一个执行中程序的实例。系统中的每个程序都是运行在某个进程的上下文 ( $context$ ) 中的。上下文是由程序正确运行所需的状态组成的，这个状态包括存放在存储器中的程序的代码和数据、它的栈、它的通用目的寄存器的内容、它的程序计数器、环境变量以及打开文件描述符的集合。<br>
        典型的，即使在系统中有许多其他程序在运行，进程也可以向每个程序提供一种假象，好像它在独占地使用处理器。如果我们想用调试器单步执行我们的程序，我们会看到一系列的<code>PC</code>的值，这些值唯一地对应于包含在我们程序的可执行目标文件中的指令或是包含在运行时动态链接到我们程序的共享对象中的指令。这个<code>PC</code>值的序列叫做逻辑控制流。任何逻辑流在时间上和另外的逻辑流重叠的进程被称为并发进程 ( $concurrent\ \ process$ )，而这两个进程就被称为并发运行。进程和其他进程轮换运行的概念称为多任务 ( $multitasking$ )。一个进程执行它的控制流的一部分的每一时间段叫做时间片 ( $time\ \ slice$ )。因此，多任务也叫做时间分片 ( $time\ \ slicing$ )。<br>
        进程也为每个程序提供一种假象，就好像它正在独占地使用系统地址空间。一个进程为每个程序提供它自己的私有地址空间。一般而言，和这个空间中某个地址相关联的那个存储器字节是不能被其他进程读或者写的，从这个意义上说，这个地址空间是私有的。<br>
        为了使操作系统内核提供一个无懈可击的进程抽象，处理器必须提供一种机制，限制一个应用可以执行的指令以及它可以访问的地址空间范围。典型地，处理器是用某个控制寄存器中的一个方式位 ( $mode\ \ bit$ ) 来提供这种功能的，当该方式位设置了时，进程就运行在内核模式中。一个运行在内核模式的进程可以执行指令集中的任何指令，并且可以访问系统中任何存储器位置。一个运行应用程序代码的进程初始时是在用户模式中的。进程从用户模式变为内核模式的唯一方法是通过诸如中断、故障或者陷入系统调用 ( $trapping\ \ system\ \ call$ ) 这样的异常。<br>
        操作系统内核利用一种称为上下文切换 ( $context\ \ switch$ ) 的较高级形式的异常控制流来实现多任务。内核为每个进程维持一个上下文，上下文就是内核重新启动一个被抢占进程所需的状态，由一些对象的值组成，包括通用目的寄存器、浮点寄存器、程序计数器、用户栈、状态寄存器、内核栈和各种内核数据结构，比如描绘地址空间的页表、包含有关当前进程信息的进程表，以及包含进程已打开文件的信息的文件表。在进程执行的某些时刻，内核可以决定抢占当前进程，并重新开始一个先前被抢占的进程，这种决定就叫做调度 ( $scheduling$ )，是由内核中称为调度器 ( $scheduler$ ) 的代码处理的。上下文切换可以：</p>
<ol>
<li>保存当前进程的上下文；</li>
<li>恢复某个先前被抢占进程所保存的上下文；</li>
<li>将控制传递给这个新恢复的进程。</li>
</ol>
<p>        当内核代表用户执行系统调用时，可以发生上下文切换。如果系统调用因为等待某个事件发生而阻塞，那么内核可以让当前进程休眠，切换到另一个进程。<br>
        当一个进程由于某种原因终止时，内核并不是立即把它从系统中清除。取而代之的是，进程被保持在一种终止状态中，直到被它的父进程回收 ( $reaped$ )。当父进程回收已终止的子进程时，内核将子进程的退出状态传递给父进程，然后抛弃已终止的进程，从此时开始，该进程就不存在了。一个终止了但还未被回收的进程称为僵死进程 ( $zombie$ )。如果父进程没有回收它的僵死子进程就终止了，那么内核会安排 $init$ 进程来回收它们。$init$ 进程的 $PID$ 为 $1$ ，并且是在系统初始化时由内核创建的。</p>
<h3 id="83-信号">8.3 信号</h3>
<p>        一个信号 ( $signal$ ) 就是一条消息，它通知进程一个某种类型的事件已经在系统中发生了。每种信号类型都对应于某个类型的系统事件。低层的硬件异常是由内核异常处理程序处理的，对用户进程而言通常是不可见的。信号提供了一种机制向用户进程通知这些异常的发生。发送一个信号到目的进程是由两个不同步骤组成的：</p>
<ul>
<li>发送信号。内核通过更新目的进程上下文中的某个状态，发送一个信号给目的进程。发送信号可以有如下两个原因：内核检测到一个系统事件，或者一个进程调用了 $kill$ 函数，显式地要求内核发送一个信号给目的进程。</li>
<li>接收信号。当目的进程被内核强迫以某种方式对信号的发送作出反应时，目的进程就接收了信号。进程可以忽略这个信号，终止，或者通过执行一个称为信号处理程序 ( $signal\ \ handler$ ) 的用户层函数捕获这个信号。</li>
</ul>
<p>        一个只发出而没有被接收的信号叫做待处理信号 ( $pending\ \ signal$ )。在任何时刻，一种类型至多只会有一个待处理信号，接下来发送到这个进程的该类型的信号都会被丢弃。一个进程可以有选择性地阻塞接收某种信号。当一种信号被阻塞时，它仍可以被发送，但是产生的待处理信号不会被接收，直到取消阻塞。</p>
<h2 id="9-测量程序执行时间">9. 测量程序执行时间</h2>
<p>        计算机是在两个完全不同的时间尺度 ( $time\ \ scale$ ) 上工作的。在微观级别，它们以每个时钟周期一条或多条指令的速度执行指令，这里每个时钟周期只需要大约 $1ns$ 。在宏观尺度上，处理器必须响应外部事件，外部事件发生的时间尺度要以 $ms$ 来度量。<br>
        外部事件，例如击键、磁盘操作和网络活动，会产生中断信号，这些中断信号使得操作系统调度程序得以运行，可能还会切换到另一个进程。即使没有这样的事件，我们也希望处理器从一个进程切换到另一个，这样用户看上去就好像处理器在同时执行许多程序一样。出于这个原因，计算机有一个外部计时器，它周期性地向处理器发送中断信号。这些中断信号之间的时间被称为间隔时间 ( $interval\ \ time$ )。当计时器中断发生时，操作系统调度程序可以选择要么继续当前正在执行的进程，要么切换到另一个进程。这个间隔时间必须设置得足够短，以保证处理器在任务间切换得足够频繁。但如果设置得太短，会导致性能很差，因为进程切换需要几千个时钟周期来进行。典型的计时器间隔范围是 $1 \sim 10ms$ 。<br>
        为了给计时测量提供更高的精确度，许多处理器还包含一个运行在时钟周期级的计时器。这个计时器是一个特殊的寄存器，每个时钟周期它都会加 $1$ 。可以用特殊的机器指令来读这个计数器的值。不是所有的处理器都有这样的计数器，而且有这样的计数器的处理器在实现细节上也各不相同。</p>
<h2 id="10-虚拟存储器">10. 虚拟存储器</h2>
<p>        计算机系统的主存被组织成一个由 $M$ 个连续的字节大小的单元组成的数组。每字节都有一个唯一的物理地址 ( $physical\ \ address$, $PA$ )。<code>CPU</code>访问存储器的最自然的方式就是使用物理地址。我们把这种方式称为物理寻址 ( $physical\ \ addressing$ )。根据虚拟寻址，<code>CPU</code>通过生成一个虚拟地址 ( $virtual\ \ address$, $VA$ ) 来访问主存，这个虚拟地址在被送到存储器之前先转换成适当的物理地址。将一个虚拟地址转换为物理地址的任务叫做地址翻译 ( $address\ \ translation$ )。就像异常处理一样，地址翻译需要<code>CPU</code>硬件和操作系统之间的紧密合作。<code>CPU</code>芯片上叫做<code>MMU</code> ( $memory\ \ management\ \ unit$ ) 的专用硬件，利用存放在主存中的查询表来动态翻译虚拟地址。<br>
        和存储器层次结构中其他缓存一样，磁盘上的数据被分割成块，这些块作为磁盘和主存之间的传输单元。<code>VM</code>系统通过将虚拟存储器分割为称为虚拟页 ( $virtual\ \ page$, $VP$ ) 的大小固定的块。<br>
        同任何缓存一样，虚拟存储器系统必须有某种方法来判定一个虚拟页是否存放在<code>DRAM</code>中的某个地方。如果是，系统还必须确定这个虚拟页存放在哪个物理页中。如果不命中，还需要进行替换。页表将虚拟页映射到物理页。虚拟地址空间中的每个页在页表中的一个固定偏移量处都有一个<code>PTE</code> ( $page\ \ table\ \ entry$ )。为了我们的目的，我们将假设每个<code>PTE</code>是由一个有效位和一个 $n$ 位地址字段组成的。<br>
        独立地址空间为操作系统提供了一个管理用户进程和操作系统自身之间共享的一致机制。一般而言，每个进程都有自己私有的代码、数据、堆以及栈区域，是不和其他进程共享的。然而，在一些情况中，还是需要进程来共享代码和数据。例如，每个进程必须调用相同的操作系统内核代码。操作系统通过将不同进程中适当的虚拟页面映射到相同的物理页面，从而安排多个进程共享这部分代码的一个拷贝，而不是在每个进程中都包括单独的内核的拷贝。<br>
        地址翻译是一个 $N$ 元素的虚拟地址空间 ( $VAS$ ) 中的元素和一个 $M$ 元素的物理地址空间 ( $PAS$ ) 中元素之间的映射。<code>CPU</code>中的一个控制寄存器，页表基址寄存器 ( $page\ \ table\ \ base\ \ register$, $PTBR$ ) 指向当前页表。$n$ 位的虚拟地址包含两个部分：一个 $p$ 位的<code>VPO</code> ( $virtual\ \ page\ \ offset$ ) 和一个 $(n - p)$ 的<code>VPN</code> ( $virtual\ \ page\ \ number$ )。<code>MMU</code>利用<code>VPN</code>来选择适当的<code>PTE</code>。<br>
        每次<code>CPU</code>产生一个虚拟地址，<code>MMU</code>就必须查阅一个<code>PTE</code>，在最糟糕情况下，这会要求一次对存储器的额外的取数据，代价是几十到几百个周期。许多系统都试图消除这样的开销，它们在<code>MMU</code>中包括了一个关于<code>PTE</code>的小的缓存，称为<code>TLB</code> ( $translation\ \ lookaside\ \ buffer$ )。<code>TLB</code>中每一行都保存着一个由单个<code>PTE</code>组成的块。当<code>TLB</code>不命中时，<code>MMU</code>必须从<code>L1</code>缓存中取出相应的<code>PTE</code>。<br>
        <code>Linux</code>通过将一个虚拟存储器区域与一个磁盘上的对象 ( $object$ ) 关联起来，以初始化这个虚拟存储器区域的内容，这个过程称为存储器映射 ( $memory\ \ mapping$ )。虚拟存储器区域可以映射到两种类型的对象：</p>
<ol>
<li><code>Unix</code>文件系统中的普通文件：一个区域可以映射到一个普通磁盘文件的连续部分。文件被分成页面大小的片，每一片包含一个虚拟页面的初始内容。</li>
<li>匿名文件：一个区域也可以映射到一个匿名文件，匿名文件是由内核创建的，包含的全是二进制零。<code>CPU</code>第一次引用这样一个区域内的虚拟页面时，内核就在物理存储器中找到一个合适的牺牲页面，用二进制零覆盖，并更新页表，在磁盘和存储器之间并没有实际的数据传送。</li>
</ol>
<p>        无论哪一种情况，一旦一个虚拟页面被初始化了，它就在一个由内核维护的专门的交换文件 ( $swap\ \ file$ ) 之间换来换去。交换文件也叫做交换空间 ( $swap\ \ space$ ) 或者交换区域 ( $swap\ \ area$ )。在任何时刻，交换空间都限制着当前运行着的进程能够分配的虚拟页面的总数。<br>
        一个对象可以被映射到虚拟存储器的一个区域，要么作为共享对象，要么作为私有对象。私有对象是使用一种叫做写时拷贝 ( $copy-on-write$ ) 的技术映射到虚拟存储器中的。一个私有对象开始的生命周期的方式基本上与共享对象一样，在物理存储器中只保存有私有对象的一份拷贝。两个进程可以将一个私有对象映射到它们的虚拟存储器的不同区域，但是共享同一份物理拷贝。对于每个映射私有对象的进程，相应私有区域的页表条目都被标记为只读，并且区域结构被标记为私有的写时拷贝。只要没有进程试图写它自己的私有区域，它们就可以继续共享物理存储器中对象的一个单独拷贝。然而，只要有一个进程试图写它自己的私有区域内的某个页面，那么这个写操作就会触发一个保护故障。当故障处理程序注意到保护异常是由于进程试图写私有的写时拷贝区域中的一个页面而引起的，它就会在物理存储器中创建这个页面的一个新拷贝，更新页表条目指向这个新拷贝，然后恢复这个页面的可写权限。<br>
        大多数<code>C</code>程序会在运行时需要额外的虚拟存储器，使用一种动态存储器分配器 ( $dynamic\ \ memory\ \ allocater$ )。一个动态存储器分配器维护着一个进程的虚拟存储器区域，称为堆 ( $heap$ )。在大多数的<code>Unix</code>系统中，堆是一个请求二进制零的区域，对于每个进程，内核维护着一个变量 $brk$ ，指向堆的顶部。<br>
        任何实际的分配器都需要一些数据结构，允许它来区分块边界，并区别已分配块和空闲块，大多数分配器将这些信息嵌在块本身当中。一个块是由一个字的头部、有效载荷以及可能的一些额外的填充组成的。头部编码了这个块的大小，以及这个块是已分配的还是空闲的。我们称这种结构为隐式空闲列表，因为空闲块是通过头部中的大小字段隐含地连接着的。<br>
        对于通用的分配器，隐式空闲列表是不适合的。一种更好的方法是将空闲块组织为某种形式的显式数据结构。例如，堆可以组织成一个双向空闲列表，或者使用<code>FIFO</code>方法维护链表。</p>
<h2 id="11-系统级io">11. 系统级<code>I/O</code></h2>
<p>        输入/输出 ( $I/O$ ) 是在主存和外部设备之间拷贝数据的过程。一个<code>Unix</code>文件就是一个 $m$ 字节的序列，所有的<code>I/O</code>设备，都被模型化为文件，而所有的输入和输出都被当作对相应文件的读和写来执行。内核用三种相关的数据结构来表示打开的文件：</p>
<ul>
<li>描述符表 ( $descriptor\ \ table$ )。每个进程都有它独立的描述符表，它的表项是由进程打开的文件描述符来索引的。每个打开的描述符表项指向文件表中的一个表项。</li>
<li>文件表 ( $file\ \ table$ )。打开文件的集合是由一张文件表来表示的，所有的进程共享这张表。每个文件表的表项组成包括有当前的文件位置、引用计数，以及一个指向 $v-node$ 表中对应表项的指针。</li>
<li>$v-node$ 表 ( $v-node\ \ table$ )。同文件表一样，所有的进程共享这张表。每个表项包含 $stat$ 结构中的大多数信息，包括 $st_-mode$ 和 $st_-size$ 成员。</li>
</ul>
<h2 id="12-网络编程">12. 网络编程</h2>
<p>        每个网络应用都是基于客户端-服务器模型的。根据这个模型，一个应用是由一个服务器进程和一个或者多个客户端进程组成的。客户端和服务器通常运行在不同的主机上，并且通过计算机网络的硬件和软件资源来通信。对于一个主机而言，网络只是一种<code>I/O</code>设备，作为数据源和数据接收方。从网络上接收到的数据从适配器经过<code>I/O</code>和存储器总线拷贝到存储器，典型地是通过<code>DMA</code>传送。<br>
        因特网客户端和服务器通过在连接 ( $connection$ ) 上发送和接收字节流来通信。从连接一对进程的意义上而言，连接是点对点 ( $point-to-point$ ) 的。从数据可以同时双向流动的角度来说，它是全双工 ( $full-duplex$ ) 的。套接字 ( $socket$ ) 是连接的端点 ( $end-point$ )。</p>
<h2 id="13-并发编程">13. 并发编程</h2>
<p>        构造并发程序最简单的方法就是用进程。对于在父、子进程间共享状态信息，进程有一个非常清晰的模型：共享文件表，但是不共享用户地址空间。有独立的进程地址空间，进程不可能不小心覆盖另一个进程的虚拟存储器，但是会使得进程共享状态信息变得更加困难。为了共享信息，它们必须使用显式的<code>IPC</code> ( 进程间通信 ) 机制。<br>
        <code>I/O</code>多路技术可以用作并发事件驱动 ( $event-driven$ ) 程序的基础，在事件驱动中，流是作为某种事件的结果前进的。一般概念是将逻辑流模型化为状态机。不严格地说，一个状态机 ( $state\ \ machine$ ) 就是一组状态 ( $state$ )、输入事件 ( $input\ \ event$ ) 和转移 ( $transition$ )，其中转移就是将状态和输入事件映射到状态。对于每个新客户端 $k$ ，基于<code>I/O</code>多路复用的并发服务器会创建一个新的状态机 $s_k$ ，并将它和已连接描述符 $d_k$ 联系起来。服务器使用<code>I/O</code>多路复用，借助 $select$ 函数，检测输入事件的发生。当每个已连接描述符准备好可读时，服务器就为相应的状态机执行转移。<br>
        <strong>线程</strong> ( $thread$ ) 就是运行在一个进程上下文中的一个逻辑流。线程由内核自动调度。每个线程都有它自己的线程上下文 ( $thread\ \ context$ )，包括一个唯一的整数线程<code>ID</code> ( $Thread\ \ ID$, $TID$ )、栈、栈指针、程序计数器、通用目的寄存器和条件码。所有运行在一个进程里的线程共享该进程的整个虚拟地址空间。在一些重要的方面，线程执行是不同于进程的。因为一个线程的上下文要比一个进程的上下文小得多，线程的上下文切换要比进程的上下文切换快得多。另一个不同就是线程不像进程那样按照严格的父子层次来组织，主线程和其他线程的区别仅在于它总是进程中第一个运行的线程。对等线程池概念的主要影响是，一个线程可以杀死它的任何对等线程，或者等待它的任意对等线程终止。进一步来说，每个对等线程都能读写相同的共享数据。<br>
        在任何一个时间点上，线程是可结合的 ( $joinable$ ) 或者是可分离的 ( $detached$ )。一个可结合的线程能够被其他线程收回资源和杀死。在被其他线程回收之前，它的存储器资源是不释放的。相反，一个分离的线程是不能被其他线程回收或杀死的。它的存储器资源在它终止时由系统自动释放。默认情况下，线程是可结合的。</p>

            </div>
            <div class="meta post-footer"> <span>2021 May 19 15:06</span> <a href="/post/csapp%E7%AC%94%E8%AE%B0/"><i
                        class="fas fa-link"></i> link</a></div>
        </div>
        
        <div class="post">
            
            <center>
                <h1><a href="/post/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/">操作系统笔记</a></h1>
            </center>
            <div class="post-content">
                <p><a href="http://c.biancheng.net/cpp/u/xitong_1/">计算机操作系统概述</a></p>
<h2 id="1-概述">1. 概述</h2>
<p>        <strong>操作系统</strong> ( $Operating\ \ System$, $OS$ ) 是指控制和管理整个计算机系统的硬件和软件资源，以提供给用户和其他软件方便的接口和环境的程序集合，是计算机系统中最基本的系统软件。没有任何软件支持的计算机称为裸机。裸机在最里层，外面是操作系统。<br>
        操作系统是计算机系统资源的管理者：</p>
<ul>
<li>处理机管理：处理机的分配和运行以进程（或线程）为基本单位，因为对处理机的管理可以归结为对进程的管理；</li>
<li>存储器管理：对内存的管理；</li>
<li>文件管理：文件系统；</li>
<li>设备管理：<code>I/O</code>。</li>
</ul>
<p>        操作系统还提供了用户接口：</p>
<ul>
<li>命令接口：使用命令接口进行作业控制的方式有两种：联机控制方式和脱机控制方式。进一步的，按照控制方式，可以将命令接口分为联机命令接口和脱机命令接口。
<ul>
<li>联机命令接口适用于分时或实时系统的接口，由一组键盘操作命令组成。用户通过控制台或者终端输入命令；</li>
<li>脱机命令接口又称批处理命令接口，适用于批处理系统，由一组作业控制命令组成，用户不能直接干预作业运行，实现用相应的作业控制命令做成一份作业操作说明书，连同作业一起提交给系统。</li>
</ul>
</li>
<li>程序接口由一组系统调用组成，用户通过在程序中使用这些系统调用命令来请求操作系统为其提供服务。</li>
</ul>
<p>        计算机系统中，通常<code>CPU</code>执行两种不同性质的程序：一种是操作系统内核程序，另一种是用户自编程序或者系统外层的应用程序。对于操作系统而言，前者是后者的管理者。内核程序可以执行一些特权指令，如<code>I/O</code>、中断、管理程序状态字寄存器等，出于安全考虑，这些程序不能被用户直接使用。操作系统在实现上划分了<strong>核心态</strong>（管态）和<strong>用户态</strong>（目态）以严格区分两类程序。<br>
        <strong>内核</strong>是计算机上配置的底层软件，大多数操作系统的内核包括四个方面的内容：</p>
<ul>
<li>时钟管理：时钟的第一功能是计时，通过时钟可以提供系统时间。此外，通过时钟中断，也可以实现进程切换；</li>
<li>中断机制：现代操作系统是靠中断驱动的软件。中断机制中，只有一小部分功能属于内核，负责保护和恢复中断现场信息，转移控制权，这样可以减少中断的处理时间；</li>
<li>原语 ( $Atomic\ \ Operation$ ) ：原语是一些可以被调用的小程序，处于操作系统的最底层，是最接近硬件的部分，具有原子性，且运行时间短、调用频繁；</li>
<li>系统控制的数据结构及处理：操作系统中存在许多记录状态信息的数据结构，如作业控制块、进程控制块、内存分配表等，操作系统需要一些对这些数据结构进行管理的基本操作。</li>
</ul>
<p>        从上述内容可知，核心态指令包括系统调用类指令和一些针对时钟、中断和原语的操作指令。<br>
        操作系统不允许用户程序实现核心态的功能，而它们又必须使用这些功能。因此，需要实现核心态和用户态之间的转换。在实际操作系统中，<code>CPU</code>运行上层程序时的唯一转换途径是通过中断或异常。当中断或异常发生时，运行用户态的<code>CPU</code>会立即进入核心态，这是通过硬件实现的（例如用一个特殊寄存器表示）。<br>
        <strong>中断</strong> ( $Interruption$ ) 指来自<code>CPU</code>执行指令以外的事件的发生，如设备<code>I/O</code>中断、时钟中断等。访管指令是一条可以在用户态下执行的指令，用于产生一个中断，称为访管中断，系统会根据访管指令的操作数执行对应的访管中断处理程序。<strong>异常</strong> ( $Exception$ )，也称为<strong>陷入</strong> ( $Trap$ ) ，指来自<code>CPU</code>执行指令内部的事件的发生，如程序的非法操作码、地址越界、内存缺页以及专门的陷入指令等。对异常的处理一般要依赖于当前程序的运行现场，并且异常不能被屏蔽，一旦出现应立即处理。<br>
        系统调用是用户在程序中调用操作系统提供的一些子功能，可以把系统调用看作是特殊的公共子程序。在用户程序中，凡是与资源有关的操作，都必须通过系统调用向操作系统提出服务请求，并由操作系统代为完成。系统调用大致可以分为如下几类：</p>
<ul>
<li>设备管理：设备请求、启动以及释放等；</li>
<li>文件管理：对文件的读写、创建和删除等；</li>
<li>进程控制：对进程的创建、销毁、阻塞和唤醒等；</li>
<li>进程通信：进程之间的消息传递；</li>
<li>内存管理：对内存的分配、回收以及获取内存区大小和地址等。</li>
</ul>
<p>        用户通过操作系统运行上层程序，上层程序依赖于操作系统的底层管理程序提供服务支持。当需要管理程序服务时，系统通过硬件中断机制进入核心态；当程序运行出现异常时，系统通过异常处理机制进入核心态。当管理程序结束时，用户程序继续运行，通过之前中断处理程序或者异常处理程序保存的中断现场，返回断点处继续执行。</p>
<h2 id="2-进程和线程">2. 进程和线程</h2>
<h3 id="21-进程">2.1 进程</h3>
<p>        在多道程序环境下，多个程序可以并发执行，为此引入了<strong>进程</strong> ( $Process$ )。为了使参与并发执行的程序能够独立地执行，操作系统为之配置了一个专门的数据结构称为<strong>进程控制块</strong> ( $Process\ \ Control\ \ Block$, $PCB$ )。系统利用<code>PCB</code>来描述进程的基本情况和运行状态，进而实现对进程的控制和管理。程序段、相关数据段和<code>PCB</code>构成了进程实体，进程实体是静态的，但是进程是动态的。进程创建实质上是创建<code>PCB</code>，撤销实质上是撤销<code>PCB</code>，<code>PCB</code>是进程存在的唯一标志。<code>PCB</code>通常包含以下内容：</p>
<table>
<thead>
<tr>
<th style="text-align:center">进程描述信息</th>
<th style="text-align:center">进程控制和管理信息</th>
<th style="text-align:center">资源分配清单</th>
<th style="text-align:center">处理机相关信息</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">进程标识符 ( <code>PID</code> )</td>
<td style="text-align:center">进程当前状态</td>
<td style="text-align:center">代码段指针</td>
<td style="text-align:center">通用寄存器值</td>
</tr>
<tr>
<td style="text-align:center">用户标识符 ( <code>UID</code> )</td>
<td style="text-align:center">进程优先级</td>
<td style="text-align:center">数据段指针</td>
<td style="text-align:center">地址寄存器值</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">代码运行入口地址</td>
<td style="text-align:center">堆栈段指针</td>
<td style="text-align:center">控制寄存器值</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">程序的外存地址</td>
<td style="text-align:center">文件描述符</td>
<td style="text-align:center">标志寄存器值</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">进入内存时间</td>
<td style="text-align:center">键盘</td>
<td style="text-align:center">状态字</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">处理机占用时间</td>
<td style="text-align:center">鼠标</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">信号量使用</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<ul>
<li>进程描述信息：进程标识符用于唯一标识一个进程，用户标识符用于表示进程归属的用户；</li>
<li>进程控制和管理信息：进程当前状态用于描述进程的状态信息，作为处理机分配调度的依据；进程优先级可以保证优先级高的进程优先获得处理机；</li>
<li>资源分配清单：说明有关内存地址空间或虚拟地址空间的状况，打开文件列表和所使用的<code>I/O</code>设备的信息；</li>
<li>处理机相关信息：处理机中各个寄存器的值，当进程切换发生时，处理机的状态信息都会被保存在<code>PCB</code>中。</li>
</ul>
<p>        进程通常有五种状态：</p>
<ul>
<li><strong>运行</strong>：进程在处理机上运行；</li>
<li><strong>就绪</strong>：进程处于准备运行的状态；</li>
<li><strong>阻塞</strong>：进程正在等待某一事件而暂停运行；</li>
<li><strong>创建</strong>：进程正在被创建，创建完成后进入就绪状态；</li>
<li><strong>结束</strong>：进程正在从系统中消失，系统会先将进程设置为结束状态，再处理资源释放和回收等工作。</li>
</ul>
<p>        进程可以创建另一个进程，此时创建者称为父进程，子进程可以继承父进程所拥有的资源。操作系统创建一个进程的过程如下（创建原语）：</p>
<ol>
<li>为新进程分配一个唯一的进程标识号，并申请一个空白的<code>PCB</code> （<code>PCB</code>数量是有限的），申请失败则创建失败；</li>
<li>为进程分配资源，包括为程序和数据、以及用户栈分配内存（在<code>PCB</code>中体现），如果资源不足，会进入阻塞状态；</li>
<li>初始化<code>PCB</code>，包括初始化标志信息、处理机状态信息、处理机控制信息以及进程优先级等；</li>
<li>如果就绪队列未满，将新进程插入就绪队列中，等待时间片调度。</li>
</ol>
<p>        正在执行的进程如果某些期待的事件未发生，如请求系统资源失败、等待操作完成，系统会执行阻塞原语，将进程由运行状态变为阻塞状态。进程的阻塞是一种主动行为，只有处于运行中的进程才能转为阻塞状态。阻塞原语的执行过程如下：</p>
<ol>
<li>找到进程标识号对应的<code>PCB</code>；</li>
<li>保护进程运行现场，将其转为阻塞状态；</li>
<li>将该<code>PCB</code>插入到相应事件的等待队列中。</li>
</ol>
<p>        唤醒原语的执行过程如下：</p>
<ol>
<li>在等待队列中找到相应进程的<code>PCB</code>；</li>
<li>将<code>PCB</code>从等待队列中移出，将其转为就绪状态；</li>
<li>将<code>PCB</code>插入就绪队列中，等待调度程序调度。</li>
</ol>
<p>        引起进程终止的事件有：正常结束，即完成任务后的准备退出运行，和异常结束，即运行过程中发生异常事件导致程序无法继续运行。终止进程的过程如下：</p>
<ol>
<li>找到进程标识号对应的<code>PCB</code>，读取进程状态；</li>
<li>如果进程处于执行状态，终止进程执行；</li>
<li>若进程存在子进程，终止其所有子进程的执行；</li>
<li>将进程拥有的资源归还给父进程或者操作系统；</li>
<li>将<code>PCB</code>从所在队列的链表中删除。</li>
</ol>
<p>        通常进程的创建、撤销以及要求系统设备完成<code>I/O</code>操作都是利用系统调用进入内核，再由内核中相应的处理程序完成的。进程切换也是在内核的支持下完成的，所以进程是与内核紧密相关的。进程切换的过程如下：</p>
<ol>
<li>保存处理机上下文，包括程序计数器和其他寄存器；</li>
<li>更新<code>PCB</code></li>
<li>把<code>PCB</code>移入相应的队列，如就绪队列或者某个事件的阻塞队列；</li>
<li>找到下一个要执行的进程，更新<code>PCB</code>；</li>
<li>更新内存管理的数据结构；</li>
<li>恢复处理机上下文。</li>
</ol>
<p>        <strong>进程间通信</strong>是指进程之间的信息交换，<code>PV</code>操作是低级通信方式，而高级通信方式能够以较高速率传输大量数据。高级通信方法主要有以下三种：</p>
<ol>
<li>共享存储：进程间一块可以直接访问的共享空间，通过同步互斥工具控制读写，实现信息交换。低级的共享方式是基于数据结构的共享，而高级的共享方式是基于存储区的共享，操作系统负责提供共享空间和互斥工具，用户负责实现读写指令；</li>
<li>消息传递：进程间的数据交换以消息为单位，系统提供发送和接受两个原语。根据是否存在中间件，可以分为直接和间接两种方式。直接通信方式直接把消息发送到接收进程的消息缓冲队列上，间接通信方式则把消息发送到某个中间实体中，典型代表是电子邮箱；</li>
<li>管道通信：管道用于连接一个读进程和一个写进程，写进程以字符流形式将大量数据送入管道，读进程则从管道中读取数据。管道必须提供三方面的协调能力：互斥、同步和确定对方存在。</li>
</ol>
<h3 id="22-线程">2.2 线程</h3>
<p>        <strong>线程</strong>可以减小程序在并发执行时付出的开销，提高操作系统的并发性能。线程的最直接理解就是“轻量级进程”，它是<code>CPU</code>的基本执行单元，是程序执行的最小单元，由线程<code>ID</code>、程序计数器、寄存器集合和堆栈组成。线程是进程中的一个实体，是系统独立调度和分派的基本单位，只拥有一些运行中必不可少的资源，共享其所在进程的全部资源。线程可以创建和撤销另一个线程，同一个进程中的线程可以并发执行。线程具有就绪、阻塞和运行三个状态。在多线程操作系统中，线程作为独立运行（或调度）的基本单位。此时，进程的执行实际上指的是进程中的某个线程正在执行。<br>
        线程的引入提高了系统的并发性和吞吐量。并且由于线程只持有一些必不可少的资源，所以在创建和撤销过程中的系统开销更小。类似地，在进行进程切换时，要涉及到当前进程<code>CPU</code>环境的保存以及新调度进程<code>CPU</code>环境的设置，而线程就只需要保存和设置少量寄存器内容即可。并且由于线程共享进程资源，所以线程之间的同步和通信非常容易实现。<br>
        线程的实现可以分为两类：用户级线程 ( $User-Level\ \ Thread$, $ULT$ ) 和内核级线程 ( $Kernel-Level\ \ Thread$, $KLT$ )。用户级线程中，有关线程管理的所有工作都交由应用程序完成，内核察觉不到线程的存在。内核级线程中，线程管理的所有工作都交由内核完成，应用程序没有进行线程管理的代码，只有一个到内核级线程的编程接口。内核为进程及其内部的每个线程维护上下文信息。有些系统同时支持用户级线程和内核级线程，由此产生了不同的线程模型：</p>
<ul>
<li>一对一模型：将每个用户级线程映射到一个内核级线程。优点：当前线程阻塞后允许另一个线程继续运行，并发能力较强；缺点：每个用户级线程都需要创建一个内核级线程与之对应，创建线程的开销较大；</li>
<li>多对一模型：将多个用户级线程映射到一个内核级线程。优点：线程管理在用户空间完成，效率较高；缺点：当内核服务被阻塞时，整个进程都会被阻塞，并且多线程不能在多处理机上并行运行；</li>
<li>多对多模型：将 $n$ 个用户级线程映射到 $m$ 个内核级线程上，要求 $m \le n$ 。既克服了多对一并发度不高的缺点又克服了一对一开销较大的缺点。</li>
</ul>
<h3 id="23-调度">2.3 调度</h3>
<p>        在多道程序系统中，进程的数量往往多于处理机的个数。处理机调度是对处理机进行分配，就是从就绪队列中按照某个算法选择一个进程并将处理机分配给它运行。一个作业从提交开始直到完成，往往要经历以下三级调度：</p>
<ul>
<li>作业调度：又称高级调度。按照一定的原则从外存上处于后备状态的作业中选择一个（或多个）作业，给它们分配内存、<code>I/O</code>设备等资源，并建立相应的进程，以使它们获得竞争处理机的权利。简单来讲就是内存与辅存之间的调度，对于每个作业只调入一次，调出一次；</li>
<li>内存调度：又称中级调度。将一些暂时不能运行的进程调至外存等待，将进程设为挂起状态。当它们具备运行条件时，再重新调回内存，并设为就绪状态，在就绪队列上等待；</li>
<li>进程调度：又称低级调度。按照某个算法从就绪队列中选择一个进程，并分配处理机，是操作系统中最基本的调度。</li>
</ul>
<p>        系统内核负责进程调度和进程切换，当请求调度事件发生后，才会运行进程调度程序，当调度了新的就绪进程后，才会进行进程切换。通常有两种进程调度方式：</p>
<ul>
<li>非抢占：当一个进程正在执行时，如果有另一个优先级更高的进程进入就绪队列，直到当前进程完成或者进入阻塞状态时才能把处理机分配给优先级更高的进程；</li>
<li>抢占：当一个进程正在处理机上运行时，如果有另一个优先级更高的进程进入就绪队列，会立即暂停当前进程，将处理机分配给优先级更高的进程。</li>
</ul>
<p>        操作系统中存在多种调度算法，有的调度算法适用于作业调度，有些适用于进程调度，还有的两者都适用。</p>
<h4 id="231-fcfs">2.3.1 <code>FCFS</code></h4>
<p>        先来先服务 ( $FCFS$ ) 调度算法是最简单的调度算法，既适用于作业调度也适用于进程调度。该算法会每次从后备作业队列或者进程就绪队列中选择最先进入该队列的一个或几个作业/进程，为它们分配资源。该算法属于非抢占算法，虽然实现简单，但是效率低，对长作业有利，适合<code>CPU</code>繁忙型作业，不利于<code>I/O</code>繁忙型作业。</p>
<h4 id="232-sjfspf">2.3.2 <code>SJF</code>/<code>SPF</code></h4>
<p>        最短作业优先 ( $SJF$ )/ 最短进程优先 ( $SPF$ ) 调度算法是对短作业/进程优先调度的算法，即每次从后备队列/就绪队列中选择一个或几个估计运行时间最短的作业，为它们分配资源。该算法对长作业不利，容易出现饥饿现象，但是平均等待时间、平均周转时间最少。</p>
<h4 id="233-优先级调度算法">2.3.3 优先级调度算法</h4>
<p>        优先级调度算法会每次从后备队列/优先队列中选择一个或几个优先级最高的作业/进程，并为它们分配资源。根据新的更高优先级进程能否抢占正在执行的进程，可以将调度算法分为非抢占式优先级调度算法和抢占式优先级调度算法。根据进程创建后优先级是否可以改变，可以将进程优先级分为静态优先级和动态优先级。</p>
<h4 id="234-高响应比优先调度算法">2.3.4 高响应比优先调度算法</h4>
<p>        高响应比优先调度算法适用于作业调度，在每次进行作业调度时，先计算后备作业中每个作业的响应比，从中选出响应比最高的作业运行。计算公式为：</p>
<p>$$
响应比R_{\rho} = \frac{等待时间+要求服务时间}{要求服务时间}
$$</p>
<h4 id="235-时间片轮转调度算法">2.3.5 时间片轮转调度算法</h4>
<p>        时间片轮转调度算法适用于分时系统，系统会将所有就绪进程按照达到时间的先后顺序排成一个队列，按照<code>FCFS</code>原则，从队列中选择一个进程分配一个时间片。在时间片结束后，进程需要释放处理机给下一个就绪的进程，被剥夺的进程会返回到就绪队列的末尾重新排队。</p>
<h4 id="236-多级反馈队列调度算法">2.3.6 多级反馈队列调度算法</h4>
<p>        多级反馈队列调度算法设置多个就绪队列，并为各个队列设置不同的优先级，同时每个队列中进程执行时间片的大小也不同，优先级更高的队列时间片越小。每当一个新进程进入内存后，会先将它放入一级队列的末尾，按照时间片轮转算法调度。如果一个进程未在时间片结束后完成，将会进入二级队列的末尾……如此下去，会一直降到 $n$ 级队列。只有上级队列为空的时候，调度程序才会调度下级队列中的进程。多级反馈队列调度算法既可以兼顾多方面的系统目标，也不需要事先估计进程的执行时间。</p>
<h3 id="24-同步">2.4 同步</h3>
<p>        虽然多个进程可以共享系统中的各种资源，但是许多资源一次只能被一个进程使用，我们称之为临界资源，如打印机等。对于临界资源的访问必须互斥进行，访问临界资源的代码称为临界区。<strong>同步</strong>是指为了完成某种任务而建立的两个或多个进程，因为需要在某些位置上协调它们的工作次序而等待、传递信息所产生的制约关系。进程间的直接制约关系就是它们之间的相互合作。<strong>互斥</strong>亦称间接制约关系。当一个进程进入临界区使用临界资源时，另一个进程必须等待，直到当前进程退出临界区。<br>
        临界区互斥的基本实现方法分为软件实现方法和硬件实现方法。软件实现方法通过一个或多个标志位判断是否存在其他进程正在访问临界区。硬件实现方法需要通过计算机提供的特殊硬件指令实现，该指令允许对一个字中的内容进行检测和修正，或者对两个字的内容进行交换等，典型的有中断屏蔽法，即在进入临界区时屏蔽中断（<code>CPU</code>只在发生中断时进行进程切换），或者通过 $TestAndSet$ 和 $CompareAndSwap$ 这些硬件指令实现。<br>
        信号量机制可以用来解决互斥与同步的问题，只能被两个标准原语 $wait$ 和 $signal$ 来访问，也可以记为 $P$ 操作和 $V$ 操作。<br>
        管程是由一组数据以及定义在数据之上的对这组数据的操作组成的软件模块，这组操作能初始化并改变管程中的数据和同步进程。管程由三部分组成：</p>
<ul>
<li>局部于管程的共享结构数据说明；</li>
<li>对该数据结构进行操作的一组过程；</li>
<li>对局部于管程的共享数据设置初始值的语句。</li>
</ul>
<p>        局部于管程的数据只能被局部于管程的过程所访问。一个进程只有通过调用管程内的过程才能进入管程访问共享数据，且每次只允许一个进程在管程内执行某个内部过程。<br>
        <strong>死锁</strong>是指多个进程因竞争资源造成的互相等待。死锁产生的必要条件有：</p>
<ul>
<li>互斥：一段时间内某个资源只被一个进程占有；</li>
<li>非抢占：进程在获得资源且未使用完毕时，不能被其他进程抢占；</li>
<li>请求并保持：进程已经持有了至少一个资源并提出新请求，同时不释放已经持有的资源；</li>
<li>循环等待：存在进程资源的循环等待链。</li>
</ul>
<p>        要防止死锁，需要破坏上述四个条件中的任意一个，或者能够检测死锁的发生并进行恢复。破坏产生死锁的四个必要条件的方式称为死锁预防，在资源分配的过程中用某种方式防止系统进入不安全状态称为死锁避免，而通过检测机制及时检测死锁发生然后采取措施称为死锁检测。死锁预防和死锁避免属于事先预防策略，实现起来较简单，但是效率低。而死锁避免的实现较为复杂。<br>
        死锁预防只需要破坏死锁产生的四个必要条件之一即可：</p>
<ul>
<li>破坏互斥：系统的所有资源都能共享使用，但是这种方式不太可行；</li>
<li>破坏非抢占：当一个进程在请求新资源失败时，必须释放已经保持的资源。该策略实现起来较复杂，因为释放资源可能会造成前一阶段的工作失效，而且反复地获取和释放会增加系统开销，常用于状态易保存和恢复的资源，如<code>CPU</code>寄存器和内存资源；</li>
<li>破坏请求并保持：采用预先静态分配的方法，进程在运行前一次性申请所有需要的资源。该策略实现起来简单，但是会造成系统资源的严重浪费，还可能带来饥饿现象；</li>
<li>破坏循环等待：采用顺序资源分配法，规定进程必须按照一定顺序申请资源。但是这种方法限制了新设备的增加，而且也经常会发生作业使用资源的顺序与系统规定顺序不同的情况，从而造成系统资源的浪费。</li>
</ul>
<p>        死锁避免是在资源动态分配的过程中防止系统进入不安全状态。通常系统会维护一张资源分配表，在新请求进来时计算分配是否会进入不安全状态。典型的算法有银行家算法。<br>
        如果系统在资源分配时不采取任何措施，则应该提供死锁检测和解除手段。系统死锁可以通过资源分配图来描述，当且仅当 $S$ 状态的资源分配图是不可完全简化的时候， $S$ 就是死锁。当检测出死锁的时候，就要采取相应的措施，主要方法有资源剥夺法：挂起某些死锁进程并释放它们持有的资源；撤销进程法：强制撤销部分、甚至全部死锁进程并释放它们的资源，可以按照优先级或者撤销代价的顺序进行；进程回退法：让一个或多个进程回退到足以回避死锁的状态，在回退的过程中进程会自愿释放资源，系统需要保持进程的历史信息并设置还原点。</p>
<h2 id="3-内存">3. 内存</h2>
<p>        <strong>内存管理</strong> ( $Memory\ \ Management$ ) 是操作系统设计中最重要和最复杂的内容之一。创建进程首先要将程序和数据装入内存，将用户源程序变为可在内存中执行的程序，通常需要以下几个步骤：</p>
<ul>
<li>编译：由编译程序将用户源代码编译成若干个目标模块；</li>
<li>链接：由链接程序将编译后形成的一组目标模块，以及所需库函数链接在一起，形成一个完整的装入模块；</li>
<li>装入：由装入程序将装入模块装入内存运行。</li>
</ul>
<p>        程序的链接有三种方式：</p>
<ul>
<li>静态链接：在程序运行之前将各自目标模块及它们所需的库函数链接成一个完整的可执行程序，不再拆开；</li>
<li>装入时动态链接：将用户源程序编译后得到的一组目标模块，在装入内存时采用边装入边链接的链接方式；</li>
<li>运行时动态链接：对某些目标模块的链接，在程序执行中需要该目标模块时，才对它进行链接。</li>
</ul>
<p>        内存的装入模块在装入内存时同样有三种方式：</p>
<ul>
<li>绝对装入：产生绝对地址的目标代码，按照装入模块中的地址，将程序和数据装入内存，此种方式中程序的逻辑地址与实际地址完全相同，只适用于单道程序环境。绝对地址可在编译或汇编时给出，也可以由程序员直接赋值。</li>
<li>可重定位装入：在多道程序环境下，多个目标模块的起始地址通常都是从 $0$ 开始，其他地址都是相对于起始地址的。可重定位装入根据当前内存情况，会在在装入时对程序中指令和数据进行修改，称为重定位。地址变换通常是在装入时一次完成的，所以又称为静态重定位。静态重定位的特点是作业装入内存时必须分配其要求的全部内存空间，此外一旦装入，便不能移动和申请新的内存空间；</li>
<li>动态运行时装入：也称为动态重定位，程序如果在内存中发生移动，就要采用动态装入方式。装入程序在把装入模块装入内存后，不会立即把装入模块中的相对地址转为绝对地址，而是推迟到程序要真正执行时，这种方式需要重定位寄存器的支持。使用动态重定位，程序在运行的时候可以只装入部分代码，再在运行时根据需要动态申请分配内存。</li>
</ul>
<p>        在编译完成后，每个目标模块都是从 $0$ 号单元开始，称为该模块的相对地址（或逻辑地址）。当链接程序将各个模块链接为一个完整的可执行程序时，链接程序会顺序依次按照各个模块的相对地址构成同一个的从 $0$ 号单元开始编址的逻辑地址空间。物理地址空间是内存中物理单元的集合，它是地址转换的最终地址，进程在运行时执行指令和访问数据最后都要通过物理地址从主存中获取，将逻辑地址转换为物理地址的过程称为地址重定位。<br>
        内存分配前，需要保护操作系统不受用户进程的影响，同时保护用户进程不受其他用户进程的影响。通过采用重定位寄存器和界地址寄存器来实现这种保护。重定位寄存器包含最小的物理地址值，界地址寄存器含逻辑地址值。每个逻辑地址值必须小于界地址寄存器，否则就会发生地址越界。如果未发生地址越界，就会加上重定位寄存器的值，映射成物理地址，再交由内存单元。当<code>CPU</code>调度程序选择进程执行时，派遣程序会初始化重定位寄存器和界地址寄存器。<br>
        内存的分配方式有连续分配方式和非连续分配方式。连续分配方式指为一个用户程序分配一个连续的内存空间，包括：</p>
<ul>
<li>单一连续分配：内存分为系统区和用户区，系统区仅提供给操作系统使用，通常在低地址部分；用户区提供给用户使用。这种方式不需要内存保护，而且实现简单，没有外部碎片，缺点是只适用于单用户、单任务系统，存在内部碎片且内存使用效率较低；</li>
<li>固定分区分配：固定分区分配是最简单的一种多道程序存储管理方式，它将用户内存空间划分为若干个固定大小的区域，这些区域大小可能相等也可能不相等，每个区域装入一道作业。如果存在空闲分区，就从外存的后备队列中选择适当大小的作业装入分区。这种分配方式产生内存碎片，而且如果没有任何一个分区满足程序的运行，就必须使用覆盖技术；</li>
<li>动态分区分配：动态分区分配不会预先划分内存，而是在进程装入内存时，根据进程大小动态地建立分区。这种分配方式会导致外部碎片。外部碎片可以通过紧凑 ( $Compaction$ ) 的技术解决，但是需要动态重定位寄存器的支持，而且相对费时。在将进程装入或换入主存时，如果存在多个足够大的空闲块，操作系统必须决定分配哪个内存块，这就是动态分区的分配策略，主要有以下几种算法：首次适应 ( $First\ \ Fit$ ) 算法、最佳适应 ( $Best\ \ Fit$ ) 算法、最坏适应 ( $Worst\ \ Fit$ ) 算法和邻近适应 ( $Next\ \ Fit$ ) 算法。首次适应算法通常是最好和最快的，但是会导致低地址部分出现很多外部碎片。邻近适应算法会从上次查找结束的位置继续查找，但是会导致分配通常在高地址部分进行，因为低地址部分被释放的空间不会参与分配。最佳适应算法的性能很差，因为每次都会留下很小的外部碎片。最差适应算法会导致很快没有大内存块使用，因此性能也很差。</li>
</ul>
<p>        非连续分配允许一个程序分散地装入到不相邻的内存分区中，根据分区大小是否固定可以分为分段或者分页管理方式。在分页管理方式中，根据是否要将作业的所有页面都装入内存才能运行分为基本分页存储管理方式和请求分页存储管理方式。<br>
        分页存储方式将内存空间划分为大小相等且固定的块，每个进程也以块为单位进行划分，进程在执行过程中以块为单位依次申请内存中的块空间。进程中的块称为页 ( $Page$ )，内存中的块称为页帧 ( $Page\ \ Frame$ )，外存也以同样的单位划分，直接称为块 ( $Block$ )。进程在执行过程中需要申请内存空间，就是为每个页面分配内存中可用的页帧。分页的地址结构包含两部分，页号和页偏移量。系统会为每个进程建立一张页表，一般存放在内存中，记录页号对应的内存中的物理块。系统中通常会设置一个页表寄存器 ( $PTR$ )，存放页表在内存的起始地址和长度，在进程执行时设置。在地址变换中通常还会设置一个具有并行查找能力的告诉缓冲存储器，称为快表或者联想寄存器 ( $TLB$ )，存放部分页表项。在设置了快表后，地址的转换过程会优先在快表中查找，如果没有找到，才会在页表中查找，并且会将这次查找结果存在快表中。由于页表存储在内存中，并且页面大小较小，所以会导致页表过大的问题，而且通常一个进程运行时只需要小部分的页面，由此提出了二级页表的概念。二级页表将一级页表的空间进行地址映射，即将一级页表划分为若干个等大的区域，这样在进程执行的过程中，只需要将二级页表映射的那一块页表区域调入内存即可。由二级页表进一步延伸，可以建立多级页表。<br>
        分段存储方式按照用户进程中的自然段划分逻辑空间，每段从 $0$ 开始编址，并分配一段连续的地址空间（段内连续，段间不连续）。逻辑地址由段号和段偏移量组成。在分页系统中，逻辑地址的页号和页偏移量对用户透明，但在分段系统中，段号和段偏移量必须由用户显式提供，在高级语言中由编译器完成。每个进程都有一个逻辑空间与内存空间映射的段表，每个段表项对应进程的一个段，包括段号、段长和起始地址。为了实现从逻辑地址到物理地址的映射，系统中设置了一个段表寄存器，存放段表的起始地址和长度。在分段系统中，段共享是通过两个段表中相应表项指向被共享段的同一个物理副本实现的。<br>
        段页式存储方式结合了分页和分段，首先将作业的地址空间分为若干个段，每个段都有自己的段号，然后再将段分为固定大小的页。内存的空间管理仍和分页存储方式一样，将其分为若干个固定大小的页帧。作业的逻辑地址分为三部分：段号、页号和页偏移量。系统为每个进程建立一张段表，每个分段有一张页表。系统中还有一个段表寄存器，记录段表起始地址和段表长度。<br>
        在程序装入时，可以将程序的一部分装入内存，在执行过程中，当访问的信息不在内存时，再将它们调入内存。另一方面，操作系统也可以将内存中暂时不使用的内存换出到外存上。这样，操作系统好像提供了一个比实际大得多的内存，称为<strong>虚拟内存</strong>。虚拟内存需要建立在非连续分配的基础上，因此只适用于分段和分页存储管理方式。请求分页系统建立在基本分页系统的基础上，为了支持虚存而增加了请求调页和页面置换功能。为了支持请求分页，操作系统除了需要一定容量的内存和外存之外，还需要有页表机制、缺页中断机制和地址变换机制。<br>
        请求分页系统在作业运行之前不要求调入全部内存，因此如何发现和解决缺页是一个基本问题。为此，页表项中新增了四个字段，分别为状态位，用于标识该页是否调入内存；访问字段，记录本页在一段时间内被访问的次数或者最近有多久未被访问；修改位：标识该页在调入内存后是否被修改；外存地址：通常是外存上的物理块号，用于调入页面时提供参考。每当要访问的页面在内存中不存在时，就会产生一个缺页中断，此时进程将会被阻塞。如果内存中存在空闲块，就会将页面装入该块，并修改页表，否则就会执行页面置换算法。常见的页面置换算法有：</p>
<ul>
<li>最佳 ( $OPT$ ) 置换算法：最佳置换算法选择的页面将是以后永不使用的，或者是在最长时间内不会被访问的。但是由于无法预测哪个页面不会被使用，所以该算法无法实现；</li>
<li>先进先出 ( $FIFO$ ) 置换算法：淘汰最早进入内存的页面，或者说在内存中驻留时间最久的页面。<code>FIFO</code>还可能会出现当所分配的物理块数增加而缺页故障数不减反增的异常，称为<code>Belady</code>异常；</li>
<li>最近最久未使用 ( $LRU$ ) 置换算法：选择最近最久未使用的页面淘汰。该算法为每个页面设置一个访问字段，记录自上次访问以来经历的时间，每次淘汰时选择最大的予以淘汰。<code>LRU</code>的性能较好，但是需要寄存器和栈的硬件支持；</li>
<li>时钟 ( $CLOCK$ ) 置换算法：<code>CLOCK</code>算法给每一帧关联一个附加位，称为使用位。当某一页首次装入内存时置 $1$ ，如果在之后被访问也会置 $1$ 。在进行页替换的时候，将候选帧看作一个循环缓冲区，并且有一个指针指向其中的某一页帧。当需要替换时，操作系统会扫描缓冲区，查找使用位为 $0$ 的帧并将其替换，在这个过程中每当遇到一个使用位为 $1$ 的帧，就把它的使用位置 $0$ 。也可以在这个算法的基础上添加一个修改位，每当页面被修改时置 $1$ 。优先替换使用位为 $0$ 的帧，其次是修改位为 $0$ 的帧（如果有的话），因为被修改的页面在被替换之前必须先写回。</li>
</ul>
<p>        使用了虚拟内存技术后，进程不需要将所有页都读到内存。但是操作系统需要决定每个进程在内存中驻留的页面的数量，称为驻留集的大小。通常有三种策略：</p>
<ul>
<li>固定分配局部置换：为每个进程分配固定数量的物理块；</li>
<li>可变分配全剧置换：这是最容易实现的策略，为每个进程分配一定数量的物理块，操作系统本身也维护一个空闲物理块队列，当进程缺页发生时，从空闲物理块队列中取出一个物理块分配给该进程；</li>
<li>可变分配局部置换：为每个进程分配一定数量的物理块，当进程缺页发生时，从该进程的驻留集中选择页面换出。如果进程频繁缺页，系统会为该进程分配若干物理块，直到缺页率趋于适当程度。如果进程缺页率过低，系统也会回收部分物理块。</li>
</ul>
<p>        在调入页面的时候，除了只调入需要的页面外，系统也可以一次调入若干个相邻的页面，但是需要预测哪些页面会被使用。这种策略主要用于进程的首次调入，由用户指定调入页面。<br>
        请求分页系统的外存可以分为文件区和对换区两个部分。对换区通常采用连续分配方式，文件区采用离散分配方式，因此对换区的<code>I/O</code>速度会更快。如果对换区空间足够，进程运行前可以把文件先从文件区复制到对换区；如果对换区空间不足，则优先将可能被修改的部分放入对换区；还可以使用<code>UNIX</code>方式，即将文件放在文件区，把运行过被换出的页面放入对换区。</p>
<h2 id="4-文件">4. 文件</h2>
<p>        在系统运行时，计算机以进程为基本单位进行资源的调度和分配；而在用户进行<code>I/O</code>时，基本单位是<strong>文件</strong> ( $File$ )。操作系统提供了文件系统 ( $File\ \ System$ ) 实现对文件的管理，如访问文件、修改文件、保存文件和删除文件等。文件的结构包括：</p>
<ol>
<li>数据项：分为基本数据项和组合数据项，前者用于描述一个对象的某种属性的一个值，是原子数据；后者由多个基本数据项组成；</li>
<li>记录：记录是一组相关的数据项的集合，用于描述一个对象在某方面的属性；</li>
<li>文件：文件是创建者定义的一组相关信息的集合，逻辑上可分为有结构文件和无结构文件。有结构文件由一组相似记录组成，而无结构文件由字符流或者字节流组成。</li>
</ol>
<p>        文件具有一定的属性，通常有：</p>
<ul>
<li>名称：唯一名称；</li>
<li>标识符：文件系统内的唯一标签，通常为数字；</li>
<li>类型：支持不同类型文件的文件系统中使用；</li>
<li>位置：设备和设备上文件指针；</li>
<li>大小：文件大小，单位可以是字节、字或者块，也可以包含文件允许的最大值；</li>
<li>保护：访问控制信息；</li>
<li>时间、日期和用户标识：文件创建、修改和访问的相关信息。</li>
</ul>
<p>        文件信息保存在目录结构中，目录结构保存在外存上，当需要使用时再调入内存。<br>
        文件系统支持对文件进行一些基本操作：</p>
<ul>
<li>创建：创建包含为文件在文件系统中找到存储空间和为文件在目录中创建条目，条目用于记录文件名称、位置和其他信息；</li>
<li>读/写：系统调用，指明文件名称和文件内容。系统根据文件名称搜索目录查找文件位置，为文件维护一个读/写位置指针。一个进程通常只对一个文件进行读/写，所以当前操作位置可作为文件位置指针，同时读写共用一个指针；</li>
<li>文件重定位：按照条件搜索目录，将当前文件位置设为给定值；</li>
<li>删除：从目录中找到待删除的文件，将其设为空，然后回收空间；</li>
<li>截断：文件属性不变但是长度设为 $0$ 并回收空间。</li>
</ul>
<p>        因为许多文件操作都涉及为给定文件搜索相关目录条目，所以许多系统要求在首次使用文件时通过系统调用 $open$ 将文件属性从外存拷贝到内存打开文件表 ( $open-file\ \ table$ ) 中，并将条目索引返回给用户。当用户需要文件操作时，通过索引可以直接访问指定文件，避免了搜索操作。通常，打开文件表中的条目还有一个文件打开计数器 ( $Open\ \ Count$ )，用于记录多少进程打开了该文件。当计数器为 $0$ 时，代表文件不再被使用，此时系统就会回收文件的内存空间，包括打开文件表中的对应条目，如果文件被修改过，还会将文件写回外存，最后释放文件的文件控制块 ( $File\ \ Control\ \ Block$, $FCB$ )。每个打开文件表的条目都有如下关联信息：</p>
<ul>
<li>文件指针：系统跟踪上次文件读写位置作为文件位置指针，对于每个进程来讲是唯一的；</li>
<li>文件打开计数：跟踪文件打开和关闭的数量，值为 $0$ 时关闭文件，删除对应条目；</li>
<li>磁盘位置：绝大多数文件操作都要修改文件数据，保存该信息是为了避免每次都进行搜索；</li>
<li>访问权限：每个进程打开文件都有一个访问模式（只读、只写、读写等），保存在打开文件表中以便操作系统能允许或者拒绝之后的<code>I/O</code>请求。</li>
</ul>
<p>        文件的逻辑结构是从用户的角度出发看到的文件的组织形式，物理结构是从实现的角度出发看到的文件的组织形式，又称为文件的存储结构。按照逻辑结构，文件有无结构文件和有结构文件两种类型。无结构文件是最简单的文件组织形式，按照顺序组织成记录并累积保存，以字节或字符为单位，适用于对基本信息单位操作不多的文件，如源程序文件、目标代码文件等；有结构文件按记录的组织形式可以分为：</p>
<ul>
<li>顺序文件：文件中的记录顺序排列，可以是定长的或者变长的，可以顺序存储也可以以链表方式存储。可以分为串结构和顺序结构，前者中记录顺序与关键字无关，通常按时间排序，后者中所有记录按照关键字顺序排序；</li>
<li>索引文件：索引文件维护一张索引表，表项记录了索引、记录开头位置指针和记录长度；</li>
<li>索引顺序文件：顺序文件和索引文件两种组织形式的结合，将顺序文件中的记录分为组，为每个组的第一条记录建立一个索引项。索引表中只包含关键字和指针两个记录，按照关键字顺序排序；</li>
<li>直接文件/散列文件：直接通过记录的键值或者哈希值确定记录的物理位置。</li>
</ul>
<p>        文件目录包含文件有关的信息，包括属性、位置和所有权等，目录管理通过树形结构实现。为了实现目录管理，操作系统中引入了文件控制块。文件控制块是用来存放控制文件需要的各种信息的数据结构，<code>FCB</code>的有序集合就是文件目录，一个<code>FCB</code>就是一个文件目录项。每当创建一个新文件的时候，系统就会分配一个<code>FCB</code>并存放在文件目录中，成为文件目录项。<code>FCB</code>主要包括：</p>
<ul>
<li>基本信息：文件名、物理位置、逻辑结构和物理结构等；</li>
<li>存储控制信息：如文件存取权限等；</li>
<li>使用信息：文件创建时间、修改时间等。</li>
</ul>
<p>        在检索文件目录时，只需要使用文件名，因此有的系统，如<code>UNIX</code>，使用了文件名和描述信息分开的方法。文件描述信息单独形成一个称为索引结点的数据结构，简称为 $i$ 结点。文件目录的每个目录项由文件名和指向该文件对应的 $i$ 结点的指针形成。<br>
        在文件目录上进行的基本操作包括：</p>
<ul>
<li>搜索：用户使用文件前需要先在目录中进行搜索，找到对应的目录项；</li>
<li>创建：文件被创建时需要在目录中增加一个目录项；</li>
<li>删除：文件被删除时需要在目录中删除对应的目录项；</li>
<li>显示目录：显示目录中所有的文件及属性；</li>
<li>修改目录：目录中保存了一些文件属性，当这些属性变化时需要修改目录项。</li>
</ul>
<p>        在操作时，需要考虑以下集中目录结构：</p>
<ul>
<li>单级目录结构：整个文件系统中建立一张目录表，每个文件占一个目录项；</li>
<li>两级目录结构：将文件目录分为主文件目录 ( $Master\ \ File\ \ Directory$, $MFD$ ) 和用户文件目录 ( $User\ \ File\ \ Directory$, $UFD$ )。主文件目录项记录用户名及相应用户文件目录所在的存储位置，用户文件目录项记录该用户文件的<code>FCB</code>信息；</li>
<li>多级目录结构：即树形目录结构。用户访问文件时使用文件的路径名标识文件，路径名是从根目录出发到所找文件的路径上所有的目录名。从根目录出发的路径称为绝对路径，从当前目录出发的路径称为相对路径；</li>
<li>无环图目录结构：树形目录结构便于实现文件分类，不便于实现文件共享，为此在树形目录结构上增加了一些指向同一节点的有向边，使得整个目录变成一个有向无环图。每个共享节点都有一个共享计数器，只有计数器为 $0$ 时才会删除节点。</li>
</ul>
<p>        在读取文件之前，必须先通过路径名找到对应的目录项。目录实现的基本方式有线性表和哈希表两种：</p>
<ul>
<li>线性表：使用存储文件名和数据块指针的线性表是最简单的目录实现方法。在创建文件时需要先搜索目录表确定没有重名文件，再在目录表中添加表项；</li>
<li>哈希表：哈希表根据文件名得到一个哈希值，通过哈希值可以得到一个指向线性表中元素的指针。</li>
</ul>
<p>        文件共享使得多个用户可以共享同一文件，系统只需要保存文件的一份副本。如果系统不支持文件共享，那么就需要该文件的每个用户都拥有各自的副本。常用的两种文件共享方式有：</p>
<ul>
<li>基于索引结点的共享方式（硬链接）：在这种共享方式中，文件名和索引结点分开存储，文件目录中只设置文件名和指向索引结点的指针。当其他用户访问文件时，会在其文件目录中增加一个目录项，设置指针指向该文件的索引结点，并将索引计数加 $1$ ；</li>
<li>基于符号链的共享方式（软链接）：系统为共享文件创建一个 $LINK$ 类型的新文件，将其写入对应用户的目录中，新文件中包含被链接文件的路径名。只有文件的拥有者才拥有指向索引结点的指针，其他用户只有该文件的路径名。当拥有者把共享文件删除时，其他用户通过符号链的访问会访问失败。在符号链的共享方式中，其他用户读取共享文件时需要根据路径查找目录，因此每次访问都要多次读盘，增加了访问开销。</li>
</ul>
<p>        文件保护通过口令保护、加密保护和访问控制等方式实现。其中，口令保护和加密保护是为了防止用户文件被他人存取或窃取，而访问控制则用于控制用户对文件的访问方式。对文件的保护可以从限制对文件的访问类型中出发，可以控制的访问类型主要有：读、写、执行、添加、删除和列表清单（列出文件名和文件属性）。此外还有重命名、复制、编辑等，这些高层功能可以通过低层系统调用实现，保护可以在低层提供。<br>
        解决访问控制最常用的方法是根据用户身份进行控制，最普通的方法是为每个文件和目录增加一个访问控制列表 ( $Access-Control\ \ List$, $ACL$ )，规定每个用户名及其所允许的访问类型。优点是可以使用复杂的访问方法，缺点是长度无法估计，可能导致复杂的空间管理，精简的访问列表可以解决这个问题。精简的访问列表采用拥有者、组和其他三种用户类型，这样只需要使用三个域列出访问表中这三类用户的访问权限即可。拥有者在创建文件时，系统会将拥有者、所属组名列在<code>FCB</code>中。<br>
        口令是指用户在建立文件时提供一个口令，系统在<code>FCB</code>上附上相应口令，用户请求访问时必须提供相应口令，优点是时间和空间开销低，缺点是口令存在系统内部，不够安全。密码则是用户对文件进行加密，用户访问时需要使用密钥，优点是保密性强，缺点是需要进行编码和解码，提高了访问开销。<br>
        文件分配对应于文件的物理结构，指如何为文件分配磁盘块，常见的分配方式有：</p>
<ul>
<li>连续分配：文件在磁盘上占有一组连续的块，支持顺序访问和直接访问，但是会产生外部碎片。文件的目录条目会包括文件开始块的地址和文件长度；</li>
<li>链接分配：采取离散分配方式，可以动态分配磁盘块。可以分为隐式链接和显式链接两种形式。隐式链接中每个文件对应一个磁盘块链表，除最后一个块之外，其他块都有指向下一个块的指针。显式链接会把链接文件各个块指针显式存放在一张链接表中，称为文件分配表 ( $File\ \ Allocation\ \ Table$, $FAT$ )；</li>
<li>索引分配：索引分配将每个文件的所有块号集中在一起构成索引块，每个文件都有对应的索引块。对于大文件，可以将多个索引块链接起来。也可以使用多层索引方式，或者混合索引方式，即系统既采用直接地址，又采用单级索引或两级索引分配方式。</li>
</ul>
<p>        <strong>磁盘</strong> ( $Disk$ ) 是由表面涂有磁性物质的金属或塑料构成的圆形盘片，通过一个称为磁头的导体线圈从磁盘中存取数据。磁盘的盘面上的数据存储在一组同心圆中，称为磁道，每个磁道与磁头一样宽。磁道又可以划分为几百个扇区，每个扇区固定存储大小 ( 通常为 $512B$ )，一个扇区称为一个块。相邻磁道及相邻扇区之间通过一定的间隙分开，避免精度错误。磁盘安装在磁盘驱动器中，由磁头臂、主轴和用于<code>I/O</code>的电子设备组成，多个盘片垂直堆叠，形成磁盘组，每个盘面对应一个磁头，所有磁头固定在一起，与磁盘中心距离相同且一起移动。扇区是磁盘可寻址的最小存储单位，磁盘地址使用柱面号、盘面号和扇区号表示。<br>
        一次磁盘读写操作由寻道时间、延迟时间和传输时间决定。寻道时间指将磁头移到指定磁道所需的时间，延迟时间指磁头定位到某一磁道的扇区所需的时间，传输时间指从磁盘读出或向磁盘写入数据所经历的时间。常用的磁盘调度算法有：</p>
<ul>
<li>先来先服务 ( $First\ \ Come\ \ First\ \ Serverd$, $FCFS$ ) 算法：根据进程请求访问磁盘的先后顺序进行调度；</li>
<li>最短寻道时间优先 ( $Shortest\ \ Seek\ \ Time\ \ First$, $SSTF$ ) 算法：选择调度处理的磁道是与当前磁头所在磁道距离最近的磁道。这种算法可能会产生饥饿；</li>
<li>扫描 ( $SCAN$ ) 算法：在磁头当前移动方向上选择与当前磁头所在磁道距离最近的请求作为下一次服务的对象；</li>
<li>循环扫描 ( $Circulair\ \ SCAN$, $C-SCAN$ ) 算法：在扫描算法的基础上规定磁头单向移动。</li>
</ul>
<p>        一个新的磁盘只是一个含有磁性记录材料的空白盘，在进行存储之前必须先分成扇区以便磁盘控制器能进行读写，这个过程称为低级格式化 ( 物理分区 )。每个扇区的数据结构通常由头、数据区域和尾组成，头尾包含了一些磁盘控制器所使用的信息。为了使用磁盘存储文件，操作系统还需要将自己的数据结构记录在磁盘上：第一步将磁盘分为由一个或多个柱面组成的分区，第二步对物理分区进行逻辑格式化，即创建文件系统。计算机启动时需要运行一个初始化程序，用于初始化<code>CPU</code>、寄存器、设备控制器和内存等，接着启动系统。初始化程序通常保存在<code>ROM</code>中，为了避免修改代码需要改变<code>ROM</code>的问题，通常在<code>ROM</code>中只保留很小部分，并将完整功能保存在磁盘的启动块上。启动块位于磁盘的固定位置上，拥有启动块的磁盘称为启动磁盘或者系统磁盘。</p>
<h2 id="5-io">5. <code>I/O</code></h2>
<p>        设备管理的主要任务之一是控制设备和内存或处理机之间的数据传送，外围设备和内存之间的输入/输出控制方式有四种：</p>
<ul>
<li>程序直接控制方式。计算机从外部设备读取数据到存储器，每次读一个字的数据。对读入的每个字，<code>CPU</code>需要对外设状态进行循环检查，直到确定该字已经在<code>I/O</code>控制器的数据寄存器中。程序直接控制方式虽然简单易于实现，但是其缺点也是显而易见的，由于<code>CPU</code>和<code>I/O</code>设备只能串行工作，导致<code>CPU</code>利用率相当低。</li>
<li>中断驱动方式。允许<code>I/O</code>设备主动打断<code>CPU</code>的运行并请求服务，从而解放<code>CPU</code>，使得其向<code>I/O</code>控制器发送读命令后可以继续做其他有用的工作。
<ul>
<li>从<code>I/O</code>控制器的角度来看，<code>I/O</code>控制器从<code>CPU</code>接收一个读命令，然后从外围设备读数据。一旦数据读入到该<code>I/O</code>控制器的数据寄存器，便通过控制线给<code>CPU</code>发出一个中断信号，表示数据已准备好，然后等待<code>CPU</code>请求该数据。<code>I/O</code>控制器收到<code>CPU</code>发出的取数据请求后，将数据放到数据总线上，传到<code>CPU</code>寄存器中。</li>
<li>从<code>CPU</code>的角度来看，<code>CPU</code>发出读命令，然后保存当前运行程序的上下文，转而去执行其他程序。在每个指令周期的末尾，<code>CPU</code>检查中断。当有来自<code>I/O</code>控制器的中断时，<code>CPU</code>保存当前正在运行程序的上下文，转而去执行中断处理程序。</li>
</ul>
</li>
<li><code>DMA</code>方式。<code>DMA</code>方式的基本单位是数据块，传送数据是从设备直接送入内存或者相反，仅在传送一个或多个数据块的开始和结束时，才需要<code>CPU</code>干预，整块数据的传送是在<code>DMA</code>控制器的控制下完成的。为了实现在主机与控制器之间成块数据的直接交换，必须在<code>DMA</code>控制器中设置如下四类寄存器：命令/状态寄存器 ( $CR$ )，接收从<code>CPU</code>发来的<code>I/O</code>命令、有关控制信息或设备状态；内存地址寄存器 ( $MAR$ )，输入时存放把数据从设备传送到内存的起始目标地址，输出时存放由内存到设备的内存源地址；数据寄存器 ( $DR$ )，用于暂存从设备到内存，或从内存到设备的数据；数据计数器 ( $DC$ )，存放本次<code>CPU</code>要读或写的数据量。<code>CPU</code>读写数据时，会给<code>I/O</code>控制器发出一条命令，启动<code>DMA</code>控制器，然后继续其他工作，之后<code>CPU</code>就把控制操作委托给<code>DMA</code>控制器，由该控制器负责处理。当传送完成后，<code>DMA</code>控制器发送一个中断信号给处理器。</li>
<li>通道控制方式。<code>I/O</code>通道是指专门负责输入/输出的处理机，是<code>DMA</code>方式的发展，即把对一个数据块的读写为单位的<code>CPU</code>干预，减少为对一组数据块的读写及有关的控制和管理为单位的干预。当<code>CPU</code>要完成一组相关的读写操作及有关控制时，只需向<code>I/O</code>通道发送一条<code>I/O</code>指令，以给出其所要执行的通道程序的首地址和要访问的<code>I/O</code>设备，通道接收到该指令后，通过执行通道程序即可完成<code>CPU</code>指定的<code>I/O</code>任务，数据传送结束时向<code>CPU</code>发中断请求。与<code>DMA</code>方式的区别是，<code>DMA</code>需要<code>CPU</code>控制传输的数据块大小和内存位置，而通道中这些信息是由通道控制的，另外，通道可以控制多台设备与内存的数据交换。</li>
</ul>

            </div>
            <div class="meta post-footer"> <span>2021 May 10 20:54</span> <a href="/post/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/"><i
                        class="fas fa-link"></i> link</a></div>
        </div>
        
    </div>
</div>


        </div><footer>
    <div class="footer-content">
        
        <div class="contact-info">
            
            <div class="footer-github">
                <i class="fab fa-github fa-ms"></i> <a target="_blank" href="https://github.com/z217">github.com/z217</a>
            </div>
            
            
            <div class="footer-mail">
                <i class="far fa-envelope"></i> <a href="mailto:mailto:zihan.zhouchn@outlook.com">mailto:zihan.zhouchn@outlook.com</a> </div>
            
            
        </div>
        
        
        <p class="copyright meta">Copyright © 2020–2020, z217 and the Hugo Authors; all rights reserved. Theme: <a target="_blank"
                href="https://github.com/ahmedsaadxyzz/npq-hugo">npq-hugo</a></p>
        
    </div>
</footer>


<script type="text/javascript" async
    src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [
                ['$', '$'],
                ['\\(', '\\)']
            ],
            displayMath: [
                ['$$', '$$'],
                ['\[\[', '\]\]']
            ],
            processEscapes: true,
            processEnvironments: true,
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            TeX: {
                equationNumbers: {
                    autoNumber: "AMS"
                },
                extensions: ["AMSmath.js", "AMSsymbols.js"]
            }
        }
    });

    MathJax.Hub.Queue(function () {
        
        
        
        var all = MathJax.Hub.getAllJax(),
            i;
        for (i = 0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
        if (tocFlag) tocInit();
    });
</script>

<style>
    code.has-jax {
        font: inherit;
        font-size: 100%;
        background: inherit;
        border: inherit;
        color: #515151;
    }
</style></main>
</body>

</html>